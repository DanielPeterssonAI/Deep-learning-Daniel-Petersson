{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "y = np.array([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = np.vectorize(lambda x: max(0, x))\n",
    "\n",
    "\n",
    "def xor(input):\n",
    "    w1 = np.random.uniform(-2, 2, (2,2))\n",
    "    w2 = np.random.uniform(-2, 2, (2,1))\n",
    "\n",
    "    b1 = np.random.uniform(-2, 2, (2,1))\n",
    "    b2 = np.random.uniform(-2, 2, 1)\n",
    "\n",
    "    return relu(w2.T @ relu(w1 @ input + b1) + b2)\n",
    "\n",
    "input = np.array([\n",
    "    [1, 1],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [0, 0]\n",
    "])\n",
    "\n",
    "xor(input.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83229031])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(-2, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "rnd.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "sigmoid = np.vectorize(lambda x: 1 / (1 + math.exp(-x)))\n",
    "\n",
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.w1 = np.random.uniform(-3, 3, (2,3))\n",
    "        self.w2 = np.random.uniform(-3, 3, (2,1))\n",
    "        self.b1 = np.random.uniform(-3, 3, (2,1))\n",
    "        self.b2 = np.random.uniform(-3, 3, 1)\n",
    "\n",
    "    def predict(self, input):\n",
    "        return (self.w2.T @ sigmoid(self.w1 @ input.T + self.b1) + self.b2).reshape(-1)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"w1:\\n{self.w1}\\nw2:\\n{self.w2}\\nb1:\\n{self.b1}\\nb2:\\n{self.b2}\"\n",
    "\n",
    "\n",
    "#ett = Net()\n",
    "\n",
    "#print(ett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = {}\n",
    "y_pred = {}\n",
    "\n",
    "for i in range(100000):\n",
    "    nets[i] = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=1.0, key=3225\n",
      "score=1.0, key=3473\n",
      "score=1.0, key=13512\n",
      "score=1.0, key=29161\n",
      "score=1.0, key=41754\n",
      "score=1.0, key=54713\n",
      "score=1.0, key=62088\n",
      "score=1.0, key=64308\n",
      "score=1.0, key=71531\n",
      "score=1.0, key=72460\n",
      "score=1.0, key=82028\n",
      "score=1.0, key=92266\n",
      "score=1.0, key=95263\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "for key, val in nets.items():\n",
    "    y_pred[key] = nets[key].predict(X)\n",
    "    y_pred[key] = (y_pred[key] > 0.5) * 1\n",
    "\n",
    "for key, val in y_pred.items():\n",
    "    score = ((val == y).sum() / 4)\n",
    "    if score > 0.76:\n",
    "        print(f\"{score=}, {key=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "X_train, y_train = df[~df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]], df[~df[\"horsepower\"].isna()][\"horsepower\"]\n",
    "X_pred = df[df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred = np.round(y_pred)\n",
    "df.loc[X_pred.index, \"horsepower\"] = y_pred\n",
    "df = pd.get_dummies(df.drop(\"name\", axis = 1), columns = [\"origin\"])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((318, 9), (40, 9), (40, 9), (318,), (40,), (40,))"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df.drop([\"mpg\"], axis = 1).values, df[\"mpg\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 9)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "sigmoid = np.vectorize(lambda x: 1 / (1 + math.exp(-x)))\n",
    "\n",
    "class Net:\n",
    "    def __init__(self, weights_and_biases = ()):\n",
    "        if len(weights_and_biases) == 0:\n",
    "            self.w1 = np.random.uniform(-3, 3, (9, 9))\n",
    "            self.w2 = np.random.uniform(-3, 3, (9, 1))\n",
    "            self.b1 = np.random.uniform(-3, 3, (9, 1))\n",
    "            self.b2 = np.random.uniform(-3, 3, 1)\n",
    "        else:\n",
    "            self.w1 = weights_and_biases[0]\n",
    "            self.w2 = weights_and_biases[1]\n",
    "            self.b1 = weights_and_biases[2]\n",
    "            self.b2 = weights_and_biases[3]\n",
    "        self.mae = 0\n",
    "    \n",
    "    def set_weights(self, weights_and_biases):\n",
    "        self.w1 = weights_and_biases[0]\n",
    "        self.w2 = weights_and_biases[1]\n",
    "        self.b1 = weights_and_biases[2]\n",
    "        self.b2 = weights_and_biases[3]\n",
    "\n",
    "    def predict(self, input):\n",
    "        return (self.w2.T @ sigmoid(self.w1 @ input.T + self.b1) + self.b2).reshape(-1)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"w1:\\n{self.w1}\\nw2:\\n{self.w2}\\nb1:\\n{self.b1}\\nb2:\\n{self.b2}\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        w1 = (self.w1 + other.w1) / 2 + np.random.normal(0, 3, (9, 9))\n",
    "        w2 = (self.w2 + other.w2) / 2 + np.random.normal(0, 3, (9, 1))\n",
    "        b1 = (self.b1 + other.b1) / 2 + np.random.normal(0, 3, (9, 1))\n",
    "        b2 = (self.b2 + other.b2) / 2 + np.random.normal(0, 3, 1)\n",
    "\n",
    "        return w1, w2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = {}\n",
    "y_pred = {}\n",
    "\n",
    "for i in range(100):\n",
    "    nets[i] = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in nets.items():\n",
    "    y_pred[key] = nets[key].predict(scaled_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(41, 4.480608028679595),\n",
       " (46, 4.576803794262158),\n",
       " (95, 5.733034932208385),\n",
       " (6, 6.161184119740518),\n",
       " (14, 6.241899989347149),\n",
       " (50, 6.25642025186649),\n",
       " (57, 6.843750578204804),\n",
       " (93, 6.998563213706495),\n",
       " (89, 7.264867639836995),\n",
       " (49, 7.2780309986458995),\n",
       " (72, 7.33116521582634),\n",
       " (31, 7.349609259865081),\n",
       " (97, 7.500701423633933),\n",
       " (69, 7.5602780191981065),\n",
       " (22, 7.694209315341058),\n",
       " (81, 7.7061665736926575),\n",
       " (9, 7.965614808614813),\n",
       " (65, 7.999598958098417),\n",
       " (83, 8.08724159074282),\n",
       " (66, 8.518138312588562),\n",
       " (35, 8.87608213717504),\n",
       " (21, 8.880821959700096),\n",
       " (25, 9.301042146476574),\n",
       " (53, 9.36266809257481),\n",
       " (19, 9.470104787130648),\n",
       " (16, 9.823314117212352),\n",
       " (68, 9.839642104251471),\n",
       " (59, 10.26260295493417),\n",
       " (29, 10.445689372803464),\n",
       " (67, 10.845429482990482),\n",
       " (77, 10.95201443892694),\n",
       " (98, 11.129588051644536),\n",
       " (45, 11.292987532561888),\n",
       " (13, 11.318553486225557),\n",
       " (18, 11.339337400640977),\n",
       " (80, 11.403377239037937),\n",
       " (56, 11.589524790417935),\n",
       " (1, 11.840795541968493),\n",
       " (85, 11.917161663741185),\n",
       " (37, 12.02424092846997),\n",
       " (24, 12.120046556532168),\n",
       " (10, 12.146581127578978),\n",
       " (3, 12.164351723107659),\n",
       " (79, 12.21364470586538),\n",
       " (92, 12.225097930057466),\n",
       " (96, 12.363798153156177),\n",
       " (78, 12.536069900845895),\n",
       " (73, 12.622850966864451),\n",
       " (58, 12.624655946541628),\n",
       " (84, 12.653313531932051),\n",
       " (30, 12.736866394364071),\n",
       " (20, 12.814837673163632),\n",
       " (99, 12.996117009989463),\n",
       " (39, 13.057443727393538),\n",
       " (2, 13.329343754703746),\n",
       " (8, 13.613712587341436),\n",
       " (47, 13.657793176895838),\n",
       " (27, 13.668135038632968),\n",
       " (70, 13.73122766104609),\n",
       " (12, 14.093565815116905),\n",
       " (76, 14.624591344085223),\n",
       " (64, 14.72767117631006),\n",
       " (91, 14.859430919230455),\n",
       " (15, 14.884350348685643),\n",
       " (62, 14.909974243334053),\n",
       " (82, 14.979521059785482),\n",
       " (54, 15.017250936131788),\n",
       " (51, 15.041058958287765),\n",
       " (86, 15.091790939038543),\n",
       " (5, 15.10649883269786),\n",
       " (23, 15.112715204085436),\n",
       " (55, 15.136826846392832),\n",
       " (44, 15.329169115655858),\n",
       " (87, 15.355412538931715),\n",
       " (32, 15.408668715971848),\n",
       " (75, 15.423209502513245),\n",
       " (0, 15.502692860397074),\n",
       " (94, 15.596466633256076),\n",
       " (11, 15.656443067986833),\n",
       " (36, 15.670684454971234),\n",
       " (52, 15.753236203553433),\n",
       " (60, 15.812379543659855),\n",
       " (7, 15.86388837390733),\n",
       " (90, 15.990463414987616),\n",
       " (4, 16.03385166206669),\n",
       " (48, 16.163838821643434),\n",
       " (38, 16.977775959488895),\n",
       " (43, 17.20054250137673),\n",
       " (17, 17.301498458502632),\n",
       " (61, 17.70814852498816),\n",
       " (74, 18.149731867001865),\n",
       " (33, 18.20858943161191),\n",
       " (26, 18.299774884470917),\n",
       " (42, 19.349184549154145),\n",
       " (88, 19.554425895227478),\n",
       " (28, 19.94585565253999),\n",
       " (34, 19.952179969342378),\n",
       " (71, 21.375042812690037),\n",
       " (63, 24.27163546006623),\n",
       " (40, 26.58197466568908)]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "mean_absolute_errors = {}\n",
    "\n",
    "for key, val in y_pred.items():\n",
    "    mean_absolute_errors[key] = mean_absolute_error(y_train, y_pred[key])\n",
    "\n",
    "sorted(mean_absolute_errors.items(), key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indecies = [key for key, value in sorted(mean_absolute_errors.items(), key = lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 50, 2):\n",
    "    nets[sorted_indecies[50 + i]].set_weights(nets[sorted_indecies[i]] + nets[sorted_indecies[i + 1]])\n",
    "    nets[sorted_indecies[50 + i + 1]].set_weights(nets[sorted_indecies[i]] + nets[sorted_indecies[i + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <__main__.Net at 0x124b8fd30>,\n",
       " 1: <__main__.Net at 0x1172a7130>,\n",
       " 2: <__main__.Net at 0x1172a7a60>,\n",
       " 3: <__main__.Net at 0x1172a7a90>,\n",
       " 4: <__main__.Net at 0x1172a7880>,\n",
       " 5: <__main__.Net at 0x1172a74c0>,\n",
       " 6: <__main__.Net at 0x1172a7640>,\n",
       " 7: <__main__.Net at 0x1172a7340>,\n",
       " 8: <__main__.Net at 0x1172a7ca0>,\n",
       " 9: <__main__.Net at 0x1172a78b0>,\n",
       " 10: <__main__.Net at 0x1172a72e0>,\n",
       " 11: <__main__.Net at 0x1172a7a30>,\n",
       " 12: <__main__.Net at 0x1172a7f40>,\n",
       " 13: <__main__.Net at 0x1172a77c0>,\n",
       " 14: <__main__.Net at 0x1172a7430>,\n",
       " 15: <__main__.Net at 0x1172a7160>,\n",
       " 16: <__main__.Net at 0x1172a7ac0>,\n",
       " 17: <__main__.Net at 0x1172a7b80>,\n",
       " 18: <__main__.Net at 0x1172a7190>,\n",
       " 19: <__main__.Net at 0x1172a71f0>,\n",
       " 20: <__main__.Net at 0x1172a7c40>,\n",
       " 21: <__main__.Net at 0x1172a7610>,\n",
       " 22: <__main__.Net at 0x1172a7490>,\n",
       " 23: <__main__.Net at 0x1172a7b20>,\n",
       " 24: <__main__.Net at 0x12732f520>,\n",
       " 25: <__main__.Net at 0x12732f640>,\n",
       " 26: <__main__.Net at 0x124df54c0>,\n",
       " 27: <__main__.Net at 0x173079310>,\n",
       " 28: <__main__.Net at 0x108e14310>,\n",
       " 29: <__main__.Net at 0x12464c520>,\n",
       " 30: <__main__.Net at 0x1099350d0>,\n",
       " 31: <__main__.Net at 0x1099352b0>,\n",
       " 32: <__main__.Net at 0x177b4efd0>,\n",
       " 33: <__main__.Net at 0x1172a7fd0>,\n",
       " 34: <__main__.Net at 0x177b4ef40>,\n",
       " 35: <__main__.Net at 0x177b4eee0>,\n",
       " 36: <__main__.Net at 0x177b4ee80>,\n",
       " 37: <__main__.Net at 0x177b4ee20>,\n",
       " 38: <__main__.Net at 0x177b4edc0>,\n",
       " 39: <__main__.Net at 0x177b4ed60>,\n",
       " 40: <__main__.Net at 0x177b4ed00>,\n",
       " 41: <__main__.Net at 0x177b4eca0>,\n",
       " 42: <__main__.Net at 0x177b4ec40>,\n",
       " 43: <__main__.Net at 0x177b4ebe0>,\n",
       " 44: <__main__.Net at 0x177b4eb80>,\n",
       " 45: <__main__.Net at 0x177b4eb20>,\n",
       " 46: <__main__.Net at 0x177b4eac0>,\n",
       " 47: <__main__.Net at 0x177b4ea60>,\n",
       " 48: <__main__.Net at 0x177b4ea00>,\n",
       " 49: <__main__.Net at 0x177b4e970>,\n",
       " 50: <__main__.Net at 0x177b4e910>,\n",
       " 51: <__main__.Net at 0x177b4e8b0>,\n",
       " 52: <__main__.Net at 0x177b4e850>,\n",
       " 53: <__main__.Net at 0x177b4e7f0>,\n",
       " 54: <__main__.Net at 0x177b4e880>,\n",
       " 55: <__main__.Net at 0x177b4e7c0>,\n",
       " 56: <__main__.Net at 0x177b4e760>,\n",
       " 57: <__main__.Net at 0x177b4e700>,\n",
       " 58: <__main__.Net at 0x177b4e6a0>,\n",
       " 59: <__main__.Net at 0x177b4e640>,\n",
       " 60: <__main__.Net at 0x177b4e5e0>,\n",
       " 61: <__main__.Net at 0x177b4e580>,\n",
       " 62: <__main__.Net at 0x177b4e520>,\n",
       " 63: <__main__.Net at 0x177b4e4c0>,\n",
       " 64: <__main__.Net at 0x177b4e460>,\n",
       " 65: <__main__.Net at 0x177b4e400>,\n",
       " 66: <__main__.Net at 0x177b4e3a0>,\n",
       " 67: <__main__.Net at 0x177b4e340>,\n",
       " 68: <__main__.Net at 0x177b4e2e0>,\n",
       " 69: <__main__.Net at 0x177b4e280>,\n",
       " 70: <__main__.Net at 0x177b4e220>,\n",
       " 71: <__main__.Net at 0x177b4e1c0>,\n",
       " 72: <__main__.Net at 0x177b4e160>,\n",
       " 73: <__main__.Net at 0x177b4e100>,\n",
       " 74: <__main__.Net at 0x177b4e0a0>,\n",
       " 75: <__main__.Net at 0x177b689a0>,\n",
       " 76: <__main__.Net at 0x177b68880>,\n",
       " 77: <__main__.Net at 0x177b688b0>,\n",
       " 78: <__main__.Net at 0x177b68ee0>,\n",
       " 79: <__main__.Net at 0x177b68af0>,\n",
       " 80: <__main__.Net at 0x177b68d00>,\n",
       " 81: <__main__.Net at 0x177b68e20>,\n",
       " 82: <__main__.Net at 0x177b68bb0>,\n",
       " 83: <__main__.Net at 0x177b686d0>,\n",
       " 84: <__main__.Net at 0x177b686a0>,\n",
       " 85: <__main__.Net at 0x177b68fd0>,\n",
       " 86: <__main__.Net at 0x177b68e80>,\n",
       " 87: <__main__.Net at 0x177b68dc0>,\n",
       " 88: <__main__.Net at 0x177b68df0>,\n",
       " 89: <__main__.Net at 0x177b68e50>,\n",
       " 90: <__main__.Net at 0x177b68ca0>,\n",
       " 91: <__main__.Net at 0x177b68220>,\n",
       " 92: <__main__.Net at 0x177b68760>,\n",
       " 93: <__main__.Net at 0x177b68280>,\n",
       " 94: <__main__.Net at 0x177b68160>,\n",
       " 95: <__main__.Net at 0x177b689d0>,\n",
       " 96: <__main__.Net at 0x177b68c10>,\n",
       " 97: <__main__.Net at 0x177b68610>,\n",
       " 98: <__main__.Net at 0x177b68310>,\n",
       " 99: <__main__.Net at 0x177b680a0>}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:\n",
      "[[ 1.01141353  0.59439883  2.48992079  2.61471638  0.62638202  2.69678376\n",
      "   2.12467107 -2.08143074 -0.99704453]\n",
      " [ 1.69273425  2.79238673 -2.07940654 -0.49092017  2.53171742  1.21999845\n",
      "  -1.66557484 -0.91857742 -2.53727033]\n",
      " [-2.56355303  1.83312715  0.36393581  0.60095031  2.25051084  0.15950237\n",
      "  -1.35255909 -2.18080927  2.47436216]\n",
      " [ 2.75606031 -0.51835822 -1.72285361 -1.97056082  1.91750731  1.63360665\n",
      "  -2.64452141  0.66256034 -1.33917763]\n",
      " [ 2.78141777  1.05032572 -2.99858409 -1.42582331 -2.41039882 -2.75059707\n",
      "  -2.81757409  1.9266409   1.96677018]\n",
      " [-2.09929284 -1.64321933  1.14075824  2.84691465 -2.54790964  2.11504108\n",
      "  -0.47742486 -0.38993603 -2.57094584]\n",
      " [-1.65334927  2.60942522  2.80814622  0.79735112  1.32344189  2.32049636\n",
      "  -0.61176893 -1.57210467  1.91872534]\n",
      " [-2.42960183 -2.77708815 -2.52965422 -2.95915083  2.87601371 -2.64246996\n",
      "   1.77848161  0.77945629  0.52483674]\n",
      " [-2.01259865 -2.96664431 -2.3507265  -1.38623225 -2.00524195 -2.01563223\n",
      "  -1.94450233 -1.88545378 -1.33226489]]\n",
      "w2:\n",
      "[[-0.12169856]\n",
      " [ 0.99886781]\n",
      " [-0.94426417]\n",
      " [ 1.98057719]\n",
      " [-0.93134645]\n",
      " [-0.21665011]\n",
      " [ 1.6883081 ]\n",
      " [ 1.510752  ]\n",
      " [ 2.48743331]]\n",
      "b1:\n",
      "[[-1.86118536]\n",
      " [ 0.14225395]\n",
      " [-0.88837784]\n",
      " [ 2.3004443 ]\n",
      " [ 0.31156636]\n",
      " [-2.00766722]\n",
      " [-0.88842182]\n",
      " [ 2.15347683]\n",
      " [-0.22800856]]\n",
      "b2:\n",
      "[2.3079107] w1:\n",
      "[[-1.75445887 -1.48616252 -2.01784539  0.24125919 -2.4322891   0.10196102\n",
      "  -0.30277341  0.09170581 -2.21231813]\n",
      " [-0.27321279 -2.74933983  2.01461812 -2.61051754 -2.85506105 -1.46520655\n",
      "   0.16367043  2.31436456 -1.57779765]\n",
      " [-2.22914909  1.69767396  2.49681121  1.67829843 -2.51788536 -0.95095725\n",
      "   2.41548557  2.61933954  0.96969159]\n",
      " [-1.09291989 -0.99003597  0.5149173   2.81167017 -2.27757854 -0.39558841\n",
      "   2.8134218   2.81563138 -0.34684446]\n",
      " [ 0.27037592  0.63467384 -2.01154204  2.43156248  2.06758313 -2.00481998\n",
      "  -1.89153212 -2.89384502 -2.62103042]\n",
      " [ 1.61247653 -2.5805259   1.99465453 -1.35414995  1.50650427  0.1537809\n",
      "   2.8350938   2.28027872 -0.63678026]\n",
      " [-0.51132916  1.35364822  2.85102026 -2.55790824  0.317455    2.85004347\n",
      "  -2.15650001 -0.72086666  1.71477782]\n",
      " [ 0.68745268 -0.09877512  0.52360542  1.3969107   0.9743857  -0.47530361\n",
      "  -0.7285572  -1.62007346  1.12061299]\n",
      " [-2.99835834 -2.1391275  -0.44159036 -1.08929985 -0.23385039  0.25772084\n",
      "   1.68605517  0.40408938 -1.21000826]]\n",
      "w2:\n",
      "[[ 2.35169626]\n",
      " [ 1.5092747 ]\n",
      " [ 0.66028639]\n",
      " [-1.65230564]\n",
      " [-0.90931923]\n",
      " [ 1.21034965]\n",
      " [ 1.77715147]\n",
      " [ 2.89151595]\n",
      " [ 0.18947615]]\n",
      "b1:\n",
      "[[-2.34213834]\n",
      " [ 1.73526995]\n",
      " [-1.16544951]\n",
      " [-1.85200684]\n",
      " [ 1.0865519 ]\n",
      " [ 0.31518092]\n",
      " [ 0.64702652]\n",
      " [-1.29204213]\n",
      " [-1.29755685]]\n",
      "b2:\n",
      "[2.16007248]\n",
      "(array([[-0.37152267, -0.44588185,  0.2360377 ,  1.42798779, -0.90295354,\n",
      "         1.39937239,  0.91094883, -0.99486246, -1.60468133],\n",
      "       [ 0.70976073,  0.02152345, -0.03239421, -1.55071885, -0.16167182,\n",
      "        -0.12260405, -0.75095221,  0.69789357, -2.05753399],\n",
      "       [-2.39635106,  1.76540056,  1.43037351,  1.13962437, -0.13368726,\n",
      "        -0.39572744,  0.53146324,  0.21926513,  1.72202688],\n",
      "       [ 0.83157021, -0.75419709, -0.60396815,  0.42055468, -0.18003561,\n",
      "         0.61900912,  0.0844502 ,  1.73909586, -0.84301104],\n",
      "       [ 1.52589684,  0.84249978, -2.50506307,  0.50286958, -0.17140785,\n",
      "        -2.37770852, -2.3545531 , -0.48360206, -0.32713012],\n",
      "       [-0.24340816, -2.11187262,  1.56770638,  0.74638235, -0.52070268,\n",
      "         1.13441099,  1.17883447,  0.94517134, -1.60386305],\n",
      "       [-1.08233922,  1.98153672,  2.82958324, -0.88027856,  0.82044845,\n",
      "         2.58526992, -1.38413447, -1.14648567,  1.81675158],\n",
      "       [-0.87107457, -1.43793164, -1.0030244 , -0.78112006,  1.9251997 ,\n",
      "        -1.55888679,  0.52496221, -0.42030859,  0.82272486],\n",
      "       [-2.5054785 , -2.55288591, -1.39615843, -1.23776605, -1.11954617,\n",
      "        -0.8789557 , -0.12922358, -0.7406822 , -1.27113657]]), array([[ 1.11499885],\n",
      "       [ 1.25407126],\n",
      "       [-0.14198889],\n",
      "       [ 0.16413577],\n",
      "       [-0.92033284],\n",
      "       [ 0.49684977],\n",
      "       [ 1.73272979],\n",
      "       [ 2.20113398],\n",
      "       [ 1.33845473]]), array([[-2.10166185],\n",
      "       [ 0.93876195],\n",
      "       [-1.02691367],\n",
      "       [ 0.22421873],\n",
      "       [ 0.69905913],\n",
      "       [-0.84624315],\n",
      "       [-0.12069765],\n",
      "       [ 0.43071735],\n",
      "       [-0.76278271]]), array([2.23399159]))\n"
     ]
    }
   ],
   "source": [
    "print(nets[sorted_indecies[0]], nets[sorted_indecies[1]]) \n",
    "print(nets[sorted_indecies[50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2\n",
    "\n",
    "n - n % 2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
