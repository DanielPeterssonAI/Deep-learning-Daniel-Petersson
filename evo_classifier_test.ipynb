{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "folder = \"kaggle-cardio/\"\n",
    "cardio_file = \"cardio_train.csv\"\n",
    "\n",
    "df_cardio = pd.read_csv(f\"{folder}{cardio_file}\", sep = \";\")\n",
    "\n",
    "df_cardio[\"bmi\"] = df_cardio[\"weight\"] / (df_cardio[\"height\"] / 100) ** 2\n",
    "\n",
    "def plot_column(df, col_name, min, max):\n",
    "    return df[(df[col_name] > min) & (df[col_name] < max)]\n",
    "\n",
    "df_cardio = plot_column(df_cardio, \"bmi\", min = 15, max = 50)\n",
    "\n",
    "df_cardio[\"bmi_category\"] = pd.cut(\n",
    "    df_cardio[\"bmi\"], \n",
    "    bins = [0, 25, 30, 35, 40, 1000], \n",
    "    labels = [\"Normal\", \"Overweight\", \"Obese (Class I)\", \"Obese (Class II)\", \"Obese (Class III)\"], \n",
    "    right = False\n",
    ")\n",
    "\n",
    "df_cardio = plot_column(df_cardio, \"ap_hi\", min = 75, max = 200)\n",
    "\n",
    "df_cardio = plot_column(df_cardio, \"ap_lo\", min = 50, max = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_categorizer(hi, lo):\n",
    "    '''ap_categorizer() takes blood two pressure values as arguments and returns the blood pressure category'''\n",
    "\n",
    "    if hi >= 180 or lo >= 120: return \"Hypertension crisis\"\n",
    "    if hi >= 140 or lo >= 90: return \"Stage 2 hypertension\"\n",
    "    if hi < 120 and lo < 80: return \"Healthy\"\n",
    "    if hi < 130 and lo < 80: return \"Elevated\"\n",
    "    return \"Stage 1 hypertension\"\n",
    "\n",
    "df_cardio[\"ap_category\"] = df_cardio.apply(lambda x: ap_categorizer(x[\"ap_hi\"], x[\"ap_lo\"]), axis = 1).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.967120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.011177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  cardio  \\\n",
       "0   0  18393    110     80            1     1      0     0       1       0   \n",
       "1   1  20228    140     90            3     1      0     0       1       1   \n",
       "2   2  18857    130     70            3     1      0     0       0       1   \n",
       "3   3  17623    150    100            1     1      0     0       1       1   \n",
       "4   4  17474    100     60            1     1      0     0       0       0   \n",
       "\n",
       "         bmi  gender_2  \n",
       "0  21.967120         1  \n",
       "1  34.927679         0  \n",
       "2  23.507805         0  \n",
       "3  28.710479         1  \n",
       "4  23.011177         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cardio_first = df_cardio.drop([\"ap_hi\", \"ap_lo\", \"height\", \"weight\", \"bmi\"], axis = 1)\n",
    "df_cardio_first = pd.get_dummies(df_cardio_first, columns = [\"bmi_category\", \"ap_category\", \"gender\"], drop_first = True)\n",
    "\n",
    "df_cardio_second = df_cardio.drop([\"bmi_category\", \"ap_category\", \"height\", \"weight\"], axis = 1)\n",
    "df_cardio_second = pd.get_dummies(df_cardio_second, columns = [\"gender\"], drop_first = True)\n",
    "\n",
    "df_cardio_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34130, 10), (17065, 10), (17065, 10), (34130,), (17065,), (17065,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tvt_split(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.5, random_state = 42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = tvt_split(df_cardio_first.drop([\"id\", \"cardio\"], axis = 1), df_cardio_first[\"cardio\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = tvt_split(df_cardio_second.drop([\"id\", \"cardio\"], axis = 1), df_cardio_second[\"cardio\"])\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from evolutionary_algos import EvoMLPClassifier\n",
    "#classifier = EvoMLPClassifier(n = 48, hidden_layers = [8], activation = \"relu\", random_state = 42)\n",
    "#classifier.fit(scaled_X_train, y_train, epochs = 1000, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvoMLPClassifier:\n",
    "    '''LATEST VERSION, TESTED WITH MULTICLASS AND BINARY'''\n",
    "\n",
    "    def __init__(self, n = 24, hidden_layers = False, activation = \"relu\", lr_target = 0.04, lr_initial_decay = 60, lr_final_decay = 0.03, random_state = None):\n",
    "\n",
    "        self.n = int(round(n / 8) * 8)\n",
    "        self.validation_loss_history = []\n",
    "        self.training_loss_history = []\n",
    "        self.random_state = random_state\n",
    "        self.activation = activation\n",
    "        self.lr_target = lr_target\n",
    "        self.lr_initial_decay = lr_initial_decay\n",
    "        self.lr_final_decay = lr_final_decay\n",
    "\n",
    "        \n",
    "        if hidden_layers:\n",
    "            self.hidden_layers = hidden_layers\n",
    "        else:\n",
    "            self.hidden_layers = False\n",
    "\n",
    "        \n",
    "\n",
    "    def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0):\n",
    "\n",
    "        n = self.n\n",
    "        ndiv4 = n // 4\n",
    "\n",
    "        if self.random_state != None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "        y_train = y_train.astype(\"int8\")\n",
    "\n",
    "        if len(y_train.shape) == 1:\n",
    "            self.multiclass = False\n",
    "        elif len(y_train.shape) == 2 and y_train.shape[1] == 1:\n",
    "            self.multiclass = False\n",
    "            y_train = y_train.ravel()\n",
    "        else:\n",
    "            self.multiclass = True\n",
    "            \n",
    "\n",
    "        if validation_data:\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == \"leaky_relu\":\n",
    "            activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        else:\n",
    "            activation_function = lambda x: np.maximum(0, x)\n",
    "\n",
    "        if self.multiclass == True:\n",
    "            output_activation_function = lambda x: np.exp(x) / np.sum(np.exp(x), axis = 2, keepdims = True)\n",
    "            \n",
    "            def loss_function(y_train, y_preds):\n",
    "                return np.mean(np.sum(-y_train * np.log10(y_preds), axis = 2), axis = 1)\n",
    "\n",
    "        elif self.multiclass == False:\n",
    "            output_activation_function = lambda x: (1 / (1 + np.exp(-x))).reshape(x.shape[:2])\n",
    "\n",
    "            def loss_function(y_train, y_preds):\n",
    "                return np.mean(np.abs(y_preds - y_train), axis = 1)\n",
    "\n",
    "        lr_target = self.lr_target\n",
    "        lr_initial_decay = self.lr_initial_decay\n",
    "        lr_final_decay = self.lr_final_decay\n",
    "\n",
    "        layers = [X_train.shape[1]]\n",
    "\n",
    "        if self.hidden_layers:\n",
    "            layers = [X_train.shape[1]] + self.hidden_layers\n",
    "\n",
    "        if self.multiclass == True:\n",
    "            layers = layers + [y_train.shape[1]]\n",
    "        elif self.multiclass == False:\n",
    "            layers = layers + [1]\n",
    "\n",
    "        number_of_layers_minus_one = len(layers) - 1\n",
    "        \n",
    "        if self.multiclass == True:\n",
    "            y_preds = np.zeros((n, y_train.shape[0], y_train.shape[1]))\n",
    "            #y_preds = np.zeros((n, 1000, y_train.shape[1]))\n",
    "        elif self.multiclass == False:\n",
    "            y_preds = np.zeros((n, y_train.shape[0]))\n",
    "            #y_preds = np.zeros((n, 1000))\n",
    "\n",
    "        nets_loss = np.zeros(n)\n",
    "        sorted_indices = np.arange(-(ndiv4), n, 1)\n",
    "        sorted_indices = np.arange(0, n, 1)\n",
    "\n",
    "        best_net_index = -1\n",
    "\n",
    "        weights = []\n",
    "\n",
    "        for i in range(number_of_layers_minus_one):\n",
    "            weights += [np.random.normal(0, 1, (n, layers[i], layers[i + 1]))]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            sample_indices = np.arange(0, X_train.shape[0])\n",
    "            np.random.shuffle(sample_indices)\n",
    "\n",
    "            while len(sample_indices) > 0:\n",
    "                forward_pass = X_train[sample_indices[:1000]].T\n",
    "                y_train_sampled = y_train[sample_indices[:1000]]\n",
    "\n",
    "                \n",
    "                for j in range(number_of_layers_minus_one - 1):\n",
    "                    forward_pass = activation_function(weights[j].transpose(0, 2, 1) @ forward_pass)\n",
    "                \n",
    "                forward_pass = weights[-1].transpose(0, 2, 1) @ forward_pass\n",
    "\n",
    "                #print(y_preds[sorted_indices[ndiv4:], sample_indices[:1000]].shape)\n",
    "                \n",
    "                y_preds[:, sample_indices[:1000]] = output_activation_function(forward_pass.transpose(0, 2, 1))\n",
    "\n",
    "                nets_loss = loss_function(y_train_sampled, y_preds[:, sample_indices[:1000]])\n",
    "\n",
    "                sorted_indices = np.argsort(nets_loss)\n",
    "                mutation_sigma = math.exp(-epoch / (epochs / (lr_initial_decay * math.log10(epochs + 1)))) + lr_final_decay * math.exp(-(epoch + 1) * (1 / (epochs))) + lr_target + (-0.036 * 10 * lr_final_decay)\n",
    "\n",
    "                for j in range(number_of_layers_minus_one):\n",
    "                    weights[j][sorted_indices[0 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indices[1 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indices[2 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indices[3 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indices[4 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indices[5 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "\n",
    "                if best_net_index != sorted_indices[0]:\n",
    "                    best_net_index = sorted_indices[0]\n",
    "                    self.training_loss_history += [nets_loss[best_net_index]]\n",
    "                    \n",
    "\n",
    "                    self.best_net_weights = []\n",
    "                    for j in range(number_of_layers_minus_one):\n",
    "                        self.best_net_weights += [weights[j][best_net_index]]\n",
    "                    \n",
    "                    if validation_data:\n",
    "                        self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
    "                        if verbose == 1:\n",
    "                            print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]}\")\n",
    "                    else:\n",
    "                        if verbose == 1:\n",
    "                            pass\n",
    "                            print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - {mutation_sigma}\")\n",
    "\n",
    "                sample_indices = sample_indices[1000:]\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == \"leaky_relu\":\n",
    "            activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        else:\n",
    "            activation_function = lambda x: np.maximum(0, x)\n",
    "\n",
    "        if self.multiclass == True:\n",
    "            output_activation_function = lambda x: np.exp(x) / np.sum(np.exp(x), axis = 1, keepdims = True)\n",
    "\n",
    "        elif self.multiclass == False:\n",
    "            output_activation_function = lambda x: (1 / (1 + np.exp(-x))).reshape(x.shape[:1])\n",
    "\n",
    "        forward_pass = X.T\n",
    "\n",
    "        for j in range(len(self.best_net_weights) - 1):\n",
    "            forward_pass = activation_function(self.best_net_weights[j].T @ forward_pass)\n",
    "            \n",
    "        forward_pass = self.best_net_weights[-1].T @ forward_pass\n",
    "            \n",
    "        return output_activation_function(forward_pass.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 0.37918163750230066 - val_loss: 0.38968283210568444\n",
      "Epoch 0 - loss: 0.3519839442170109 - val_loss: 0.3501530197326706\n",
      "Epoch 0 - loss: 0.33279584255532146 - val_loss: 0.3324322576935052\n",
      "Epoch 0 - loss: 0.2922150658986911 - val_loss: 0.30791141544493716\n",
      "Epoch 0 - loss: 0.28645695804593657 - val_loss: 0.30765297120692775\n",
      "Epoch 0 - loss: 0.2996603578308702 - val_loss: 0.2981230259940363\n",
      "Epoch 0 - loss: 0.30514945433121515 - val_loss: 0.31276338226139117\n",
      "Epoch 0 - loss: 0.2930353101765562 - val_loss: 0.2923143775670306\n",
      "Epoch 0 - loss: 0.281672150383948 - val_loss: 0.29700094365034746\n",
      "Epoch 0 - loss: 0.30003666584323574 - val_loss: 0.29388858936023643\n",
      "Epoch 0 - loss: 0.29964267816099965 - val_loss: 0.28625551335222443\n",
      "Epoch 0 - loss: 0.2674351881316396 - val_loss: 0.2900736682557648\n",
      "Epoch 0 - loss: 0.2745440291181876 - val_loss: 0.2968510658322562\n",
      "Epoch 0 - loss: 0.2781774025163572 - val_loss: 0.28807678873297016\n",
      "Epoch 0 - loss: 0.2685763619150532 - val_loss: 0.28625551335222443\n",
      "Epoch 0 - loss: 0.29003115209444413 - val_loss: 0.2894492171642593\n",
      "Epoch 0 - loss: 0.2639036780212844 - val_loss: 0.28628352650965105\n",
      "Epoch 0 - loss: 0.2707508484967183 - val_loss: 0.282482371035373\n",
      "Epoch 0 - loss: 0.2539895205962302 - val_loss: 0.28287880324623405\n",
      "Epoch 0 - loss: 0.27100689473657114 - val_loss: 0.28855500994424316\n",
      "Epoch 0 - loss: 0.28346236512023454 - val_loss: 0.2879121470533482\n",
      "Epoch 0 - loss: 0.26460230426822196 - val_loss: 0.2857643529423701\n",
      "Epoch 0 - loss: 0.27091239759584196 - val_loss: 0.2853792650552579\n",
      "Epoch 0 - loss: 0.2630182093408464 - val_loss: 0.2810971057964949\n",
      "Epoch 0 - loss: 0.23917658944958425 - val_loss: 0.2779553579341359\n",
      "Epoch 0 - loss: 0.2602485851970723 - val_loss: 0.27942070156421156\n",
      "Epoch 0 - loss: 0.2767075024634097 - val_loss: 0.27732788370361877\n",
      "Epoch 0 - loss: 0.2698173940136614 - val_loss: 0.2792334786157807\n",
      "Epoch 0 - loss: 0.23667613471649224 - val_loss: 0.2780312243191577\n",
      "Epoch 1 - loss: 0.2656675990490642 - val_loss: 0.2842172502968205\n",
      "Epoch 1 - loss: 0.2663653636657069 - val_loss: 0.2809103427818408\n",
      "Epoch 1 - loss: 0.2803423697560404 - val_loss: 0.2752114186108297\n",
      "Epoch 1 - loss: 0.2560600408270202 - val_loss: 0.2779725435568007\n",
      "Epoch 1 - loss: 0.27998758134263785 - val_loss: 0.2757979468834762\n",
      "Epoch 1 - loss: 0.2302974584213063 - val_loss: 0.27733569615158676\n",
      "Epoch 1 - loss: 0.2510667876448391 - val_loss: 0.2770810870019398\n",
      "Epoch 1 - loss: 0.25056008117117157 - val_loss: 0.2777703713429361\n",
      "Epoch 1 - loss: 0.2552773595864814 - val_loss: 0.2782671031047695\n",
      "Epoch 1 - loss: 0.2634887721360746 - val_loss: 0.279843834157614\n",
      "Epoch 1 - loss: 0.27586161519115937 - val_loss: 0.27589081321468373\n",
      "Epoch 1 - loss: 0.2672189143055159 - val_loss: 0.27981783527785486\n",
      "Epoch 1 - loss: 0.2560473721646794 - val_loss: 0.2769602376778039\n",
      "Epoch 1 - loss: 0.2658182102035169 - val_loss: 0.28082919267156736\n",
      "Epoch 1 - loss: 0.2542176573242294 - val_loss: 0.2782406465052268\n",
      "Epoch 1 - loss: 0.2887845397806337 - val_loss: 0.2775211836349971\n",
      "Epoch 1 - loss: 0.27655694417523174 - val_loss: 0.2782563366339525\n",
      "Epoch 1 - loss: 0.25718836500049674 - val_loss: 0.2779924313161955\n",
      "Epoch 1 - loss: 0.2578005377002552 - val_loss: 0.27625464915540476\n",
      "Epoch 1 - loss: 0.26471099460402064 - val_loss: 0.2826552692512987\n",
      "Epoch 1 - loss: 0.2675676676872934 - val_loss: 0.2761352045175285\n",
      "Epoch 1 - loss: 0.2680141370649452 - val_loss: 0.27625464915540476\n",
      "Epoch 1 - loss: 0.26921796475279025 - val_loss: 0.28311145398931203\n",
      "Epoch 1 - loss: 0.2619236139534242 - val_loss: 0.2799552574079331\n",
      "Epoch 1 - loss: 0.268801820643479 - val_loss: 0.27903261009153213\n",
      "Epoch 1 - loss: 0.26939801862572754 - val_loss: 0.27645535456853954\n",
      "Epoch 1 - loss: 0.2584467080348227 - val_loss: 0.2770157618022174\n",
      "Epoch 1 - loss: 0.26753458203364505 - val_loss: 0.28026832811855484\n",
      "Epoch 1 - loss: 0.2653877967074712 - val_loss: 0.27469620015623625\n",
      "Epoch 1 - loss: 0.26663918504287026 - val_loss: 0.2808504654826901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/f2gwbn5n3vs4pz044n49z3cw0000gn/T/ipykernel_89777/1840960108.py:60: RuntimeWarning: overflow encountered in exp\n",
      "  output_activation_function = lambda x: (1 / (1 + np.exp(-x))).reshape(x.shape[:2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 0.28268308034656303 - val_loss: 0.27379052706488216\n",
      "Epoch 1 - loss: 0.2672524983210719 - val_loss: 0.27261064662707785\n",
      "Epoch 1 - loss: 0.24481621414556 - val_loss: 0.2730890514293234\n",
      "Epoch 1 - loss: 0.2574780710812591 - val_loss: 0.27423161045944017\n",
      "Epoch 1 - loss: 0.1919595432991132 - val_loss: 0.2741576625140119\n",
      "Epoch 2 - loss: 0.2645567263767943 - val_loss: 0.2754563013381908\n",
      "Epoch 2 - loss: 0.26404371617590333 - val_loss: 0.2737883509436602\n",
      "Epoch 2 - loss: 0.2564201309139382 - val_loss: 0.2723609448278085\n",
      "Epoch 2 - loss: 0.2525211945037178 - val_loss: 0.2741773205656172\n",
      "Epoch 2 - loss: 0.24425699434262196 - val_loss: 0.2752825145093881\n",
      "Epoch 2 - loss: 0.2722379680505043 - val_loss: 0.2767985250575517\n",
      "Epoch 2 - loss: 0.26310924417022435 - val_loss: 0.27832354503703155\n",
      "Epoch 2 - loss: 0.283278396522973 - val_loss: 0.2774794108317614\n",
      "Epoch 2 - loss: 0.2533283505996998 - val_loss: 0.27411619545175475\n",
      "Epoch 2 - loss: 0.2819624422449374 - val_loss: 0.2757673719720599\n",
      "Epoch 2 - loss: 0.2613438393577253 - val_loss: 0.27518182125332\n",
      "Epoch 2 - loss: 0.2623349183349693 - val_loss: 0.2701525106363105\n",
      "Epoch 2 - loss: 0.27234042919128154 - val_loss: 0.27518182125332\n",
      "Epoch 2 - loss: 0.22180227792727739 - val_loss: 0.2740017352307045\n",
      "Epoch 2 - loss: 0.27475210217713925 - val_loss: 0.27366921019766355\n",
      "Epoch 2 - loss: 0.2743084172168754 - val_loss: 0.27377057963913937\n",
      "Epoch 2 - loss: 0.2497529524832144 - val_loss: 0.27471649943907384\n",
      "Epoch 2 - loss: 0.2655790281108258 - val_loss: 0.272108179753282\n",
      "Epoch 2 - loss: 0.2300473413168472 - val_loss: 0.27421977910038253\n",
      "Epoch 2 - loss: 0.25497380797291597 - val_loss: 0.27349621829235027\n",
      "Epoch 2 - loss: 0.2720455375295447 - val_loss: 0.27523665207575493\n",
      "Epoch 2 - loss: 0.24761096204467023 - val_loss: 0.27450030002069054\n",
      "Epoch 2 - loss: 0.27579884126444637 - val_loss: 0.2738447071958265\n",
      "Epoch 2 - loss: 0.26679532907163817 - val_loss: 0.273980977732359\n",
      "Epoch 2 - loss: 0.27415512141222065 - val_loss: 0.27982707046611166\n",
      "Epoch 2 - loss: 0.23860700292399786 - val_loss: 0.27611824571223126\n",
      "Epoch 2 - loss: 0.2661416291744327 - val_loss: 0.27999961227646386\n",
      "Epoch 2 - loss: 0.2642018352753909 - val_loss: 0.2753593550471157\n",
      "Epoch 2 - loss: 0.2523789696986409 - val_loss: 0.2758978342539493\n",
      "Epoch 2 - loss: 0.2626917196831343 - val_loss: 0.2753042761612896\n",
      "Epoch 2 - loss: 0.2636587738955831 - val_loss: 0.27618957915165987\n",
      "Epoch 2 - loss: 0.27072125922782975 - val_loss: 0.2734050709133159\n",
      "Epoch 2 - loss: 0.27108950124285625 - val_loss: 0.27309117471504596\n",
      "Epoch 2 - loss: 0.26921325893434644 - val_loss: 0.27455106020665954\n",
      "Epoch 2 - loss: 0.2575389604092507 - val_loss: 0.2768787708297824\n",
      "Epoch 3 - loss: 0.2495483581137613 - val_loss: 0.27295269195032457\n",
      "Epoch 3 - loss: 0.2608361283928121 - val_loss: 0.27127430843239614\n",
      "Epoch 3 - loss: 0.25345958963045856 - val_loss: 0.271411785030224\n",
      "Epoch 3 - loss: 0.2762863919970814 - val_loss: 0.2731404638182632\n",
      "Epoch 3 - loss: 0.25714862408312067 - val_loss: 0.27367282375100427\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb#ch0000005?line=0'>1</a>\u001b[0m classifier \u001b[39m=\u001b[39m EvoMLPClassifier(n \u001b[39m=\u001b[39m \u001b[39m48\u001b[39m, hidden_layers \u001b[39m=\u001b[39m [\u001b[39m8\u001b[39m], activation \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m, random_state \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb#ch0000005?line=1'>2</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(scaled_X_train, y_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (scaled_X_val, y_val), verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb Cell 7'\u001b[0m in \u001b[0;36mEvoMLPClassifier.fit\u001b[0;34m(self, X_train, y_train, epochs, validation_data, verbose)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb#ch0000010?line=104'>105</a>\u001b[0m y_train_sampled \u001b[39m=\u001b[39m y_train[sample_indices[:\u001b[39m1000\u001b[39m]]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb#ch0000010?line=107'>108</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_of_layers_minus_one \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb#ch0000010?line=108'>109</a>\u001b[0m     forward_pass \u001b[39m=\u001b[39m activation_function(weights[j]\u001b[39m.\u001b[39;49mtranspose(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m) \u001b[39m@\u001b[39;49m forward_pass)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb#ch0000010?line=110'>111</a>\u001b[0m forward_pass \u001b[39m=\u001b[39m weights[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m@\u001b[39m forward_pass\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb#ch0000010?line=112'>113</a>\u001b[0m \u001b[39m#print(y_preds[sorted_indices[ndiv4:], sample_indices[:1000]].shape)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = EvoMLPClassifier(n = 48, hidden_layers = [8], activation = \"relu\", random_state = 42)\n",
    "classifier.fit(scaled_X_train, y_train, epochs = 1000, validation_data = (scaled_X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      8683\n",
      "           1       0.73      0.71      0.72      8382\n",
      "\n",
      "    accuracy                           0.73     17065\n",
      "   macro avg       0.73      0.73      0.73     17065\n",
      "weighted avg       0.73      0.73      0.73     17065\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = classifier.predict(scaled_X_test)\n",
    "y_pred = (y_pred > 0.5) * 1\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [1, 3],\n",
       "       [3, 4],\n",
       "       [1, 1],\n",
       "       [3, 2],\n",
       "       [3, 3],\n",
       "       [3, 3],\n",
       "       [4, 1],\n",
       "       [4, 4],\n",
       "       [4, 3]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "a = np.random.randint(1, 5, (10, 2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(0, a.shape[0])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 0, 6, 7, 9, 3, 1, 4, 5])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(b)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 0])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = b[:4]\n",
    "k[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 1, 4, 0]),\n",
       " array([[4, 1],\n",
       "        [1, 3],\n",
       "        [3, 2],\n",
       "        [3, 4]]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, a[b[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.delete(b, [0, 1, 2], axis = 0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = k[2:]\n",
    "k.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 3, 7, 4, 6, 9, 2, 6, 7, 4],\n",
       "       [3, 7, 7, 2, 5, 4, 1, 7, 5, 1],\n",
       "       [4, 0, 9, 5, 8, 0, 9, 2, 6, 3],\n",
       "       [8, 2, 4, 2, 6, 4, 8, 6, 1, 3],\n",
       "       [8, 1, 9, 8, 9, 4, 1, 3, 6, 7],\n",
       "       [2, 0, 3, 1, 7, 3, 1, 5, 5, 9],\n",
       "       [3, 5, 1, 9, 1, 9, 3, 7, 6, 8],\n",
       "       [7, 4, 1, 4, 7, 9, 8, 8, 0, 8],\n",
       "       [6, 8, 7, 0, 7, 7, 2, 0, 7, 2],\n",
       "       [2, 0, 4, 9, 6, 9, 8, 6, 8, 7]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "a = np.random.randint(0, 10, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 2],\n",
       "       [0, 9, 5],\n",
       "       [2, 4, 2]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a[[1,2,3]][:,[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_classifier_test.ipynb#ch0000022?line=0'>1</a>\u001b[0m a[[\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m],:[\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m]]\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "a[[1, 2, 3],:[1, 2, 3]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
