{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import recall_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "folder = \"kaggle-cardio/\"\n",
    "cardio_file = \"cardio_train.csv\"\n",
    "\n",
    "df_cardio = pd.read_csv(f\"{folder}{cardio_file}\", sep = \";\")\n",
    "\n",
    "df_cardio[\"bmi\"] = df_cardio[\"weight\"] / (df_cardio[\"height\"] / 100) ** 2\n",
    "\n",
    "def plot_column(df, col_name, min, max):\n",
    "    return df[(df[col_name] > min) & (df[col_name] < max)]\n",
    "\n",
    "df_cardio = plot_column(df_cardio, \"bmi\", min = 15, max = 50)\n",
    "\n",
    "df_cardio[\"bmi_category\"] = pd.cut(\n",
    "    df_cardio[\"bmi\"], \n",
    "    bins = [0, 25, 30, 35, 40, 1000], \n",
    "    labels = [\"Normal\", \"Overweight\", \"Obese (Class I)\", \"Obese (Class II)\", \"Obese (Class III)\"], \n",
    "    right = False\n",
    ")\n",
    "\n",
    "df_cardio = plot_column(df_cardio, \"ap_hi\", min = 75, max = 200)\n",
    "\n",
    "df_cardio = plot_column(df_cardio, \"ap_lo\", min = 50, max = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_categorizer(hi, lo):\n",
    "    '''ap_categorizer() takes blood two pressure values as arguments and returns the blood pressure category'''\n",
    "\n",
    "    if hi >= 180 or lo >= 120: return \"Hypertension crisis\"\n",
    "    if hi >= 140 or lo >= 90: return \"Stage 2 hypertension\"\n",
    "    if hi < 120 and lo < 80: return \"Healthy\"\n",
    "    if hi < 130 and lo < 80: return \"Elevated\"\n",
    "    return \"Stage 1 hypertension\"\n",
    "\n",
    "df_cardio[\"ap_category\"] = df_cardio.apply(lambda x: ap_categorizer(x[\"ap_hi\"], x[\"ap_lo\"]), axis = 1).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>gender_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.967120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.011177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  cardio  \\\n",
       "0   0  18393    110     80            1     1      0     0       1       0   \n",
       "1   1  20228    140     90            3     1      0     0       1       1   \n",
       "2   2  18857    130     70            3     1      0     0       0       1   \n",
       "3   3  17623    150    100            1     1      0     0       1       1   \n",
       "4   4  17474    100     60            1     1      0     0       0       0   \n",
       "\n",
       "         bmi  gender_2  \n",
       "0  21.967120         1  \n",
       "1  34.927679         0  \n",
       "2  23.507805         0  \n",
       "3  28.710479         1  \n",
       "4  23.011177         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cardio_first = df_cardio.drop([\"ap_hi\", \"ap_lo\", \"height\", \"weight\", \"bmi\"], axis = 1)\n",
    "df_cardio_first = pd.get_dummies(df_cardio_first, columns = [\"bmi_category\", \"ap_category\", \"gender\"], drop_first = True)\n",
    "\n",
    "df_cardio_second = df_cardio.drop([\"bmi_category\", \"ap_category\", \"height\", \"weight\"], axis = 1)\n",
    "df_cardio_second = pd.get_dummies(df_cardio_second, columns = [\"gender\"], drop_first = True)\n",
    "\n",
    "df_cardio_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34130, 10), (17065, 10), (17065, 10), (34130,), (17065,), (17065,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tvt_split(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.5, random_state = 42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = tvt_split(df_cardio_first.drop([\"id\", \"cardio\"], axis = 1), df_cardio_first[\"cardio\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = tvt_split(df_cardio_second.drop([\"id\", \"cardio\"], axis = 1), df_cardio_second[\"cardio\"])\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from evolutionary_algos import EvoMLPClassifier\n",
    "#classifier = EvoMLPClassifier(n = 48, hidden_layers = [8], activation = \"relu\", random_state = 42)\n",
    "#classifier.fit(scaled_X_train, y_train, epochs = 1000, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvoMLPClassifier:\n",
    "    '''LATEST VERSION, TESTED WITH MULTICLASS AND BINARY'''\n",
    "\n",
    "    def __init__(self, n = 24, hidden_layers = False, activation = \"relu\", lr_target = 0.04, lr_initial_decay = 60, lr_final_decay = 0.03, random_state = None):\n",
    "\n",
    "        self.n = int(round(n / 8) * 8)\n",
    "        self.validation_loss_history = []\n",
    "        self.training_loss_history = []\n",
    "        self.random_state = random_state\n",
    "        self.activation = activation\n",
    "        self.lr_target = lr_target\n",
    "        self.lr_initial_decay = lr_initial_decay\n",
    "        self.lr_final_decay = lr_final_decay\n",
    "\n",
    "        \n",
    "        if hidden_layers:\n",
    "            self.hidden_layers = hidden_layers\n",
    "        else:\n",
    "            self.hidden_layers = False\n",
    "\n",
    "        \n",
    "\n",
    "    def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0):\n",
    "\n",
    "        n = self.n\n",
    "        ndiv4 = n // 4\n",
    "\n",
    "        if self.random_state != None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "        y_train = y_train.astype(\"int8\")\n",
    "\n",
    "        if len(y_train.shape) == 1:\n",
    "            self.multiclass = False\n",
    "        elif len(y_train.shape) == 2 and y_train.shape[1] == 1:\n",
    "            self.multiclass = False\n",
    "            y_train = y_train.ravel()\n",
    "        else:\n",
    "            self.multiclass = True\n",
    "            \n",
    "\n",
    "        if validation_data:\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == \"leaky_relu\":\n",
    "            activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        else:\n",
    "            activation_function = lambda x: np.maximum(0, x)\n",
    "\n",
    "        if self.multiclass == True:\n",
    "            output_activation_function = lambda x: np.exp(x) / np.sum(np.exp(x), axis = 2, keepdims = True)\n",
    "            \n",
    "            def loss_function(y_train, y_preds, sorted_indices):\n",
    "                return np.mean(np.sum(-y_train * np.log10(y_preds[sorted_indices[ndiv4:]]), axis = 2), axis = 1)\n",
    "\n",
    "        elif self.multiclass == False:\n",
    "            output_activation_function = lambda x: (1 / (1 + np.exp(-x))).reshape(x.shape[:2])\n",
    "\n",
    "            def loss_function(y_train, y_preds, sorted_indices):\n",
    "                return np.mean(np.abs(y_preds[sorted_indices[ndiv4:]] - y_train), axis = 1)\n",
    "\n",
    "        lr_target = self.lr_target\n",
    "        lr_initial_decay = self.lr_initial_decay\n",
    "        lr_final_decay = self.lr_final_decay\n",
    "\n",
    "        layers = [X_train.shape[1]]\n",
    "\n",
    "        if self.hidden_layers:\n",
    "            layers = [X_train.shape[1]] + self.hidden_layers\n",
    "\n",
    "        if self.multiclass == True:\n",
    "            layers = layers + [y_train.shape[1]]\n",
    "        elif self.multiclass == False:\n",
    "            layers = layers + [1]\n",
    "\n",
    "        number_of_layers_minus_one = len(layers) - 1\n",
    "        \n",
    "        if self.multiclass == True:\n",
    "            y_preds = np.zeros((n, y_train.shape[0], y_train.shape[1]))\n",
    "        elif self.multiclass == False:\n",
    "            y_preds = np.zeros((n, y_train.shape[0]))\n",
    "\n",
    "        nets_loss = np.zeros(n)\n",
    "        sorted_indices = np.arange(-(ndiv4), n, 1)\n",
    "\n",
    "        best_net_index = -1\n",
    "\n",
    "        weights = []\n",
    "\n",
    "        for i in range(number_of_layers_minus_one):\n",
    "            weights += [np.random.normal(0, 1, (n, layers[i], layers[i + 1]))]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "\n",
    "\n",
    "            forward_pass = X_train.T\n",
    "\n",
    "            \n",
    "            for j in range(number_of_layers_minus_one - 1):\n",
    "                forward_pass = activation_function(weights[j][sorted_indices[ndiv4:]].transpose(0, 2, 1) @ forward_pass)\n",
    "            \n",
    "            forward_pass = weights[-1][sorted_indices[ndiv4:]].transpose(0, 2, 1) @ forward_pass\n",
    "            \n",
    "            y_preds[sorted_indices[ndiv4:]] = output_activation_function(forward_pass.transpose(0, 2, 1))\n",
    "\n",
    "            nets_loss[sorted_indices[ndiv4:]] = loss_function(y_train, y_preds, sorted_indices)\n",
    "\n",
    "            sorted_indices = np.argsort(nets_loss)\n",
    "            mutation_sigma = math.exp(-epoch / (epochs / (lr_initial_decay * math.log10(epochs + 1)))) + lr_final_decay * math.exp(-(epoch + 1) * (1 / (epochs))) + lr_target + (-0.036 * 10 * lr_final_decay)\n",
    "\n",
    "            for j in range(number_of_layers_minus_one):\n",
    "                weights[j][sorted_indices[0 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[1 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[2 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[3 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[4 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[5 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "\n",
    "            if best_net_index != sorted_indices[0]:\n",
    "                best_net_index = sorted_indices[0]\n",
    "                self.training_loss_history += [nets_loss[best_net_index]]\n",
    "                \n",
    "\n",
    "                self.best_net_weights = []\n",
    "                for j in range(number_of_layers_minus_one):\n",
    "                    self.best_net_weights += [weights[j][best_net_index]]\n",
    "                \n",
    "                if validation_data:\n",
    "                    self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
    "                    if verbose == 1:\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]}\")\n",
    "                else:\n",
    "                    if verbose == 1:\n",
    "                        pass\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - {mutation_sigma}\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == \"leaky_relu\":\n",
    "            activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        else:\n",
    "            activation_function = lambda x: np.maximum(0, x)\n",
    "\n",
    "        if self.multiclass == True:\n",
    "            output_activation_function = lambda x: np.exp(x) / np.sum(np.exp(x), axis = 1, keepdims = True)\n",
    "\n",
    "        elif self.multiclass == False:\n",
    "            output_activation_function = lambda x: (1 / (1 + np.exp(-x))).reshape(x.shape[:1])\n",
    "\n",
    "        forward_pass = X.T\n",
    "\n",
    "        for j in range(len(self.best_net_weights) - 1):\n",
    "            forward_pass = activation_function(self.best_net_weights[j].T @ forward_pass)\n",
    "            \n",
    "        forward_pass = self.best_net_weights[-1].T @ forward_pass\n",
    "            \n",
    "        return output_activation_function(forward_pass.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 0.39374032246301394 - val_loss: 0.38968283210568444\n",
      "Epoch 1 - loss: 0.3397788346408439 - val_loss: 0.33640518290534366\n",
      "Epoch 3 - loss: 0.33468340103248234 - val_loss: 0.3317709969432861\n",
      "Epoch 4 - loss: 0.3334523129568803 - val_loss: 0.3340965631975216\n",
      "Epoch 5 - loss: 0.30126881765951924 - val_loss: 0.301819874015624\n",
      "Epoch 6 - loss: 0.29681837002558825 - val_loss: 0.29804901352497487\n",
      "Epoch 7 - loss: 0.2937070206555696 - val_loss: 0.2953613057663528\n",
      "Epoch 8 - loss: 0.2886923266383625 - val_loss: 0.2883959141595153\n",
      "Epoch 9 - loss: 0.2846693337818226 - val_loss: 0.2845784549059798\n",
      "Epoch 10 - loss: 0.2826359437342934 - val_loss: 0.28264373722908975\n",
      "Epoch 11 - loss: 0.28206415929834955 - val_loss: 0.2834567176642941\n",
      "Epoch 12 - loss: 0.27939242712663925 - val_loss: 0.2790168244993552\n",
      "Epoch 13 - loss: 0.2775301777112635 - val_loss: 0.2784404088016199\n",
      "Epoch 14 - loss: 0.2768329184535879 - val_loss: 0.2765330683131002\n",
      "Epoch 15 - loss: 0.2758143373228325 - val_loss: 0.27709302376172135\n",
      "Epoch 16 - loss: 0.274729525322885 - val_loss: 0.2761560296962111\n",
      "Epoch 17 - loss: 0.27360580596517575 - val_loss: 0.2763060894381215\n",
      "Epoch 19 - loss: 0.27323163164919206 - val_loss: 0.27604597987863577\n",
      "Epoch 20 - loss: 0.27301903522691245 - val_loss: 0.27624563933246293\n",
      "Epoch 21 - loss: 0.2726639482251121 - val_loss: 0.27643585040025553\n",
      "Epoch 22 - loss: 0.2724422255149849 - val_loss: 0.27567227632127167\n",
      "Epoch 23 - loss: 0.27211251596240554 - val_loss: 0.2745331702048535\n",
      "Epoch 24 - loss: 0.27207852255515463 - val_loss: 0.2748938835306989\n",
      "Epoch 25 - loss: 0.2720466904795382 - val_loss: 0.2745327186248679\n",
      "Epoch 26 - loss: 0.2719338406979684 - val_loss: 0.2743033905726542\n",
      "Epoch 27 - loss: 0.27143908191149496 - val_loss: 0.2754226378875486\n",
      "Epoch 28 - loss: 0.27128915037633583 - val_loss: 0.27500983354631486\n",
      "Epoch 29 - loss: 0.2711199699799407 - val_loss: 0.2745555636511984\n",
      "Epoch 30 - loss: 0.27086337104839303 - val_loss: 0.275155795911513\n",
      "Epoch 31 - loss: 0.27083848468761523 - val_loss: 0.27543334977563555\n",
      "Epoch 32 - loss: 0.27053772700107226 - val_loss: 0.275151568746839\n",
      "Epoch 34 - loss: 0.2703642152416633 - val_loss: 0.2745220118252736\n",
      "Epoch 35 - loss: 0.2702867624135522 - val_loss: 0.2750668315912476\n",
      "Epoch 36 - loss: 0.27010659639792123 - val_loss: 0.2745292813126056\n",
      "Epoch 37 - loss: 0.270022181322297 - val_loss: 0.27513625458582674\n",
      "Epoch 38 - loss: 0.26970380672060973 - val_loss: 0.274931610567206\n",
      "Epoch 39 - loss: 0.2695725854464465 - val_loss: 0.2748191314317355\n",
      "Epoch 40 - loss: 0.26950484110385325 - val_loss: 0.27445434840573313\n",
      "Epoch 41 - loss: 0.26943605808700694 - val_loss: 0.27408729490578954\n",
      "Epoch 42 - loss: 0.2691522702719726 - val_loss: 0.2743992383915002\n",
      "Epoch 45 - loss: 0.26901061595656983 - val_loss: 0.2737530140346925\n",
      "Epoch 46 - loss: 0.2688456997600548 - val_loss: 0.27359705582208077\n",
      "Epoch 47 - loss: 0.2687928005871888 - val_loss: 0.2740958530050857\n",
      "Epoch 48 - loss: 0.2687398908511884 - val_loss: 0.2740118598261652\n",
      "Epoch 49 - loss: 0.2686122335616709 - val_loss: 0.2741305560888473\n",
      "Epoch 51 - loss: 0.2685218892686798 - val_loss: 0.27413026486399117\n",
      "Epoch 52 - loss: 0.26841030243354363 - val_loss: 0.2733983509163679\n",
      "Epoch 53 - loss: 0.26828581825694003 - val_loss: 0.27376135260639073\n",
      "Epoch 55 - loss: 0.2681532322437885 - val_loss: 0.2735585323141133\n",
      "Epoch 56 - loss: 0.268024138389885 - val_loss: 0.2739634610811724\n",
      "Epoch 58 - loss: 0.2679236058370654 - val_loss: 0.2738969850516946\n",
      "Epoch 60 - loss: 0.26775835413271437 - val_loss: 0.2732764864366486\n",
      "Epoch 62 - loss: 0.26765560982099296 - val_loss: 0.27334582411767383\n",
      "Epoch 63 - loss: 0.26764593045804036 - val_loss: 0.2730146945947421\n",
      "Epoch 64 - loss: 0.2676457130211116 - val_loss: 0.2738025873457847\n",
      "Epoch 65 - loss: 0.2674629893429988 - val_loss: 0.2731412916341971\n",
      "Epoch 66 - loss: 0.26741498048220896 - val_loss: 0.27325503006230417\n",
      "Epoch 67 - loss: 0.2673529358744382 - val_loss: 0.27376737832534814\n",
      "Epoch 68 - loss: 0.26727159339277773 - val_loss: 0.27365273696937\n",
      "Epoch 70 - loss: 0.26708494407084593 - val_loss: 0.273657805520529\n",
      "Epoch 71 - loss: 0.26707684448333735 - val_loss: 0.2736680083666586\n",
      "Epoch 75 - loss: 0.26699917347132074 - val_loss: 0.27342441773430526\n",
      "Epoch 77 - loss: 0.2669230245263841 - val_loss: 0.27327110114836556\n",
      "Epoch 78 - loss: 0.26691362280382275 - val_loss: 0.273334727085096\n",
      "Epoch 79 - loss: 0.2668289048928768 - val_loss: 0.273675227108872\n",
      "Epoch 81 - loss: 0.26679445768729937 - val_loss: 0.27327262977556227\n",
      "Epoch 82 - loss: 0.26678085329900375 - val_loss: 0.2734817197899713\n",
      "Epoch 83 - loss: 0.266742811809165 - val_loss: 0.27333061278909776\n",
      "Epoch 84 - loss: 0.2666044982695161 - val_loss: 0.27341072216541423\n",
      "Epoch 85 - loss: 0.2665881683366932 - val_loss: 0.2731370414338898\n",
      "Epoch 86 - loss: 0.26639544595212 - val_loss: 0.27288611687372655\n",
      "Epoch 90 - loss: 0.2663172558299836 - val_loss: 0.27262986411459383\n",
      "Epoch 92 - loss: 0.2662639519518682 - val_loss: 0.2727942311037918\n",
      "Epoch 93 - loss: 0.2661452142085567 - val_loss: 0.2728150763606546\n",
      "Epoch 94 - loss: 0.26614267436052974 - val_loss: 0.27289795963803964\n",
      "Epoch 98 - loss: 0.2660927992465126 - val_loss: 0.27286021968952384\n",
      "Epoch 102 - loss: 0.2660893482644497 - val_loss: 0.27299376727604446\n",
      "Epoch 103 - loss: 0.26603861690293534 - val_loss: 0.2725852382639878\n",
      "Epoch 104 - loss: 0.2660068772884723 - val_loss: 0.2726602973799734\n",
      "Epoch 108 - loss: 0.26593674481479845 - val_loss: 0.2726731630078883\n",
      "Epoch 111 - loss: 0.2658810888292442 - val_loss: 0.27241803126945546\n",
      "Epoch 113 - loss: 0.2656893476406113 - val_loss: 0.2723532711692997\n",
      "Epoch 118 - loss: 0.26565889269846715 - val_loss: 0.272291810871259\n",
      "Epoch 120 - loss: 0.265652420603956 - val_loss: 0.27282981112015325\n",
      "Epoch 121 - loss: 0.2655823764457277 - val_loss: 0.2727724262096816\n",
      "Epoch 122 - loss: 0.26555604932906485 - val_loss: 0.2720038112951405\n",
      "Epoch 123 - loss: 0.2655361472046292 - val_loss: 0.27227477292334623\n",
      "Epoch 125 - loss: 0.2654605482531731 - val_loss: 0.272612369681516\n",
      "Epoch 127 - loss: 0.2654147931086526 - val_loss: 0.27280115503061275\n",
      "Epoch 128 - loss: 0.26538704174444727 - val_loss: 0.2722283843385637\n",
      "Epoch 130 - loss: 0.26533498420443863 - val_loss: 0.2726060577369225\n",
      "Epoch 132 - loss: 0.26530679483710556 - val_loss: 0.27208875677054606\n",
      "Epoch 139 - loss: 0.2652977850445599 - val_loss: 0.2724504084511132\n",
      "Epoch 140 - loss: 0.26527023290090485 - val_loss: 0.2726778162907647\n",
      "Epoch 143 - loss: 0.26522379996407885 - val_loss: 0.27230827078554226\n",
      "Epoch 144 - loss: 0.2652211479452347 - val_loss: 0.27208918301651347\n",
      "Epoch 145 - loss: 0.2652144755382109 - val_loss: 0.27177345181801105\n",
      "Epoch 147 - loss: 0.2650614746286529 - val_loss: 0.2720051107346426\n",
      "Epoch 148 - loss: 0.2650084860939346 - val_loss: 0.2720076436110945\n",
      "Epoch 156 - loss: 0.2649962578669156 - val_loss: 0.2720878637878502\n",
      "Epoch 158 - loss: 0.2649757267359862 - val_loss: 0.2724795807059234\n",
      "Epoch 161 - loss: 0.2649578309964595 - val_loss: 0.27209006604015423\n",
      "Epoch 162 - loss: 0.2649429159454322 - val_loss: 0.2721165603701587\n",
      "Epoch 167 - loss: 0.26493883701770626 - val_loss: 0.272256233929358\n",
      "Epoch 168 - loss: 0.26489264090087844 - val_loss: 0.2720460247400815\n",
      "Epoch 169 - loss: 0.2647568965924277 - val_loss: 0.2719004096089757\n",
      "Epoch 176 - loss: 0.26473151704286235 - val_loss: 0.2720926977924141\n",
      "Epoch 182 - loss: 0.26470874834584 - val_loss: 0.27182874453273864\n",
      "Epoch 184 - loss: 0.26461804795687277 - val_loss: 0.2718418657304895\n",
      "Epoch 188 - loss: 0.2646130231949129 - val_loss: 0.27133393096524544\n",
      "Epoch 192 - loss: 0.2646066657925754 - val_loss: 0.2717927726476501\n",
      "Epoch 198 - loss: 0.26455975324029346 - val_loss: 0.27148880548989357\n",
      "Epoch 199 - loss: 0.26452362374226235 - val_loss: 0.2714532583484509\n",
      "Epoch 201 - loss: 0.2645121538055778 - val_loss: 0.27167057535838374\n",
      "Epoch 206 - loss: 0.26444040099349664 - val_loss: 0.27143548486894337\n",
      "Epoch 215 - loss: 0.2644263823002263 - val_loss: 0.2712604214474271\n",
      "Epoch 219 - loss: 0.2644108366916325 - val_loss: 0.2715077773051098\n",
      "Epoch 221 - loss: 0.26437245281835914 - val_loss: 0.2713333583152726\n",
      "Epoch 222 - loss: 0.26429745597730636 - val_loss: 0.2714924184963314\n",
      "Epoch 228 - loss: 0.2642847024635438 - val_loss: 0.2715719999357685\n",
      "Epoch 245 - loss: 0.26426691303814265 - val_loss: 0.27149013862124605\n",
      "Epoch 249 - loss: 0.26424224256314865 - val_loss: 0.2713597770708623\n",
      "Epoch 250 - loss: 0.2642298569578053 - val_loss: 0.2712960751048367\n",
      "Epoch 254 - loss: 0.2642284956244185 - val_loss: 0.27141568429691854\n",
      "Epoch 256 - loss: 0.2641466600482446 - val_loss: 0.27136402436237933\n",
      "Epoch 269 - loss: 0.26413100486910507 - val_loss: 0.2710164344460892\n",
      "Epoch 271 - loss: 0.26408756035473 - val_loss: 0.2710552093907708\n",
      "Epoch 277 - loss: 0.2640789423202917 - val_loss: 0.2709693881420162\n",
      "Epoch 284 - loss: 0.26406065048160526 - val_loss: 0.2711560294843441\n",
      "Epoch 286 - loss: 0.2640151188650366 - val_loss: 0.2713423189717583\n",
      "Epoch 290 - loss: 0.2640140198482841 - val_loss: 0.2715213647464451\n",
      "Epoch 292 - loss: 0.2639540518291933 - val_loss: 0.27132689527119064\n",
      "Epoch 303 - loss: 0.26395047210932676 - val_loss: 0.27101741589095785\n",
      "Epoch 306 - loss: 0.26392586296209847 - val_loss: 0.27129074993365476\n",
      "Epoch 310 - loss: 0.2639253276702524 - val_loss: 0.2712539466052187\n",
      "Epoch 319 - loss: 0.26389124892346144 - val_loss: 0.27117384965580293\n",
      "Epoch 321 - loss: 0.26385948950446225 - val_loss: 0.27103421055889454\n",
      "Epoch 335 - loss: 0.2638561686981321 - val_loss: 0.27119631219945745\n",
      "Epoch 351 - loss: 0.2637858217961342 - val_loss: 0.27116602237692483\n",
      "Epoch 353 - loss: 0.26378426720515324 - val_loss: 0.2711026458619388\n",
      "Epoch 354 - loss: 0.26374627085680585 - val_loss: 0.2710496861145466\n",
      "Epoch 364 - loss: 0.2637420904597594 - val_loss: 0.27105731082314516\n",
      "Epoch 365 - loss: 0.2637260712798839 - val_loss: 0.2709750866852497\n",
      "Epoch 367 - loss: 0.2636791214377994 - val_loss: 0.27096666921881724\n",
      "Epoch 371 - loss: 0.26367668222439217 - val_loss: 0.27113487261137376\n",
      "Epoch 372 - loss: 0.26363065022939003 - val_loss: 0.2710152275040342\n",
      "Epoch 386 - loss: 0.2636263315993238 - val_loss: 0.2708630155313791\n",
      "Epoch 389 - loss: 0.2635916006545328 - val_loss: 0.27068941501489113\n",
      "Epoch 390 - loss: 0.263582237272985 - val_loss: 0.2704900984948863\n",
      "Epoch 394 - loss: 0.2635690865064343 - val_loss: 0.2707556896932262\n",
      "Epoch 396 - loss: 0.26348800604497086 - val_loss: 0.27075061913049264\n",
      "Epoch 413 - loss: 0.26346511068274114 - val_loss: 0.2706404617495939\n",
      "Epoch 417 - loss: 0.2634342557444729 - val_loss: 0.2706420252586514\n",
      "Epoch 424 - loss: 0.26341686053645 - val_loss: 0.2706229988124602\n",
      "Epoch 434 - loss: 0.2633980912966676 - val_loss: 0.2708910167590913\n",
      "Epoch 439 - loss: 0.2633513055878948 - val_loss: 0.27087864418574675\n",
      "Epoch 449 - loss: 0.26326743171035244 - val_loss: 0.27070850885257625\n",
      "Epoch 455 - loss: 0.2632646774544579 - val_loss: 0.27078967603009463\n",
      "Epoch 462 - loss: 0.26325656829579297 - val_loss: 0.2706996215005572\n",
      "Epoch 463 - loss: 0.2632492959648466 - val_loss: 0.27089631986394963\n",
      "Epoch 465 - loss: 0.2631551451294114 - val_loss: 0.2707895593894482\n",
      "Epoch 488 - loss: 0.26313963162490345 - val_loss: 0.27083891503568475\n",
      "Epoch 490 - loss: 0.26312283874615955 - val_loss: 0.27073729746212655\n",
      "Epoch 500 - loss: 0.26307742760120223 - val_loss: 0.27086858351268844\n",
      "Epoch 502 - loss: 0.26307508721608575 - val_loss: 0.27076539295267615\n",
      "Epoch 506 - loss: 0.2630584438749199 - val_loss: 0.27047835033368733\n",
      "Epoch 510 - loss: 0.2630427563214874 - val_loss: 0.2706758668018373\n",
      "Epoch 513 - loss: 0.26298748581452575 - val_loss: 0.270469587798512\n",
      "Epoch 530 - loss: 0.2629813408346567 - val_loss: 0.2709716402599336\n",
      "Epoch 547 - loss: 0.26293812024674024 - val_loss: 0.27061543758678164\n",
      "Epoch 549 - loss: 0.26291561116809414 - val_loss: 0.2704830750010441\n",
      "Epoch 556 - loss: 0.26289856088490016 - val_loss: 0.27054760947677886\n",
      "Epoch 565 - loss: 0.26289344568174494 - val_loss: 0.27050730881266954\n",
      "Epoch 571 - loss: 0.2628316635309669 - val_loss: 0.2705355017198999\n",
      "Epoch 596 - loss: 0.2628255217797081 - val_loss: 0.27053958818950696\n",
      "Epoch 604 - loss: 0.26280953242249705 - val_loss: 0.27054151566469015\n",
      "Epoch 610 - loss: 0.26277451183257106 - val_loss: 0.27059378901974956\n",
      "Epoch 617 - loss: 0.2627648092606034 - val_loss: 0.27056125540033904\n",
      "Epoch 631 - loss: 0.26275201617147176 - val_loss: 0.2703517660226851\n",
      "Epoch 647 - loss: 0.2627477712108912 - val_loss: 0.27055485089488857\n",
      "Epoch 655 - loss: 0.2627006675052796 - val_loss: 0.2705747457426012\n",
      "Epoch 659 - loss: 0.2626527134312544 - val_loss: 0.27048910625801703\n",
      "Epoch 676 - loss: 0.262595557801371 - val_loss: 0.270262417566457\n",
      "Epoch 683 - loss: 0.2625930101062188 - val_loss: 0.2704436271770163\n",
      "Epoch 701 - loss: 0.26258528557457367 - val_loss: 0.27046626162010684\n",
      "Epoch 711 - loss: 0.2625846869884248 - val_loss: 0.27025725023146846\n",
      "Epoch 712 - loss: 0.26255819818618675 - val_loss: 0.2703707069836044\n",
      "Epoch 759 - loss: 0.2625364441905441 - val_loss: 0.27027295931312695\n",
      "Epoch 776 - loss: 0.26243843637112313 - val_loss: 0.2703084800757306\n",
      "Epoch 815 - loss: 0.26240570104461514 - val_loss: 0.2701957073492554\n",
      "Epoch 837 - loss: 0.26238264664591493 - val_loss: 0.27024996198591383\n",
      "Epoch 849 - loss: 0.2623705448651599 - val_loss: 0.2702180395979455\n",
      "Epoch 853 - loss: 0.262369879206072 - val_loss: 0.2701032758230907\n",
      "Epoch 860 - loss: 0.2623650456360939 - val_loss: 0.2703216364646983\n",
      "Epoch 911 - loss: 0.2623331284078574 - val_loss: 0.27007972631954547\n",
      "Epoch 993 - loss: 0.2622705300489793 - val_loss: 0.2698961963818591\n",
      "Epoch 994 - loss: 0.2622521301227027 - val_loss: 0.270022286811963\n"
     ]
    }
   ],
   "source": [
    "classifier = EvoMLPClassifier(n = 48, hidden_layers = [8], activation = \"relu\", random_state = 42)\n",
    "classifier.fit(scaled_X_train, y_train, epochs = 1000, validation_data = (scaled_X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      8683\n",
      "           1       0.74      0.69      0.72      8382\n",
      "\n",
      "    accuracy                           0.73     17065\n",
      "   macro avg       0.73      0.73      0.73     17065\n",
      "weighted avg       0.73      0.73      0.73     17065\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = classifier.predict(scaled_X_test)\n",
    "y_pred = (y_pred > 0.5) * 1\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [1, 3],\n",
       "       [3, 4],\n",
       "       [1, 1],\n",
       "       [3, 2],\n",
       "       [3, 3],\n",
       "       [3, 3],\n",
       "       [4, 1],\n",
       "       [4, 4],\n",
       "       [4, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "a = np.random.randint(1, 5, (10, 2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(0, a.shape[0])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 8, 6]),\n",
       " array([[3, 4],\n",
       "        [3, 4],\n",
       "        [4, 4],\n",
       "        [3, 3]]),\n",
       " array([4, 3, 3, 4, 1, 2, 3, 3, 3, 3, 4, 1, 4, 4, 4, 3]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.random.choice(b, 4, replace = False)\n",
    "c, a[b[c]], np.delete(a, b[c])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
