{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "X_train, y_train = df[~df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]], df[~df[\"horsepower\"].isna()][\"horsepower\"]\n",
    "X_pred = df[df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred = np.round(y_pred)\n",
    "df.loc[X_pred.index, \"horsepower\"] = y_pred\n",
    "df = pd.get_dummies(df.drop(\"name\", axis = 1), columns = [\"origin\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"mpg\"], axis = 1).values, df[\"mpg\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorRegressor:\n",
    "    def __init__(self, n = 100, hidden_layers = False, activation = \"sigmoid\", random_state = None, verbose = 0):\n",
    "\n",
    "        self.n = n // 2 * 2\n",
    "        self.nets = []\n",
    "        self.best_net = -1\n",
    "        self.best_result = None\n",
    "        self.validation_loss_history = []\n",
    "        self.training_loss_history = []\n",
    "        self.mutation_sigma = 0\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif activation == \"relu\":\n",
    "            self.activation_function = lambda x: np.maximum(0, x)\n",
    "        elif activation == \"leaky_relu\":\n",
    "            self.activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        \n",
    "        if hidden_layers:\n",
    "            self.layers = hidden_layers + [1]\n",
    "        else:\n",
    "            self.layers = [1]\n",
    "        \n",
    "        if random_state != None:\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "    \n",
    "    def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0):\n",
    "        X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "\n",
    "        if validation_data:\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        self.layers = [X_train.shape[1]] + self.layers\n",
    "\n",
    "        self.y_preds = np.zeros((self.n, y_train.shape[0]))\n",
    "        self.nets_loss = np.zeros(self.n)\n",
    "        self.sorted_indecies = np.zeros(self.n)\n",
    "\n",
    "        self.weights = []\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.weights += [np.random.uniform(-3, 3, (self.n, self.layers[i], self.layers[i + 1]))]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            forward_pass = X_train.T\n",
    "            \n",
    "            for j in range(0, len(self.layers) - 2):\n",
    "                forward_pass = self.activation_function(self.weights[j].transpose(0, 2, 1) @ forward_pass)\n",
    "\n",
    "            forward_pass = self.weights[-1].transpose(0, 2, 1) @ forward_pass\n",
    "            self.y_preds = forward_pass.reshape(self.n, -1)\n",
    "\n",
    "            self.nets_loss = np.mean(np.abs(self.y_preds - y_train), axis = 1)\n",
    "\n",
    "            self.sorted_indecies = np.argsort(self.nets_loss)\n",
    "\n",
    "            self.mutation_sigma = 0.1 + 5 * 1 / math.exp(epoch / ((epochs + 1) / (100 * math.log10(epochs + 1))))\n",
    "\n",
    "            for j in range(0, len(self.layers) - 1):\n",
    "                self.weights[j][self.sorted_indecies[50::2]] = np.mean((self.weights[j][self.sorted_indecies[:50:2]], self.weights[j][self.sorted_indecies[1:51:2]]), axis = 0) + np.random.normal(0, self.mutation_sigma, (self.n // 4, self.layers[j], self.layers[j + 1]))\n",
    "                self.weights[j][self.sorted_indecies[51::2]] = np.mean((self.weights[j][self.sorted_indecies[:50:2]], self.weights[j][self.sorted_indecies[1:51:2]]), axis = 0) + np.random.normal(0, self.mutation_sigma, (self.n // 4, self.layers[j], self.layers[j + 1]))\n",
    "\n",
    "            if self.best_net != self.sorted_indecies[0]:\n",
    "                self.best_net = self.sorted_indecies[0]\n",
    "                self.training_loss_history += [self.nets_loss[self.best_net]]\n",
    "                \n",
    "                if validation_data:\n",
    "                    self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
    "                    if verbose == 1:\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]}\")\n",
    "                else:\n",
    "                    if verbose == 1:\n",
    "                        pass\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]}\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        forward_pass = X.T\n",
    "        for j in range(0, len(self.layers) - 2):\n",
    "            forward_pass = self.activation_function(self.weights[j][self.best_net].T @ forward_pass)\n",
    "\n",
    "        forward_pass = self.weights[-1][self.best_net].T @ forward_pass\n",
    "        return forward_pass.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 7.883740580987366 - val_loss: 9.117732389946575\n",
      "Epoch 8 - loss: 6.509559630765517 - val_loss: 5.388920323499075\n",
      "Epoch 9 - loss: 5.998083120288314 - val_loss: 6.3412164088795455\n",
      "Epoch 10 - loss: 5.592001228332479 - val_loss: 6.454976459652011\n",
      "Epoch 11 - loss: 3.0841378037642433 - val_loss: 2.5989116231479956\n",
      "Epoch 16 - loss: 2.9555520450527855 - val_loss: 2.8980046483984907\n",
      "Epoch 17 - loss: 2.906880088282498 - val_loss: 3.186756421049205\n",
      "Epoch 19 - loss: 2.8087058993814913 - val_loss: 2.4119623069341927\n",
      "Epoch 20 - loss: 2.7614240897092635 - val_loss: 2.6010845758648924\n",
      "Epoch 22 - loss: 2.7433499757292736 - val_loss: 2.223134737068101\n",
      "Epoch 23 - loss: 2.6550750674258703 - val_loss: 2.214594076355291\n",
      "Epoch 24 - loss: 2.652240970513056 - val_loss: 2.410043527210161\n",
      "Epoch 26 - loss: 2.6266760009763512 - val_loss: 2.1223308580269173\n",
      "Epoch 27 - loss: 2.6203564683319485 - val_loss: 2.4925404189997864\n",
      "Epoch 29 - loss: 2.6181629883559605 - val_loss: 2.1568055258261\n",
      "Epoch 30 - loss: 2.5570256661546082 - val_loss: 2.017798063917975\n",
      "Epoch 32 - loss: 2.495569144753631 - val_loss: 2.236502410671929\n",
      "Epoch 35 - loss: 2.462818815408191 - val_loss: 1.9115580952609352\n",
      "Epoch 39 - loss: 2.4474077542801105 - val_loss: 2.076993260624991\n",
      "Epoch 42 - loss: 2.4401312794086816 - val_loss: 1.8715777427581841\n",
      "Epoch 46 - loss: 2.3901359913306583 - val_loss: 1.7623079787125906\n",
      "Epoch 47 - loss: 2.3796136122292872 - val_loss: 1.9935239257338737\n",
      "Epoch 54 - loss: 2.347826155422591 - val_loss: 1.841043119794699\n",
      "Epoch 65 - loss: 2.308843885947631 - val_loss: 1.763328355553022\n",
      "Epoch 66 - loss: 2.300169795964788 - val_loss: 1.6854199478751504\n",
      "Epoch 79 - loss: 2.2333970896809605 - val_loss: 1.8527568581794553\n",
      "Epoch 86 - loss: 2.217882936207238 - val_loss: 1.712331153614803\n",
      "Epoch 89 - loss: 2.2096586289385813 - val_loss: 1.7540156547506058\n",
      "Epoch 92 - loss: 2.174700040916971 - val_loss: 1.5424245228531521\n",
      "Epoch 104 - loss: 2.132182307072515 - val_loss: 1.7695288924762835\n",
      "Epoch 122 - loss: 2.11604505369181 - val_loss: 1.6391907003536734\n",
      "Epoch 127 - loss: 2.0783056597916394 - val_loss: 1.6708095514621406\n",
      "Epoch 139 - loss: 2.0736788572684466 - val_loss: 1.6239308330540179\n",
      "Epoch 147 - loss: 2.0497054374166344 - val_loss: 1.6090856470532748\n",
      "Epoch 163 - loss: 2.048441133182905 - val_loss: 1.8027351800138938\n",
      "Epoch 164 - loss: 2.0028794911753813 - val_loss: 1.6984149388717327\n",
      "Epoch 208 - loss: 1.9782651422157687 - val_loss: 1.6468030420409168\n",
      "Epoch 213 - loss: 1.9658937643296024 - val_loss: 1.6093437630117158\n",
      "Epoch 264 - loss: 1.9511586253951294 - val_loss: 1.5189624207873713\n",
      "Epoch 287 - loss: 1.941521882891049 - val_loss: 1.5302084131138318\n",
      "Epoch 301 - loss: 1.9263201800352758 - val_loss: 1.6188608357671896\n",
      "Epoch 324 - loss: 1.9133980252153595 - val_loss: 1.7537179795553324\n",
      "Epoch 332 - loss: 1.9107472436434272 - val_loss: 1.669193776610499\n",
      "Epoch 359 - loss: 1.9036234427525065 - val_loss: 1.61979993228259\n",
      "Epoch 361 - loss: 1.8871159736518734 - val_loss: 1.5457861848457601\n",
      "Epoch 426 - loss: 1.871771282182329 - val_loss: 1.648140159683703\n",
      "Epoch 576 - loss: 1.86176799943378 - val_loss: 1.6239650347877048\n",
      "Epoch 594 - loss: 1.8601479028059988 - val_loss: 1.601738421477436\n",
      "Epoch 617 - loss: 1.8521416890848754 - val_loss: 1.5981682780096063\n",
      "Epoch 685 - loss: 1.8415177401244855 - val_loss: 1.548679703185224\n",
      "Epoch 752 - loss: 1.8326347164453316 - val_loss: 1.6061005214597723\n",
      "Epoch 883 - loss: 1.83240013730166 - val_loss: 1.639906179640604\n",
      "Epoch 911 - loss: 1.8301901437481494 - val_loss: 1.6494164854306212\n",
      "Epoch 922 - loss: 1.8193097454958305 - val_loss: 1.567856869133378\n",
      "Epoch 961 - loss: 1.8184820081351034 - val_loss: 1.5053545822733558\n"
     ]
    }
   ],
   "source": [
    "vregressor = VectorRegressor(n = 100, hidden_layers = [10], activation = \"relu\", random_state = 42)\n",
    "vregressor.fit(scaled_X_train, y_train, epochs = 1000, validation_data = (scaled_X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vregressor.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.64140437, 34.21617117, 24.74893805, 38.62679494, 15.876758  ,\n",
       "       20.02510414, 13.46302104, 34.90722375, 13.29632817, 23.60215502,\n",
       "       26.86724428, 23.19228495, 35.32786318, 12.72546595, 27.18078347,\n",
       "       34.17316901, 18.61793492, 33.68498309, 11.87646859, 24.63018934,\n",
       "       18.42963081, 18.84493869, 25.39409425, 22.80014085, 34.74881644,\n",
       "       22.47990386, 21.1984451 , 27.10008261, 31.60438038, 26.05328812,\n",
       "       17.96848593, 18.22051233, 11.42318815, 20.31168452, 11.55482496,\n",
       "       37.67098392, 23.50907463, 45.18838465, 21.93169879, 14.97971544])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6244880201432412"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function = np.vectorize(lambda x: 1 / (1 + math.exp(-x)))\n",
    "\n",
    "w = [np.array([[[0, 3],[2, 0]],[[1, 3],[9, 7]],[[5, 8],[3, 3]]]),\n",
    "    np.array([[[2],[6]],[[0],[4]],[[6],[9]]])]\n",
    "#w1 = np.array([[[0, 3],[2, 0]],[[1, 3],[9, 7]],[[5, 8],[3, 3]]])\n",
    "#w2 = np.array([[[2],[6]],[[0],[4]],[[6],[9]]])\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "B = np.array([  [8, 0],\n",
    "                [9, 2],\n",
    "                [6, 3]])\n",
    "\n",
    "pred = []\n",
    "\n",
    "for i in range(3):\n",
    "    forward_pass = B.T\n",
    "    forward_pass = activation_function(w[0][i].T @ forward_pass)\n",
    "\n",
    "    forward_pass = w[1][i].T @ forward_pass\n",
    "\n",
    "    pred.append(forward_pass.reshape(-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7.        , 7.96402758, 7.99505466]),\n",
       " array([4., 4., 4.]),\n",
       " array([15., 15., 15.])]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "forward_pass = B.T\n",
    "forward_pass = activation_function(w[0].transpose(0, 2, 1) @ forward_pass)\n",
    "forward_pass = w[1].transpose(0, 2, 1) @ forward_pass\n",
    "pred = forward_pass.reshape(3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.        ,  7.96402758,  7.99505466],\n",
       "       [ 4.        ,  4.        ,  4.        ],\n",
       "       [15.        , 15.        , 15.        ]])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 1)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([48, 58, 42, 72, 93, 72]),\n",
       " array([56, 73, 57, 16, 26, 24]),\n",
       " array([32, 54, 51,  0, 10, 15])]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unsupported dtype dtype('O') for randint",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/test8.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/test8.ipynb#ch0000023?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, \u001b[39m10\u001b[39;49m, (\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, (\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)), dtype \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mobject\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32mmtrand.pyx:764\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unsupported dtype dtype('O') for randint"
     ]
    }
   ],
   "source": [
    "np.random.randint(0, 10, (2, 2, (1, 1)), dtype = \"object\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
