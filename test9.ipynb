{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "X_train, y_train = df[~df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]], df[~df[\"horsepower\"].isna()][\"horsepower\"]\n",
    "X_pred = df[df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred = np.round(y_pred)\n",
    "df.loc[X_pred.index, \"horsepower\"] = y_pred\n",
    "df = pd.get_dummies(df.drop(\"name\", axis = 1), columns = [\"origin\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"mpg\"], axis = 1).values, df[\"mpg\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorRegressor:\n",
    "    def __init__(self, n = 100, hidden_layers = False, activation = \"sigmoid\", random_state = None, verbose = 0):\n",
    "\n",
    "        self.n = n // 2 * 2\n",
    "        self.nets = []\n",
    "        self.best_net = -1\n",
    "        self.best_result = None\n",
    "        self.validation_loss_history = []\n",
    "        self.training_loss_history = []\n",
    "        self.mutation_sigma = 0\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif activation == \"relu\":\n",
    "            self.activation_function = lambda x: np.maximum(0, x)\n",
    "        elif activation == \"leaky_relu\":\n",
    "            self.activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        \n",
    "        if hidden_layers:\n",
    "            self.layers = hidden_layers + [1]\n",
    "        else:\n",
    "            self.layers = [1]\n",
    "        \n",
    "        if random_state != None:\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "    \n",
    "    def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0):\n",
    "        X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "\n",
    "        if validation_data:\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        self.layers = [X_train.shape[1]] + self.layers\n",
    "\n",
    "        self.y_preds = np.zeros((self.n, y_train.shape[0]))\n",
    "        self.nets_loss = np.zeros(self.n)\n",
    "        self.sorted_indecies = np.zeros(self.n)\n",
    "\n",
    "        self.weights = []\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.weights += [np.random.uniform(-3, 3, (self.n, self.layers[i], self.layers[i + 1]))]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            forward_pass = X_train.T\n",
    "            \n",
    "            for j in range(0, len(self.layers) - 2):\n",
    "                forward_pass = self.activation_function(self.weights[j].transpose(0, 2, 1) @ forward_pass)\n",
    "\n",
    "            forward_pass = self.weights[-1].transpose(0, 2, 1) @ forward_pass\n",
    "            self.y_preds = forward_pass.reshape(self.n, -1)\n",
    "\n",
    "            self.nets_loss = np.mean(np.abs(self.y_preds - y_train), axis = 1)\n",
    "\n",
    "            self.sorted_indecies = np.argsort(self.nets_loss)\n",
    "\n",
    "            self.mutation_sigma = 0.1 + 5 * 1 / math.exp(epoch / ((epochs + 1) / (10 * math.log10(epochs + 1))))\n",
    "\n",
    "            for j in range(0, len(self.layers) - 1):\n",
    "                self.weights[j][self.sorted_indecies[50::2]] = np.mean((self.weights[j][self.sorted_indecies[:50:2]], self.weights[j][self.sorted_indecies[1:51:2]]), axis = 0) + np.random.normal(0, self.mutation_sigma, (self.n // 4, self.layers[j], self.layers[j + 1]))\n",
    "                self.weights[j][self.sorted_indecies[51::2]] = np.mean((self.weights[j][self.sorted_indecies[:50:2]], self.weights[j][self.sorted_indecies[1:51:2]]), axis = 0) + np.random.normal(0, self.mutation_sigma, (self.n // 4, self.layers[j], self.layers[j + 1]))\n",
    "\n",
    "            if self.best_net != self.sorted_indecies[0]:\n",
    "                self.best_net = self.sorted_indecies[0]\n",
    "                self.training_loss_history += [self.nets_loss[self.best_net]]\n",
    "                \n",
    "                if validation_data:\n",
    "                    self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
    "                    if verbose == 1:\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]}\")\n",
    "                else:\n",
    "                    if verbose == 1:\n",
    "                        pass\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]}\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        forward_pass = X.T\n",
    "        for j in range(0, len(self.layers) - 2):\n",
    "            forward_pass = self.activation_function(self.weights[j][self.best_net].T @ forward_pass)\n",
    "\n",
    "        forward_pass = self.weights[-1][self.best_net].T @ forward_pass\n",
    "        return forward_pass.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 9.102721013798714 - val_loss: 8.398943305675033\n",
      "Epoch 25 - loss: 8.57143305946211 - val_loss: 8.351760926959304\n",
      "Epoch 27 - loss: 7.008406893645711 - val_loss: 7.078457510766609\n",
      "Epoch 41 - loss: 6.863639484033477 - val_loss: 7.502665028701311\n",
      "Epoch 47 - loss: 6.180237851149276 - val_loss: 4.577349783085332\n",
      "Epoch 54 - loss: 5.947949521366185 - val_loss: 5.71314795147191\n",
      "Epoch 58 - loss: 5.302623581963404 - val_loss: 5.199747199713962\n",
      "Epoch 61 - loss: 5.007625696947729 - val_loss: 5.197120808074201\n",
      "Epoch 62 - loss: 4.956147982732969 - val_loss: 4.387979008222061\n",
      "Epoch 66 - loss: 4.952389188188683 - val_loss: 6.060077579986136\n",
      "Epoch 69 - loss: 4.564585517164943 - val_loss: 3.9724024869876673\n",
      "Epoch 70 - loss: 4.508589764471477 - val_loss: 3.540674122308976\n",
      "Epoch 74 - loss: 3.3642325457566606 - val_loss: 3.1813853100013896\n",
      "Epoch 87 - loss: 2.9315165443805364 - val_loss: 2.707514446147145\n",
      "Epoch 90 - loss: 2.9046125173302806 - val_loss: 2.460648236513375\n",
      "Epoch 96 - loss: 2.8046096672902876 - val_loss: 2.2771516281882347\n",
      "Epoch 99 - loss: 2.7614395926224176 - val_loss: 2.833495984925916\n",
      "Epoch 110 - loss: 2.6963262856493904 - val_loss: 2.459881567492506\n",
      "Epoch 113 - loss: 2.6640711214955424 - val_loss: 2.616817292388584\n",
      "Epoch 114 - loss: 2.6548079478349833 - val_loss: 2.4351980036905494\n",
      "Epoch 115 - loss: 2.539516219095883 - val_loss: 2.4114312644308376\n",
      "Epoch 119 - loss: 2.5258307261805473 - val_loss: 2.52289976504656\n",
      "Epoch 121 - loss: 2.4877775780501454 - val_loss: 2.41884413523237\n",
      "Epoch 122 - loss: 2.4402469340346777 - val_loss: 2.2890396345334687\n",
      "Epoch 127 - loss: 2.3476798148366 - val_loss: 1.8740107567897126\n",
      "Epoch 132 - loss: 2.2157569906164998 - val_loss: 1.929678141226907\n",
      "Epoch 143 - loss: 2.1474460573842484 - val_loss: 1.9951404809683986\n",
      "Epoch 162 - loss: 2.140073894758934 - val_loss: 2.041642302142958\n",
      "Epoch 163 - loss: 2.05565835309469 - val_loss: 1.876448566218862\n",
      "Epoch 183 - loss: 2.0417519518933536 - val_loss: 2.0190255024282058\n",
      "Epoch 186 - loss: 2.0372837522238862 - val_loss: 1.7401647737180153\n",
      "Epoch 188 - loss: 2.0248894538978695 - val_loss: 2.0713138339087287\n",
      "Epoch 210 - loss: 2.021010133111626 - val_loss: 1.9640499710193893\n",
      "Epoch 215 - loss: 1.9915269537974463 - val_loss: 1.986823562861956\n",
      "Epoch 239 - loss: 1.985819778486441 - val_loss: 1.811035821414515\n",
      "Epoch 256 - loss: 1.9746457577918488 - val_loss: 2.0206937758580468\n",
      "Epoch 271 - loss: 1.96026449838337 - val_loss: 1.8443439969091842\n",
      "Epoch 328 - loss: 1.9544307635439002 - val_loss: 1.8385348472280225\n",
      "Epoch 364 - loss: 1.9527715244477666 - val_loss: 1.7744237488442494\n",
      "Epoch 382 - loss: 1.9509177824403598 - val_loss: 1.8279365086194315\n",
      "Epoch 434 - loss: 1.9467152913421002 - val_loss: 1.825449340944327\n",
      "Epoch 453 - loss: 1.9464754874953498 - val_loss: 1.882921298751641\n",
      "Epoch 483 - loss: 1.9262445635698995 - val_loss: 1.8164299628712364\n",
      "Epoch 595 - loss: 1.9229503491590574 - val_loss: 1.774863054691909\n",
      "Epoch 648 - loss: 1.9175328547305641 - val_loss: 1.9387978555668528\n",
      "Epoch 729 - loss: 1.916854412405676 - val_loss: 1.866841976155835\n",
      "Epoch 741 - loss: 1.916303119022766 - val_loss: 1.7656373287622937\n",
      "Epoch 751 - loss: 1.9085186074241476 - val_loss: 1.7544809823614744\n",
      "Epoch 764 - loss: 1.9056917226636458 - val_loss: 1.804685582496288\n",
      "Epoch 811 - loss: 1.8975222276514687 - val_loss: 1.8063051587322008\n",
      "Epoch 890 - loss: 1.8963212504768971 - val_loss: 1.8739332959633983\n"
     ]
    }
   ],
   "source": [
    "vregressor = VectorRegressor(n = 100, hidden_layers = [6], activation = \"relu\", random_state = 42)\n",
    "vregressor.fit(scaled_X_train, y_train, epochs = 1000, validation_data = (scaled_X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vregressor.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.60780215, 35.10591942, 26.0054007 , 39.01270276, 15.89375584,\n",
       "       17.99728717, 14.69126485, 36.4398758 , 13.47150772, 26.35626454,\n",
       "       28.53587332, 24.07746348, 36.84360747, 13.88108429, 30.0586416 ,\n",
       "       34.4046181 , 18.24526728, 34.13306707, 12.58403241, 23.16228996,\n",
       "       19.36623327, 19.68528503, 26.54746929, 21.00745788, 35.11865951,\n",
       "       21.76090962, 18.90002236, 26.32366799, 32.2704354 , 25.49646208,\n",
       "       17.48770788, 17.8076253 , 12.43021684, 21.67811921, 12.12335115,\n",
       "       37.42347901, 24.1966296 , 41.43846227, 22.1480613 , 15.14224081])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8202937607925365"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function = np.vectorize(lambda x: 1 / (1 + math.exp(-x)))\n",
    "\n",
    "w = [np.array([[[0, 3],[2, 0]],[[1, 3],[9, 7]],[[5, 8],[3, 3]]]),\n",
    "    np.array([[[2],[6]],[[0],[4]],[[6],[9]]])]\n",
    "#w1 = np.array([[[0, 3],[2, 0]],[[1, 3],[9, 7]],[[5, 8],[3, 3]]])\n",
    "#w2 = np.array([[[2],[6]],[[0],[4]],[[6],[9]]])\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "B = np.array([  [8, 0],\n",
    "                [9, 2],\n",
    "                [6, 3]])\n",
    "\n",
    "pred = []\n",
    "\n",
    "for i in range(3):\n",
    "    forward_pass = B.T\n",
    "    forward_pass = activation_function(w[0][i].T @ forward_pass)\n",
    "\n",
    "    forward_pass = w[1][i].T @ forward_pass\n",
    "\n",
    "    pred.append(forward_pass.reshape(-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7.        , 7.96402758, 7.99505466]),\n",
       " array([4., 4., 4.]),\n",
       " array([15., 15., 15.])]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "forward_pass = B.T\n",
    "forward_pass = activation_function(w[0].transpose(0, 2, 1) @ forward_pass)\n",
    "forward_pass = w[1].transpose(0, 2, 1) @ forward_pass\n",
    "pred = forward_pass.reshape(3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.        ,  7.96402758,  7.99505466],\n",
       "       [ 4.        ,  4.        ,  4.        ],\n",
       "       [15.        , 15.        , 15.        ]])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 1)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([48, 58, 42, 72, 93, 72]),\n",
       " array([56, 73, 57, 16, 26, 24]),\n",
       " array([32, 54, 51,  0, 10, 15])]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unsupported dtype dtype('O') for randint",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/test8.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/test8.ipynb#ch0000023?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, \u001b[39m10\u001b[39;49m, (\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, (\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)), dtype \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mobject\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32mmtrand.pyx:764\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unsupported dtype dtype('O') for randint"
     ]
    }
   ],
   "source": [
    "np.random.randint(0, 10, (2, 2, (1, 1)), dtype = \"object\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
