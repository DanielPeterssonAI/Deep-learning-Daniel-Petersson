{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "X_train, y_train = df[~df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]], df[~df[\"horsepower\"].isna()][\"horsepower\"]\n",
    "X_pred = df[df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred = np.round(y_pred)\n",
    "df.loc[X_pred.index, \"horsepower\"] = y_pred\n",
    "df = pd.get_dummies(df.drop(\"name\", axis = 1), columns = [\"origin\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"mpg\"], axis = 1).values, df[\"mpg\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = np.vectorize(lambda x: 1 / (1 + math.exp(-x)))\n",
    "\n",
    "def seed_np(integer):\n",
    "    np.random.seed(integer)\n",
    "\n",
    "class ERegressor:\n",
    "    class Net:\n",
    "        def __init__(self):\n",
    "            #self.layers = layers\n",
    "            pass\n",
    "\n",
    "        def set_input_size(self, input_size):\n",
    "            self.input_size = input_size\n",
    "\n",
    "        def set_layers(self, layers):\n",
    "            self.layers = layers\n",
    "        \n",
    "        def set_weights(self, weights_and_biases):\n",
    "            self.w, self.b = [], []\n",
    "\n",
    "            for i, weight_bias in enumerate(weights_and_biases):\n",
    "                self.w += [weight_bias[0]]\n",
    "                self.b += [weight_bias[1]]\n",
    "        \n",
    "        def set_mutation_sigma(self, n):\n",
    "            #self.mutation_sigma = 3 - (2 - 40 / (10 + n))\n",
    "            self.mutation_sigma = 2.5 - (3 - 1200 / (200 + n))\n",
    "        \n",
    "        def predict(self, input):\n",
    "            forward_pass = input.T\n",
    "            #print(self.w[0].T[0], self.w[0].T.shape, input.T.shape, self.b[0].shape)\n",
    "\n",
    "            #for i in range(1, len(self.layers) - 2):\n",
    "            #    forward_pass = sigmoid(self.w[i].T @ forward_pass + self.b[i])\n",
    "\n",
    "\n",
    "            #print(self.w[-1].T[0], forward_pass.shape, self.b[-1].shape)\n",
    "\n",
    "            for i in range(0, len(self.layers) - 1):\n",
    "                if i < len(self.layers) - 2:\n",
    "                    forward_pass = sigmoid(self.w[i].T @ forward_pass + self.b[i])\n",
    "                else:\n",
    "                    forward_pass = self.w[i].T @ forward_pass + self.b[i]\n",
    "\n",
    "            #forward_pass = self.w[0].T @ forward_pass + self.b[0]\n",
    "\n",
    "            return forward_pass.reshape(-1)\n",
    "\n",
    "        \n",
    "        def get_layer_shapes(self):\n",
    "            weights, biases = [], []\n",
    "\n",
    "            for w, b in zip(self.w, self.b):\n",
    "                weights += [w.shape]\n",
    "                biases += [b.shape]\n",
    "\n",
    "            return weights, biases\n",
    "        \n",
    "        def __add__(self, other):\n",
    "            w, b = [], []\n",
    "\n",
    "            for i in range(len(self.layers) - 1):\n",
    "                w += [(self.w[i] + other.w[i]) / 2 + np.random.normal(0, self.mutation_sigma, (self.layers[i], self.layers[i + 1]))]\n",
    "            \n",
    "            for i in range(len(self.layers) - 1):\n",
    "                b += [(self.b[i] + other.b[i]) / 2 + np.random.normal(0, self.mutation_sigma, (self.layers[i + 1], 1))]\n",
    "\n",
    "            return zip(w, b)\n",
    "\n",
    "    \n",
    "    def __init__(self, n = 100, hidden_layers = False, random_state = None):\n",
    "        self.nets = {}\n",
    "        self.y_preds = {}\n",
    "        self.best_net = None\n",
    "        self.best_result = None\n",
    "        self.n = n // 2 * 2\n",
    "        if not hidden_layers:\n",
    "            self.layers = [1]\n",
    "        else:\n",
    "            self.layers = hidden_layers + [1]\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            #self.nets[i] = self.Net(self.layers)\n",
    "            self.nets[i] = self.Net()\n",
    "\n",
    "        if random_state != None:\n",
    "            seed_np(random_state)\n",
    "    \n",
    "    def fit(self, X_train, y_train, epochs = 100):\n",
    "        self.input_size = X_train.shape[1]\n",
    "        self.layers = [X_train.shape[1]] + self.layers\n",
    "\n",
    "        for key in self.nets.keys():\n",
    "            #self.nets[key].set_input_size(self.input_size)\n",
    "            self.nets[key].set_layers(self.layers)\n",
    "            \n",
    "            w, b = [], []\n",
    "\n",
    "            for i in range(len(self.layers) - 1):\n",
    "                w += [np.random.uniform(-3, 3, (self.layers[i], self.layers[i + 1]))]\n",
    "            \n",
    "            for i in range(len(self.layers) - 1):\n",
    "                b += [np.random.uniform(-3, 3, (self.layers[i + 1], 1))]\n",
    "                    \n",
    "            self.nets[key].set_weights(zip(w, b))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for key, _ in self.nets.items():\n",
    "                self.y_preds[key] = self.nets[key].predict(X_train)\n",
    "                self.nets[key].set_mutation_sigma(epoch)\n",
    "            \n",
    "            self.mean_absolute_errors = {}\n",
    "            \n",
    "            for key, _ in self.y_preds.items():\n",
    "                self.mean_absolute_errors[key] = mean_absolute_error(y_train, self.y_preds[key])\n",
    "\n",
    "            self.sorted_indecies = [key for key, _ in sorted(self.mean_absolute_errors.items(), key = lambda x: x[1])]\n",
    "\n",
    "            if self.best_result != None:\n",
    "                if self.best_result[1] > sorted(self.mean_absolute_errors.items(), key = lambda x: x[1])[0][1]:\n",
    "                    self.best_result = sorted(self.mean_absolute_errors.items(), key = lambda x: x[1])[0]\n",
    "                    print(f\"Epoch {epoch}: MAE: {self.best_result[1]}\")\n",
    "            else:        \n",
    "                self.best_result = sorted(self.mean_absolute_errors.items(), key = lambda x: x[1])[0]\n",
    "                print(f\"Epoch {epoch}: MAE: {self.best_result[1]}\")\n",
    "\n",
    "            self.best_net = self.sorted_indecies[0]\n",
    "            \n",
    "            for i in range(0, self.n // 2, 2):\n",
    "                self.nets[self.sorted_indecies[self.n // 2 + i]].set_weights(self.nets[self.sorted_indecies[i]] + self.nets[self.sorted_indecies[i + 1]])\n",
    "                self.nets[self.sorted_indecies[self.n // 2 + i + 1]].set_weights(self.nets[self.sorted_indecies[i]] + self.nets[self.sorted_indecies[i + 1]])\n",
    "                pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.nets[self.best_net].predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: MAE: 15.525692036080034\n",
      "Epoch 1: MAE: 7.477269631428442\n",
      "Epoch 3: MAE: 5.249829589371986\n",
      "Epoch 6: MAE: 4.6856046881029165\n",
      "Epoch 17: MAE: 4.475585814564628\n",
      "Epoch 24: MAE: 4.274454356990163\n",
      "Epoch 45: MAE: 4.111198203965975\n",
      "Epoch 51: MAE: 4.045583500255095\n",
      "Epoch 52: MAE: 3.9238223486310075\n",
      "Epoch 58: MAE: 3.801227160802128\n",
      "Epoch 72: MAE: 3.68821181874302\n",
      "Epoch 86: MAE: 3.146313691916892\n",
      "Epoch 89: MAE: 3.1189069844357347\n"
     ]
    }
   ],
   "source": [
    "regressor = ERegressor(n = 100, hidden_layers = [9], random_state = 42)\n",
    "regressor.fit(scaled_X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(9, 1)], [(1, 1)])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.nets[regressor.best_net].get_layer_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75275929,  2.70428584,  1.39196365,  0.59195091, -2.06388816,\n",
       "        -2.06403288, -2.65149833,  2.19705687,  0.60669007],\n",
       "       [ 1.24843547, -2.87649303,  2.81945911,  1.99465584, -1.72596534,\n",
       "        -1.9090502 , -1.89957294, -1.17454654,  0.14853859],\n",
       "       [-0.40832989, -1.25262516,  0.67111737, -2.16303684, -1.24713211,\n",
       "        -0.80182894, -0.26358009,  1.71105577, -1.80195731],\n",
       "       [ 0.08540663,  0.55448741, -2.72129752,  0.64526911, -1.97685526,\n",
       "        -2.60969044,  2.69331322,  2.7937922 ,  1.85038409],\n",
       "       [-1.17231738, -2.41396732,  1.10539816, -0.35908504, -2.26777059,\n",
       "        -0.02893854, -2.79366887,  2.45592241, -1.44732011],\n",
       "       [ 0.97513371, -1.12973354,  0.12040813,  0.28026168, -1.89087327,\n",
       "         2.81750777,  1.65079694,  2.63699365,  2.3689641 ],\n",
       "       [ 0.58739987,  2.53124541, -2.46904499, -1.82410283, -2.72863627,\n",
       "        -1.04801802, -0.66793626, -1.37190581,  1.97242505],\n",
       "       [-0.85948004, -1.31439294,  0.2561765 , -2.15445465,  1.81318188,\n",
       "        -2.55269614,  2.92132162,  1.63346862, -1.80770591],\n",
       "       [-2.9668673 ,  1.89276857,  1.24114406,  1.37404301,  1.62762208,\n",
       "        -2.55573209, -0.84920563, -2.30478564,  2.17862056]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.nets[0].w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 318)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(9, 9), (9, 1)], [(9, 1), (1, 1)])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.nets[1].get_layer_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9495569827432118"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
