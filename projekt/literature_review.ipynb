{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature review\n",
    "\n",
    "https://aircconline.com/ijaia/V10N1/10119ijaia02.pdf\n",
    "\n",
    "The application consists of two modules, a Natural Language Processing module and a classifier module. The NLP module is responsible for cleaning and tokenizing the raw input, whilst the classification module is doing the actual classification. \n",
    "\n",
    "The NLP module is divided into four parts:\n",
    "- Tokenization, where sentences are converted into a list of tokens\n",
    "- Stop Word Deletion, deletion of unimportant words\n",
    "- Parts of Speech Tagging, and deletion of non-noun non-pronouns\n",
    "- Named Entity Recognition, removing names, places etc.\n",
    "\n",
    "The classification module is a voting classifier of five individual classifiers: Naive Bayes, Multinomial Naive Bayes, Linear SVC, Bernoulli Naive Bayes and Logistic Regression. The voting is weighted by how the classifier performed on the training set and soft, meaning that the confidence of the classifications are taken into account.\n",
    "\n",
    "If the the tokens are words that the classifier haven't yet been trained on, the tokens are sent to Stack Overflow REST API which returns related topics for each of the tokens. The classifiers are then retrained with the new data and a new prediction is made. This increases the performance of the classifier by 8.3 %.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
