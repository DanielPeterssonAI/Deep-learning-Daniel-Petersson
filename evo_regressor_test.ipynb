{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "X_train, y_train = df[~df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]], df[~df[\"horsepower\"].isna()][\"horsepower\"]\n",
    "X_pred = df[df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred = np.round(y_pred)\n",
    "df.loc[X_pred.index, \"horsepower\"] = y_pred\n",
    "df = pd.get_dummies(df.drop(\"name\", axis = 1), columns = [\"origin\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"mpg\"], axis = 1).values, df[\"mpg\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from evolutionary_algos import EvoMLPRegressor\n",
    "\n",
    "class EvoMLPRegressor:\n",
    "\n",
    "    '''THIS IS THE ONE TO USE'''\n",
    "\n",
    "    def __init__(self, n = 24, hidden_layers = False, activation = \"relu\", lr_decay = 20, random_state = None):\n",
    "\n",
    "        self.n = int(round(n / 8) * 8)\n",
    "        self.validation_loss_history = []\n",
    "        self.training_loss_history = []\n",
    "        self.random_state = random_state\n",
    "        self.activation = activation\n",
    "        self.lr_decay = lr_decay\n",
    "        \n",
    "        if hidden_layers:\n",
    "            self.layers = hidden_layers + [1]\n",
    "        else:\n",
    "            self.layers = [1]\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0):\n",
    "\n",
    "        if self.random_state != None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        if validation_data:\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == \"leaky_relu\":\n",
    "            activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        elif self.activation == \"relu\":\n",
    "            activation_function = lambda x: np.maximum(0, x)\n",
    "\n",
    "        X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "\n",
    "        n = self.n\n",
    "        ndiv4 = n // 4\n",
    "\n",
    "        lr_decay = self.lr_decay\n",
    "\n",
    "        layers = [X_train.shape[1]] + self.layers\n",
    "\n",
    "        number_of_layers_minus_one = len(layers) - 1\n",
    "\n",
    "        y_preds = np.zeros((n, y_train.shape[0]))\n",
    "\n",
    "        nets_loss = np.zeros(n)\n",
    "        sorted_indices = np.arange(-(ndiv4), n, 1)\n",
    "        \n",
    "        best_net_index = -1\n",
    "        \n",
    "        weights = []\n",
    "\n",
    "        for i in range(number_of_layers_minus_one):\n",
    "            weights += [np.random.normal(0, 2, (n, layers[i], layers[i + 1]))]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            forward_pass = X_train.T\n",
    "            \n",
    "            for j in range(number_of_layers_minus_one - 1):\n",
    "                forward_pass = activation_function(weights[j][sorted_indices[ndiv4:]].transpose(0, 2, 1) @ forward_pass)\n",
    "\n",
    "            forward_pass = weights[-1][sorted_indices[ndiv4:]].transpose(0, 2, 1) @ forward_pass\n",
    "            \n",
    "            y_preds[sorted_indices[ndiv4:]] = forward_pass.reshape(*forward_pass.shape[::2])\n",
    "\n",
    "            nets_loss[sorted_indices[ndiv4:]] = np.mean(np.abs(y_preds[sorted_indices[ndiv4:]] - y_train), axis = 1)\n",
    "\n",
    "            sorted_indices = np.argsort(nets_loss)\n",
    "\n",
    "            mutation_sigma = math.exp(-epoch / (epochs / (lr_decay * math.log10(epochs + 1)))) + 0.02 * math.exp(-(epoch + 1) * (1 / (epochs + 1))) - 0.005\n",
    "            \n",
    "            for j in range(number_of_layers_minus_one):\n",
    "                weights[j][sorted_indices[0 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[1 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[2 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[3 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[4 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "                weights[j][sorted_indices[5 + ndiv4::6]] = (weights[j][sorted_indices[0: ndiv4: 2]] + weights[j][sorted_indices[1: ndiv4: 2]]) / 2 + np.random.normal(0, mutation_sigma, (ndiv4 // 2, layers[j], layers[j + 1]))\n",
    "\n",
    "            if best_net_index != sorted_indices[0]:\n",
    "                best_net_index = sorted_indices[0]\n",
    "                self.training_loss_history += [nets_loss[best_net_index]]\n",
    "\n",
    "                self.best_net_weights = []\n",
    "                for j in range(number_of_layers_minus_one):\n",
    "                    self.best_net_weights += [weights[j][best_net_index]]\n",
    "                \n",
    "                if validation_data:\n",
    "                    self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
    "                    if verbose == 1:\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]} - mutation_sigma: {mutation_sigma}\")\n",
    "                else:\n",
    "                    if verbose == 1:\n",
    "                        pass\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]}\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == \"leaky_relu\":\n",
    "            activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        else:\n",
    "            activation_function = lambda x: np.maximum(0, x)\n",
    "\n",
    "        forward_pass = X.T\n",
    "        for j in range(len(self.best_net_weights) - 1):\n",
    "            forward_pass = activation_function(self.best_net_weights[j].T @ forward_pass)\n",
    "\n",
    "        forward_pass = self.best_net_weights[-1].T @ forward_pass\n",
    "        return forward_pass.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 7.737057559160331 - val_loss: 8.01487563511419 - mutation_sigma: 1.0149980002999568\n",
      "Epoch 1 - loss: 7.510331828695556 - val_loss: 8.968397931066926 - mutation_sigma: 1.0070278294744286\n",
      "Epoch 2 - loss: 6.5947106040460755 - val_loss: 7.0458890972361505 - mutation_sigma: 0.9991211506030916\n",
      "Epoch 4 - loss: 5.829510974233065 - val_loss: 4.908348079817188 - mutation_sigma: 0.9834962491014118\n",
      "Epoch 5 - loss: 5.281573644652448 - val_loss: 4.607294742401278 - mutation_sigma: 0.9757770267061644\n",
      "Epoch 10 - loss: 5.112338479928962 - val_loss: 4.755319630232976 - mutation_sigma: 0.9380935589113272\n",
      "Epoch 11 - loss: 4.900885896319837 - val_loss: 5.699607911615603 - mutation_sigma: 0.9307360185968425\n",
      "Epoch 20 - loss: 4.733582000861924 - val_loss: 4.326982884667847 - mutation_sigma: 0.8671003569760438\n",
      "Epoch 25 - loss: 4.634677176188427 - val_loss: 4.266749060398398 - mutation_sigma: 0.8336770480449884\n",
      "Epoch 31 - loss: 4.596983524063516 - val_loss: 4.909666057905956 - mutation_sigma: 0.7952939508383862\n",
      "Epoch 32 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677 - mutation_sigma: 0.7890739325449794\n",
      "Epoch 48 - loss: 3.913337989896924 - val_loss: 4.15412824898813 - mutation_sigma: 0.6960308369953331\n",
      "Epoch 53 - loss: 3.5760343636423015 - val_loss: 3.5443791654741332 - mutation_sigma: 0.6693131712285929\n",
      "Epoch 59 - loss: 3.505001437926961 - val_loss: 3.342708554591469 - mutation_sigma: 0.6386306877599001\n",
      "Epoch 68 - loss: 3.5000433360136887 - val_loss: 3.3229922460243655 - mutation_sigma: 0.5952809758259879\n",
      "Epoch 71 - loss: 3.4039652344390032 - val_loss: 2.491508669678962 - mutation_sigma: 0.581510658453911\n",
      "Epoch 73 - loss: 3.339316649783786 - val_loss: 2.528769459576549 - mutation_sigma: 0.5725122714739252\n",
      "Epoch 81 - loss: 3.1005799648925514 - val_loss: 2.8486087312841484 - mutation_sigma: 0.537923919886711\n",
      "Epoch 82 - loss: 3.0222522288176834 - val_loss: 2.542217669668907 - mutation_sigma: 0.5337538878243995\n",
      "Epoch 87 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344 - mutation_sigma: 0.5133966451729272\n",
      "Epoch 105 - loss: 2.580664007832874 - val_loss: 2.2381378983115447 - mutation_sigma: 0.4464957269792484\n",
      "Epoch 133 - loss: 2.559722965143909 - val_loss: 2.278871614253666 - mutation_sigma: 0.35980258295186685\n",
      "Epoch 135 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507 - mutation_sigma: 0.354321411860374\n",
      "Epoch 144 - loss: 2.389766900525124 - val_loss: 2.2600978971897896 - mutation_sigma: 0.3307122973896719\n",
      "Epoch 152 - loss: 2.3175483599393893 - val_loss: 1.9666911107254528 - mutation_sigma: 0.3111058985320412\n",
      "Epoch 155 - loss: 2.2213342418936124 - val_loss: 1.892180138493059 - mutation_sigma: 0.30407077385151215\n",
      "Epoch 156 - loss: 2.210068066118549 - val_loss: 1.9522225317515347 - mutation_sigma: 0.30176297311661315\n",
      "Epoch 159 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072 - mutation_sigma: 0.29494922724001665\n",
      "Epoch 196 - loss: 2.1693622563992427 - val_loss: 1.8299758409572484 - mutation_sigma: 0.223068034541863\n",
      "Epoch 200 - loss: 2.161356898359588 - val_loss: 1.595117302756535 - mutation_sigma: 0.21649506346167388\n",
      "Epoch 208 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518 - mutation_sigma: 0.20396290076620066\n",
      "Epoch 222 - loss: 2.0442635165005583 - val_loss: 1.6074319218259039 - mutation_sigma: 0.18386976588240353\n",
      "Epoch 223 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914 - mutation_sigma: 0.18251871292664165\n",
      "Epoch 254 - loss: 2.023776672506467 - val_loss: 1.63546868534046 - mutation_sigma: 0.14556671831309415\n",
      "Epoch 255 - loss: 2.008583950839811 - val_loss: 1.7799745180328777 - mutation_sigma: 0.14452037897899978\n",
      "Epoch 257 - loss: 1.96214626183952 - val_loss: 1.7028261526232193 - mutation_sigma: 0.14245260022015568\n",
      "Epoch 287 - loss: 1.9562957160859948 - val_loss: 1.7390892167771905 - mutation_sigma: 0.11509044437857555\n",
      "Epoch 289 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315 - mutation_sigma: 0.11348882652871345\n",
      "Epoch 310 - loss: 1.9309500390857222 - val_loss: 1.6945487480502677 - mutation_sigma: 0.0981286037403341\n",
      "Epoch 316 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782 - mutation_sigma: 0.09419231204775427\n",
      "Epoch 325 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753 - mutation_sigma: 0.08863005782048594\n",
      "Epoch 335 - loss: 1.9154285492142349 - val_loss: 1.7158586732435797 - mutation_sigma: 0.08290038843558935\n",
      "Epoch 338 - loss: 1.9151044388582628 - val_loss: 1.6958512782525275 - mutation_sigma: 0.08126869144624821\n",
      "Epoch 339 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811 - mutation_sigma: 0.08073340675337005\n",
      "Epoch 348 - loss: 1.888355758967431 - val_loss: 1.6014800276604366 - mutation_sigma: 0.076103088402792\n",
      "Epoch 349 - loss: 1.8794305645636966 - val_loss: 1.6818342037238376 - mutation_sigma: 0.07560881209217199\n",
      "Epoch 353 - loss: 1.8711496975960402 - val_loss: 1.64841652285107 - mutation_sigma: 0.07367062833338604\n",
      "Epoch 364 - loss: 1.870995206111572 - val_loss: 1.7016134081101768 - mutation_sigma: 0.06864840075777043\n",
      "Epoch 369 - loss: 1.854219956480461 - val_loss: 1.5969568338314086 - mutation_sigma: 0.06650705108406649\n",
      "Epoch 379 - loss: 1.8532092059376457 - val_loss: 1.6204742064508082 - mutation_sigma: 0.062471848149197894\n",
      "Epoch 383 - loss: 1.8495022176064686 - val_loss: 1.537384180940168 - mutation_sigma: 0.06094559811434317\n",
      "Epoch 388 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047 - mutation_sigma: 0.05910486604972901\n",
      "Epoch 400 - loss: 1.8291662439109284 - val_loss: 1.561813038150841 - mutation_sigma: 0.05497473219005386\n",
      "Epoch 402 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756 - mutation_sigma: 0.05432390026163654\n",
      "Epoch 415 - loss: 1.8223668040710084 - val_loss: 1.5079992643264213 - mutation_sigma: 0.05033667656789271\n",
      "Epoch 419 - loss: 1.8180591447725498 - val_loss: 1.5916522063030418 - mutation_sigma: 0.0491904574455904\n",
      "Epoch 425 - loss: 1.8151129171360803 - val_loss: 1.5854997139467533 - mutation_sigma: 0.04753801233339985\n",
      "Epoch 427 - loss: 1.8069069448466806 - val_loss: 1.5124144206687609 - mutation_sigma: 0.04700447052065555\n",
      "Epoch 431 - loss: 1.806438573789528 - val_loss: 1.6009515284457183 - mutation_sigma: 0.0459624797293419\n",
      "Epoch 440 - loss: 1.804257465046809 - val_loss: 1.5614015536611947 - mutation_sigma: 0.0437355537412688\n",
      "Epoch 442 - loss: 1.801706834485771 - val_loss: 1.6365161345341235 - mutation_sigma: 0.04326191759021416\n",
      "Epoch 446 - loss: 1.8009563614907615 - val_loss: 1.5822342711172328 - mutation_sigma: 0.04233690086306476\n",
      "Epoch 448 - loss: 1.7985136144097837 - val_loss: 1.6036817457436192 - mutation_sigma: 0.041885285430947085\n",
      "Epoch 449 - loss: 1.7959964813126112 - val_loss: 1.526056797692123 - mutation_sigma: 0.04166215049038336\n",
      "Epoch 450 - loss: 1.7897790210188556 - val_loss: 1.541225200561767 - mutation_sigma: 0.0414407784840066\n",
      "Epoch 453 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587 - mutation_sigma: 0.040787100170129174\n",
      "Epoch 466 - loss: 1.7881156066846802 - val_loss: 1.5935755067461455 - mutation_sigma: 0.03812745897501384\n",
      "Epoch 470 - loss: 1.7799616539797742 - val_loss: 1.5998823158004296 - mutation_sigma: 0.03736271964351303\n",
      "Epoch 471 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255 - mutation_sigma: 0.037175290677730455\n",
      "Epoch 479 - loss: 1.7783441329002132 - val_loss: 1.5657429105747838 - mutation_sigma: 0.035728105653352056\n",
      "Epoch 481 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885 - mutation_sigma: 0.03538040317591349\n",
      "Epoch 488 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654 - mutation_sigma: 0.034205871183812124\n",
      "Epoch 495 - loss: 1.776259104217378 - val_loss: 1.6172353922848757 - mutation_sigma: 0.03309458896676531\n",
      "Epoch 496 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654 - mutation_sigma: 0.03294079439253083\n",
      "Epoch 511 - loss: 1.764155044742701 - val_loss: 1.5406418243586515 - mutation_sigma: 0.03077387107931785\n",
      "Epoch 515 - loss: 1.7631299917064658 - val_loss: 1.5631614281014312 - mutation_sigma: 0.030238059326832798\n",
      "Epoch 520 - loss: 1.7623378758170634 - val_loss: 1.570258071146122 - mutation_sigma: 0.02959163070501022\n",
      "Epoch 521 - loss: 1.7599696061276071 - val_loss: 1.5707671051647425 - mutation_sigma: 0.029465374433176244\n",
      "Epoch 523 - loss: 1.7582424283285596 - val_loss: 1.5680381689850313 - mutation_sigma: 0.029215827282581906\n",
      "Epoch 524 - loss: 1.75402615743999 - val_loss: 1.5680926674056992 - mutation_sigma: 0.029092520675272824\n",
      "Epoch 540 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098 - mutation_sigma: 0.027246109625623186\n",
      "Epoch 554 - loss: 1.7466804076050904 - val_loss: 1.5439246282243797 - mutation_sigma: 0.02581045784175193\n",
      "Epoch 559 - loss: 1.7466118735383698 - val_loss: 1.5732276844934583 - mutation_sigma: 0.02533477804341309\n",
      "Epoch 560 - loss: 1.7460381342113067 - val_loss: 1.514554438737896 - mutation_sigma: 0.025241859729949776\n",
      "Epoch 561 - loss: 1.742950017805513 - val_loss: 1.5361445369192621 - mutation_sigma: 0.02514966692831948\n",
      "Epoch 564 - loss: 1.7412651519751683 - val_loss: 1.5111243194623012 - mutation_sigma: 0.024877384029169055\n",
      "Epoch 566 - loss: 1.7403107512094358 - val_loss: 1.559605891963243 - mutation_sigma: 0.024699384918770537\n",
      "Epoch 569 - loss: 1.739605461935401 - val_loss: 1.530268586265701 - mutation_sigma: 0.024437558978519253\n",
      "Epoch 573 - loss: 1.7393697104844608 - val_loss: 1.5512218096661392 - mutation_sigma: 0.02409788486037692\n",
      "Epoch 574 - loss: 1.739205797302013 - val_loss: 1.5453294240095399 - mutation_sigma: 0.02401461417810461\n",
      "Epoch 575 - loss: 1.7360637365025036 - val_loss: 1.5461656595121493 - mutation_sigma: 0.02393199215449855\n",
      "Epoch 578 - loss: 1.735630613300042 - val_loss: 1.4842882173835465 - mutation_sigma: 0.023687966569832613\n",
      "Epoch 580 - loss: 1.7333939767503346 - val_loss: 1.531364632105483 - mutation_sigma: 0.023528432500799234\n",
      "Epoch 582 - loss: 1.7323768692986115 - val_loss: 1.534465452545016 - mutation_sigma: 0.02337137153893803\n",
      "Epoch 583 - loss: 1.7321788366233208 - val_loss: 1.499531703454028 - mutation_sigma: 0.02329375618517539\n",
      "Epoch 585 - loss: 1.7307067744682159 - val_loss: 1.498881528236468 - mutation_sigma: 0.0231403314976806\n",
      "Epoch 587 - loss: 1.7294842420149017 - val_loss: 1.503549936772614 - mutation_sigma: 0.022989282973622068\n",
      "Epoch 591 - loss: 1.7292711298550967 - val_loss: 1.5176654613723755 - mutation_sigma: 0.022694164195629783\n",
      "Epoch 594 - loss: 1.726997768850053 - val_loss: 1.5492679058088765 - mutation_sigma: 0.022478786440017794\n",
      "Epoch 595 - loss: 1.7261082044570486 - val_loss: 1.5241542283617706 - mutation_sigma: 0.022408105338765676\n",
      "Epoch 599 - loss: 1.7256136755329385 - val_loss: 1.4974519908053685 - mutation_sigma: 0.02213082116586163\n",
      "Epoch 600 - loss: 1.7252279364529362 - val_loss: 1.5049623990735275 - mutation_sigma: 0.022062838600181354\n",
      "Epoch 601 - loss: 1.7243256058350935 - val_loss: 1.5053657713100879 - mutation_sigma: 0.02199538291340768\n",
      "Epoch 605 - loss: 1.7212225662129799 - val_loss: 1.5290890937073818 - mutation_sigma: 0.02173074551979345\n",
      "Epoch 610 - loss: 1.7209217416447282 - val_loss: 1.490496839719547 - mutation_sigma: 0.021411309727809417\n",
      "Epoch 611 - loss: 1.7199605413872066 - val_loss: 1.522133873930876 - mutation_sigma: 0.021348897437936925\n",
      "Epoch 619 - loss: 1.718658215655511 - val_loss: 1.4796551888575085 - mutation_sigma: 0.02086665048459224\n",
      "Epoch 620 - loss: 1.7158997173797115 - val_loss: 1.513453916780404 - mutation_sigma: 0.020808444972335093\n",
      "Epoch 625 - loss: 1.715151838834765 - val_loss: 1.5296853566272057 - mutation_sigma: 0.02052408136109617\n",
      "Epoch 626 - loss: 1.7143720658833508 - val_loss: 1.505212338636334 - mutation_sigma: 0.020468516791157118\n",
      "Epoch 635 - loss: 1.7109478138702108 - val_loss: 1.5238941688419954 - mutation_sigma: 0.019987290863024098\n",
      "Epoch 638 - loss: 1.7096352101859185 - val_loss: 1.4890912539036238 - mutation_sigma: 0.019834167777814767\n",
      "Epoch 642 - loss: 1.708440954604318 - val_loss: 1.510154624032653 - mutation_sigma: 0.01963543285216051\n",
      "Epoch 644 - loss: 1.7081257296126242 - val_loss: 1.4958803411039603 - mutation_sigma: 0.01953833699551024\n",
      "Epoch 647 - loss: 1.7063782658958269 - val_loss: 1.487920463658274 - mutation_sigma: 0.019395465369031677\n",
      "Epoch 648 - loss: 1.705653300556553 - val_loss: 1.4954504084561548 - mutation_sigma: 0.01934856900007133\n",
      "Epoch 651 - loss: 1.705333518700015 - val_loss: 1.5066961285634057 - mutation_sigma: 0.01921002207031661\n",
      "Epoch 653 - loss: 1.7039811355868277 - val_loss: 1.5104444961734165 - mutation_sigma: 0.01911941429618765\n",
      "Epoch 654 - loss: 1.7035523053925126 - val_loss: 1.512511728638961 - mutation_sigma: 0.019074629090329403\n",
      "Epoch 659 - loss: 1.7034174007308667 - val_loss: 1.539003342162316 - mutation_sigma: 0.018855780666425934\n",
      "Epoch 661 - loss: 1.7030351033931648 - val_loss: 1.5126744468832705 - mutation_sigma: 0.018770560891268735\n",
      "Epoch 662 - loss: 1.7027367548497458 - val_loss: 1.5060440586333737 - mutation_sigma: 0.018728437546110508\n",
      "Epoch 665 - loss: 1.698695239222831 - val_loss: 1.5155143808052176 - mutation_sigma: 0.018603982827019933\n",
      "Epoch 672 - loss: 1.6974853076129377 - val_loss: 1.4745067193513004 - mutation_sigma: 0.01832443964259058\n",
      "Epoch 676 - loss: 1.6972898747608398 - val_loss: 1.5467003670344692 - mutation_sigma: 0.018171271776579727\n",
      "Epoch 678 - loss: 1.697168381051914 - val_loss: 1.505829908194616 - mutation_sigma: 0.018096418735436857\n",
      "Epoch 680 - loss: 1.696914368875435 - val_loss: 1.5008701796143022 - mutation_sigma: 0.01802269524895053\n",
      "Epoch 683 - loss: 1.696352378010625 - val_loss: 1.5062800666303593 - mutation_sigma: 0.017914188817473573\n",
      "Epoch 685 - loss: 1.6960374554833368 - val_loss: 1.4962515551630509 - mutation_sigma: 0.017843211449281363\n",
      "Epoch 690 - loss: 1.6947684487633414 - val_loss: 1.4970305297276991 - mutation_sigma: 0.01767040388218275\n",
      "Epoch 692 - loss: 1.6946052096226003 - val_loss: 1.5462865639226144 - mutation_sigma: 0.017603091252803977\n",
      "Epoch 693 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598 - mutation_sigma: 0.01756981467610096\n",
      "Epoch 701 - loss: 1.6930717643274076 - val_loss: 1.509371985665412 - mutation_sigma: 0.01731245354470898\n",
      "Epoch 706 - loss: 1.692434030765556 - val_loss: 1.5255420358341263 - mutation_sigma: 0.017159301919106376\n",
      "Epoch 710 - loss: 1.692142700935924 - val_loss: 1.5159898515246275 - mutation_sigma: 0.017040855386663206\n",
      "Epoch 712 - loss: 1.6912990209535448 - val_loss: 1.5087313671464395 - mutation_sigma: 0.016982951067119872\n",
      "Epoch 715 - loss: 1.6911185376158928 - val_loss: 1.5056467992673657 - mutation_sigma: 0.01689770418024372\n",
      "Epoch 716 - loss: 1.6910082086417622 - val_loss: 1.495912258256612 - mutation_sigma: 0.016869710964267835\n",
      "Epoch 718 - loss: 1.6892950900791364 - val_loss: 1.50273339224132 - mutation_sigma: 0.016814348096532466\n",
      "Epoch 720 - loss: 1.68875171111645 - val_loss: 1.4964446907206912 - mutation_sigma: 0.016759805652651893\n",
      "Epoch 726 - loss: 1.6872407691104763 - val_loss: 1.4929733915197025 - mutation_sigma: 0.0166009717854485\n",
      "Epoch 730 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405 - mutation_sigma: 0.016498951572685366\n",
      "Epoch 737 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705 - mutation_sigma: 0.016327534510095217\n",
      "Epoch 745 - loss: 1.6843038397447672 - val_loss: 1.4980112666756435 - mutation_sigma: 0.016142176660412812\n",
      "Epoch 747 - loss: 1.6837646923798686 - val_loss: 1.4920001984160052 - mutation_sigma: 0.016097517008078998\n",
      "Epoch 748 - loss: 1.6815400839026688 - val_loss: 1.5079980592456197 - mutation_sigma: 0.01607543184392674\n",
      "Epoch 754 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844 - mutation_sigma: 0.01594626520299637\n",
      "Epoch 764 - loss: 1.678606209189609 - val_loss: 1.5009182064445405 - mutation_sigma: 0.015743167103918\n",
      "Epoch 769 - loss: 1.6775822478516285 - val_loss: 1.5160291855355896 - mutation_sigma: 0.015647016507831877\n",
      "Epoch 772 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165 - mutation_sigma: 0.015590972426211946\n",
      "Epoch 781 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927 - mutation_sigma: 0.015429921365728457\n",
      "Epoch 788 - loss: 1.675114926767903 - val_loss: 1.5182156300807688 - mutation_sigma: 0.015311641530773128\n",
      "Epoch 789 - loss: 1.673824369201371 - val_loss: 1.4987808326893184 - mutation_sigma: 0.015295220946124573\n",
      "Epoch 792 - loss: 1.6730280152906596 - val_loss: 1.4862613681490555 - mutation_sigma: 0.015246653308166064\n",
      "Epoch 794 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666 - mutation_sigma: 0.015214844152080405\n",
      "Epoch 808 - loss: 1.6705289085350614 - val_loss: 1.4701504725041372 - mutation_sigma: 0.015004307176521705\n",
      "Epoch 809 - loss: 1.6704686532500106 - val_loss: 1.4720747509752061 - mutation_sigma: 0.01499004495223458\n",
      "Epoch 812 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085 - mutation_sigma: 0.014947849926667606\n",
      "Epoch 821 - loss: 1.6670721445570622 - val_loss: 1.474692828512551 - mutation_sigma: 0.014826409523965009\n",
      "Epoch 823 - loss: 1.6658819020704358 - val_loss: 1.4741190159945885 - mutation_sigma: 0.014800432402400174\n",
      "Epoch 826 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442 - mutation_sigma: 0.014762129831800377\n",
      "Epoch 837 - loss: 1.6648559849230902 - val_loss: 1.4755556077612546 - mutation_sigma: 0.014628212898870174\n",
      "Epoch 840 - loss: 1.6639619720958985 - val_loss: 1.4712610586091115 - mutation_sigma: 0.014593391160156986\n",
      "Epoch 841 - loss: 1.6638914869138612 - val_loss: 1.4884123433153642 - mutation_sigma: 0.014581939540008717\n",
      "Epoch 847 - loss: 1.6638781942467098 - val_loss: 1.4652805688444184 - mutation_sigma: 0.01451482107783781\n",
      "Epoch 849 - loss: 1.6613669182008606 - val_loss: 1.4943225371740951 - mutation_sigma: 0.01449304011937546\n",
      "Epoch 850 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644 - mutation_sigma: 0.0144822579804051\n",
      "Epoch 861 - loss: 1.659905797090408 - val_loss: 1.4565844985810863 - mutation_sigma: 0.014368248195888535\n",
      "Epoch 864 - loss: 1.6590084626552613 - val_loss: 1.4701893675523645 - mutation_sigma: 0.014338559178370486\n",
      "Epoch 869 - loss: 1.6587444026080567 - val_loss: 1.468069603491669 - mutation_sigma: 0.014290348991362719\n",
      "Epoch 871 - loss: 1.6583405134688463 - val_loss: 1.4645905686395646 - mutation_sigma: 0.0142714982597059\n",
      "Epoch 875 - loss: 1.6568021067649628 - val_loss: 1.487832968400229 - mutation_sigma: 0.014234518244266258\n",
      "Epoch 880 - loss: 1.6560872098007888 - val_loss: 1.4688288529518012 - mutation_sigma: 0.014189607030501261\n",
      "Epoch 883 - loss: 1.655189336770723 - val_loss: 1.494473412397927 - mutation_sigma: 0.014163338984989744\n",
      "Epoch 893 - loss: 1.654787685576 - val_loss: 1.486376028497698 - mutation_sigma: 0.014079283846554307\n",
      "Epoch 899 - loss: 1.6535480784899257 - val_loss: 1.4943725310453781 - mutation_sigma: 0.014031311885722604\n",
      "Epoch 904 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879 - mutation_sigma: 0.013992668499623419\n",
      "Epoch 927 - loss: 1.6514359646964234 - val_loss: 1.4753617425050969 - mutation_sigma: 0.013829186389930713\n",
      "Epoch 932 - loss: 1.651246206537777 - val_loss: 1.4598430881910627 - mutation_sigma: 0.013796490250640139\n",
      "Epoch 937 - loss: 1.651135997566617 - val_loss: 1.4942517331738099 - mutation_sigma: 0.013764723475059835\n",
      "Epoch 944 - loss: 1.6508516698489393 - val_loss: 1.4582764362354674 - mutation_sigma: 0.013721742543775648\n",
      "Epoch 945 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345 - mutation_sigma: 0.01371573972730276\n",
      "Epoch 957 - loss: 1.6495275162810914 - val_loss: 1.4805903245828849 - mutation_sigma: 0.013646245706365315\n",
      "Epoch 958 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717 - mutation_sigma: 0.013640658473338535\n",
      "Epoch 966 - loss: 1.6484735653856282 - val_loss: 1.4783408855616238 - mutation_sigma: 0.013597028775399662\n",
      "Epoch 970 - loss: 1.6478457331618466 - val_loss: 1.4461332716670796 - mutation_sigma: 0.01357590196808647\n",
      "Epoch 975 - loss: 1.6475169451201648 - val_loss: 1.4829689833208737 - mutation_sigma: 0.013550110031756053\n",
      "Epoch 978 - loss: 1.645181907660707 - val_loss: 1.45997006650999 - mutation_sigma: 0.013534953413423218\n",
      "Epoch 987 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699 - mutation_sigma: 0.013490854063524276\n",
      "Epoch 999 - loss: 1.6432171060057628 - val_loss: 1.4412142395130065 - mutation_sigma: 0.013435057063585856\n",
      "Epoch 1005 - loss: 1.6423787383507042 - val_loss: 1.429135197763711 - mutation_sigma: 0.013408356312654635\n",
      "Epoch 1007 - loss: 1.641840988642151 - val_loss: 1.4411689886500796 - mutation_sigma: 0.013399624305504943\n",
      "Epoch 1020 - loss: 1.641001476442525 - val_loss: 1.4575943784928775 - mutation_sigma: 0.013344806498173978\n",
      "Epoch 1035 - loss: 1.640139760144246 - val_loss: 1.462198376644603 - mutation_sigma: 0.01328541839330347\n",
      "Epoch 1036 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387 - mutation_sigma: 0.013281595427096476\n",
      "Epoch 1050 - loss: 1.6383806888283725 - val_loss: 1.4565238873397193 - mutation_sigma: 0.013229725921898808\n",
      "Epoch 1055 - loss: 1.6367983936898376 - val_loss: 1.451633576709871 - mutation_sigma: 0.01321191016863774\n",
      "Epoch 1057 - loss: 1.6354518655548598 - val_loss: 1.444876708338808 - mutation_sigma: 0.013204882694777102\n",
      "Epoch 1073 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547 - mutation_sigma: 0.013150577344193577\n",
      "Epoch 1083 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904 - mutation_sigma: 0.013118242764930808\n",
      "Epoch 1091 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805 - mutation_sigma: 0.013093188331085973\n",
      "Epoch 1098 - loss: 1.6325507871019767 - val_loss: 1.4624848293839974 - mutation_sigma: 0.013071820964650639\n",
      "Epoch 1099 - loss: 1.6323963909816246 - val_loss: 1.4352683463359852 - mutation_sigma: 0.013068809044040102\n",
      "Epoch 1105 - loss: 1.6320523203536097 - val_loss: 1.442748436420223 - mutation_sigma: 0.013050942789699774\n",
      "Epoch 1112 - loss: 1.6310990515587733 - val_loss: 1.4348160708474755 - mutation_sigma: 0.013030527636103031\n",
      "Epoch 1117 - loss: 1.6309782387432177 - val_loss: 1.4450676056125766 - mutation_sigma: 0.013016215104671297\n",
      "Epoch 1122 - loss: 1.6309394872736378 - val_loss: 1.4402154068485826 - mutation_sigma: 0.013002117561733792\n",
      "Epoch 1124 - loss: 1.6308117877416752 - val_loss: 1.4469543973769583 - mutation_sigma: 0.012996536880786346\n",
      "Epoch 1126 - loss: 1.6302946005750518 - val_loss: 1.4542674355530585 - mutation_sigma: 0.012990988759510606\n",
      "Epoch 1129 - loss: 1.6286865310588001 - val_loss: 1.4531830846577525 - mutation_sigma: 0.012982726523150974\n",
      "Epoch 1135 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596 - mutation_sigma: 0.012966411769711566\n",
      "Epoch 1145 - loss: 1.628251488607008 - val_loss: 1.4497247983174926 - mutation_sigma: 0.01293981203753684\n",
      "Epoch 1147 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825 - mutation_sigma: 0.012934576749867008\n",
      "Epoch 1160 - loss: 1.6274908659627139 - val_loss: 1.463378420713023 - mutation_sigma: 0.012901192059498724\n",
      "Epoch 1164 - loss: 1.6274720500515067 - val_loss: 1.4335168875937137 - mutation_sigma: 0.012891133861854226\n",
      "Epoch 1166 - loss: 1.627306901284965 - val_loss: 1.4571554896967558 - mutation_sigma: 0.012886140703546739\n",
      "Epoch 1173 - loss: 1.6264614606280987 - val_loss: 1.4467500185857407 - mutation_sigma: 0.01286884710881767\n",
      "Epoch 1175 - loss: 1.6262930171581862 - val_loss: 1.457137721251174 - mutation_sigma: 0.012863956751731565\n",
      "Epoch 1179 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475 - mutation_sigma: 0.0128542413629478\n",
      "Epoch 1188 - loss: 1.625127579994084 - val_loss: 1.439401800284108 - mutation_sigma: 0.012832688169937396\n",
      "Epoch 1191 - loss: 1.6248521605043231 - val_loss: 1.4417814853160995 - mutation_sigma: 0.012825594250136536\n",
      "Epoch 1197 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633 - mutation_sigma: 0.012811535976500098\n",
      "Epoch 1204 - loss: 1.6233245589852225 - val_loss: 1.4389355433959061 - mutation_sigma: 0.012795344235722265\n",
      "Epoch 1209 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938 - mutation_sigma: 0.012783910656181736\n",
      "Epoch 1217 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004 - mutation_sigma: 0.012765834242878808\n",
      "Epoch 1243 - loss: 1.6200211047631083 - val_loss: 1.436108879588107 - mutation_sigma: 0.01270876054569801\n",
      "Epoch 1244 - loss: 1.619855971261856 - val_loss: 1.428986994191229 - mutation_sigma: 0.012706612186151395\n",
      "Epoch 1248 - loss: 1.6193780821707704 - val_loss: 1.437371191651899 - mutation_sigma: 0.012698050753598901\n",
      "Epoch 1258 - loss: 1.6185370437239284 - val_loss: 1.436711970050596 - mutation_sigma: 0.012676862953887359\n",
      "Epoch 1273 - loss: 1.6183982544676203 - val_loss: 1.4366507717559354 - mutation_sigma: 0.012645618942979057\n",
      "Epoch 1275 - loss: 1.6181907776349702 - val_loss: 1.4130167894093848 - mutation_sigma: 0.012641498627954616\n",
      "Epoch 1279 - loss: 1.617765484813033 - val_loss: 1.4266342654312276 - mutation_sigma: 0.01263328850370533\n",
      "Epoch 1282 - loss: 1.6176321458578218 - val_loss: 1.4223267805951552 - mutation_sigma: 0.012627157013750254\n",
      "Epoch 1283 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502 - mutation_sigma: 0.01262511805800207\n",
      "Epoch 1319 - loss: 1.6150821890880886 - val_loss: 1.445944149722168 - mutation_sigma: 0.012553189385673378\n",
      "Epoch 1338 - loss: 1.614904506640372 - val_loss: 1.4349248220355644 - mutation_sigma: 0.012516237105358992\n",
      "Epoch 1340 - loss: 1.6144670567326984 - val_loss: 1.406961305451305 - mutation_sigma: 0.012512382665557716\n",
      "Epoch 1353 - loss: 1.6133852364182015 - val_loss: 1.429062068634201 - mutation_sigma: 0.012487479793246704\n",
      "Epoch 1356 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178 - mutation_sigma: 0.012481768595814981\n",
      "Epoch 1368 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756 - mutation_sigma: 0.012459048878826453\n",
      "Epoch 1394 - loss: 1.611393417969238 - val_loss: 1.4147221352571573 - mutation_sigma: 0.012410447942107428\n",
      "Epoch 1404 - loss: 1.61108893014879 - val_loss: 1.4133569434618303 - mutation_sigma: 0.01239195937753013\n",
      "Epoch 1408 - loss: 1.6100370515085605 - val_loss: 1.4248052841520882 - mutation_sigma: 0.012384592937248091\n",
      "Epoch 1409 - loss: 1.608086364130082 - val_loss: 1.4044837241798498 - mutation_sigma: 0.01238275383001582\n",
      "Epoch 1450 - loss: 1.607722106586941 - val_loss: 1.4074509710703471 - mutation_sigma: 0.01230813181865854\n",
      "Epoch 1451 - loss: 1.6070694531804026 - val_loss: 1.414723272242064 - mutation_sigma: 0.01230632915365721\n",
      "Epoch 1460 - loss: 1.6070412894063324 - val_loss: 1.4066603490026868 - mutation_sigma: 0.012290138585453119\n",
      "Epoch 1464 - loss: 1.6069294910239662 - val_loss: 1.4129183863061507 - mutation_sigma: 0.012282961541032613\n",
      "Epoch 1465 - loss: 1.6055211443740645 - val_loss: 1.4159526710953128 - mutation_sigma: 0.012281169033377289\n",
      "Epoch 1471 - loss: 1.6045739276717523 - val_loss: 1.4153331542996632 - mutation_sigma: 0.01227042839459164\n",
      "Epoch 1473 - loss: 1.604516315891886 - val_loss: 1.4217820026536305 - mutation_sigma: 0.012266853572353006\n",
      "Epoch 1480 - loss: 1.6044840917131065 - val_loss: 1.3992090312734642 - mutation_sigma: 0.012254362298958286\n",
      "Epoch 1482 - loss: 1.603666870503361 - val_loss: 1.4206456593829184 - mutation_sigma: 0.01225079912482687\n",
      "Epoch 1485 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449 - mutation_sigma: 0.012245459053295913\n",
      "Epoch 1493 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931 - mutation_sigma: 0.012231245695648894\n",
      "Epoch 1509 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558 - mutation_sigma: 0.012202930253318877\n",
      "Epoch 1518 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342 - mutation_sigma: 0.012187064136710241\n",
      "Epoch 1547 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924 - mutation_sigma: 0.012136212791422102\n",
      "Epoch 1572 - loss: 1.597111293194125 - val_loss: 1.4104749087647837 - mutation_sigma: 0.012092675956640847\n",
      "Epoch 1587 - loss: 1.5962530980488563 - val_loss: 1.412116405493275 - mutation_sigma: 0.012066673379212082\n",
      "Epoch 1606 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132 - mutation_sigma: 0.012033854621601989\n",
      "Epoch 1634 - loss: 1.594782902662078 - val_loss: 1.4034583696954228 - mutation_sigma: 0.011985710639848587\n",
      "Epoch 1646 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097 - mutation_sigma: 0.011965152066497654\n",
      "Epoch 1657 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213 - mutation_sigma: 0.011946343682561832\n",
      "Epoch 1666 - loss: 1.5935303032250272 - val_loss: 1.4055526184665659 - mutation_sigma: 0.011930980389927213\n",
      "Epoch 1671 - loss: 1.5930591643789664 - val_loss: 1.411103491493929 - mutation_sigma: 0.011922454839179714\n",
      "Epoch 1679 - loss: 1.5921838656688483 - val_loss: 1.4127802192663867 - mutation_sigma: 0.011908827919633935\n",
      "Epoch 1685 - loss: 1.5915696852003385 - val_loss: 1.402539713195365 - mutation_sigma: 0.011898618796209355\n",
      "Epoch 1701 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899 - mutation_sigma: 0.011871439538823577\n",
      "Epoch 1712 - loss: 1.5902763229877228 - val_loss: 1.4044477775034891 - mutation_sigma: 0.011852790713706013\n",
      "Epoch 1716 - loss: 1.5901276282991317 - val_loss: 1.3749002354507798 - mutation_sigma: 0.011846016583358092\n",
      "Epoch 1717 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955 - mutation_sigma: 0.011844323647871587\n",
      "Epoch 1726 - loss: 1.5882287969133588 - val_loss: 1.3942791602441922 - mutation_sigma: 0.011829097857038447\n",
      "Epoch 1728 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998 - mutation_sigma: 0.01182571692182844\n",
      "Epoch 1785 - loss: 1.587364776806824 - val_loss: 1.3965704843945712 - mutation_sigma: 0.01172973528085168\n",
      "Epoch 1794 - loss: 1.5872908109002555 - val_loss: 1.405288577911579 - mutation_sigma: 0.011714643710036072\n",
      "Epoch 1796 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083 - mutation_sigma: 0.011711292285716015\n",
      "Epoch 1818 - loss: 1.5865965442565646 - val_loss: 1.3958038407687527 - mutation_sigma: 0.01167447992257397\n",
      "Epoch 1820 - loss: 1.5864597096736035 - val_loss: 1.391565936310267 - mutation_sigma: 0.011671138130315974\n",
      "Epoch 1822 - loss: 1.5862017395467638 - val_loss: 1.3924337237143682 - mutation_sigma: 0.011667797126331217\n",
      "Epoch 1826 - loss: 1.585954787361674 - val_loss: 1.3810002157590735 - mutation_sigma: 0.011661117474959577\n",
      "Epoch 1837 - loss: 1.5858652674646028 - val_loss: 1.393871992174292 - mutation_sigma: 0.011642764519349709\n",
      "Epoch 1844 - loss: 1.584520582251103 - val_loss: 1.4031067610714203 - mutation_sigma: 0.011631097539784876\n",
      "Epoch 1871 - loss: 1.58420216043585 - val_loss: 1.4134689494418264 - mutation_sigma: 0.011586183536188687\n",
      "Epoch 1873 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017 - mutation_sigma: 0.011582862013336793\n",
      "Epoch 1897 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354 - mutation_sigma: 0.01154306128719261\n",
      "Epoch 1952 - loss: 1.5800992610312556 - val_loss: 1.3947638620959 - mutation_sigma: 0.011452243357466245\n",
      "Epoch 1964 - loss: 1.5796429133793373 - val_loss: 1.382650600873259 - mutation_sigma: 0.011432499555124289\n",
      "Epoch 1990 - loss: 1.578875380900198 - val_loss: 1.3786316446811473 - mutation_sigma: 0.011389807018409262\n",
      "Epoch 2006 - loss: 1.577515469377503 - val_loss: 1.3820262076058842 - mutation_sigma: 0.01136359246326727\n",
      "Epoch 2042 - loss: 1.576582822600041 - val_loss: 1.379375140348381 - mutation_sigma: 0.011304768857411673\n",
      "Epoch 2073 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426 - mutation_sigma: 0.011254289964111572\n",
      "Epoch 2089 - loss: 1.5757596803440024 - val_loss: 1.3710288775113657 - mutation_sigma: 0.01122829905241151\n",
      "Epoch 2093 - loss: 1.5745429566747737 - val_loss: 1.3727699961498507 - mutation_sigma: 0.011221807963098556\n",
      "Epoch 2096 - loss: 1.5745146283496647 - val_loss: 1.367702533132055 - mutation_sigma: 0.011216941385143855\n",
      "Epoch 2110 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315 - mutation_sigma: 0.011194250361430215\n",
      "Epoch 2138 - loss: 1.573180087814976 - val_loss: 1.3515296257120644 - mutation_sigma: 0.011148965168533927\n",
      "Epoch 2141 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736 - mutation_sigma: 0.011144120816448212\n",
      "Epoch 2150 - loss: 1.57288294976354 - val_loss: 1.3664410720075442 - mutation_sigma: 0.011129596598404068\n",
      "Epoch 2153 - loss: 1.5723427867801285 - val_loss: 1.3602193086317906 - mutation_sigma: 0.011124758135389188\n",
      "Epoch 2154 - loss: 1.5707965243041837 - val_loss: 1.367916348048245 - mutation_sigma: 0.011123145641093454\n",
      "Epoch 2163 - loss: 1.570563230911838 - val_loss: 1.3512575740668005 - mutation_sigma: 0.011108640536995121\n",
      "Epoch 2187 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638 - mutation_sigma: 0.01107002474972614\n",
      "Epoch 2197 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385 - mutation_sigma: 0.01105396244980007\n",
      "Epoch 2222 - loss: 1.5694723349524686 - val_loss: 1.3619969428617993 - mutation_sigma: 0.011013877513890775\n",
      "Epoch 2225 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217 - mutation_sigma: 0.011009074105362178\n",
      "Epoch 2238 - loss: 1.5679719856885452 - val_loss: 1.357517687390613 - mutation_sigma: 0.010988276096195737\n",
      "Epoch 2242 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809 - mutation_sigma: 0.010981882182687065\n",
      "Epoch 2256 - loss: 1.567509202280568 - val_loss: 1.3665762104205987 - mutation_sigma: 0.010959523739347894\n",
      "Epoch 2269 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949 - mutation_sigma: 0.010938790495563216\n",
      "Epoch 2286 - loss: 1.567221932423831 - val_loss: 1.3599917622127142 - mutation_sigma: 0.010911718633954338\n",
      "Epoch 2290 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585 - mutation_sigma: 0.010905355500433228\n",
      "Epoch 2304 - loss: 1.565435453775313 - val_loss: 1.3472290376902827 - mutation_sigma: 0.01088310465002085\n",
      "Epoch 2324 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945 - mutation_sigma: 0.010851371913827415\n",
      "Epoch 2347 - loss: 1.564618393989928 - val_loss: 1.3705626597647815 - mutation_sigma: 0.010814957893848613\n",
      "Epoch 2362 - loss: 1.5645828100656556 - val_loss: 1.3634595494291455 - mutation_sigma: 0.010791254826420068\n",
      "Epoch 2368 - loss: 1.5641625365543275 - val_loss: 1.361848630328406 - mutation_sigma: 0.01078178357461761\n",
      "Epoch 2371 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895 - mutation_sigma: 0.010777050084203741\n",
      "Epoch 2409 - loss: 1.5617618107336222 - val_loss: 1.3591983412957955 - mutation_sigma: 0.010717215537741742\n",
      "Epoch 2410 - loss: 1.5615659570619882 - val_loss: 1.3410703818692735 - mutation_sigma: 0.01071564401833371\n",
      "Epoch 2415 - loss: 1.5614439455453963 - val_loss: 1.365460092874347 - mutation_sigma: 0.010707788781875411\n",
      "Epoch 2436 - loss: 1.5609246493925848 - val_loss: 1.3294379724925294 - mutation_sigma: 0.010674839707747782\n",
      "Epoch 2441 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763 - mutation_sigma: 0.01066700489708344\n",
      "Epoch 2459 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457 - mutation_sigma: 0.010638832031168152\n",
      "Epoch 2482 - loss: 1.5594848194698567 - val_loss: 1.350115356188767 - mutation_sigma: 0.010602907164614057\n",
      "Epoch 2499 - loss: 1.558473087764596 - val_loss: 1.3613298436081642 - mutation_sigma: 0.010576407105008127\n",
      "Epoch 2504 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631 - mutation_sigma: 0.010568621546122214\n",
      "Epoch 2540 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524 - mutation_sigma: 0.010512680364015863\n",
      "Epoch 2549 - loss: 1.557905464325448 - val_loss: 1.3701267708649914 - mutation_sigma: 0.010498726524578395\n",
      "Epoch 2555 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118 - mutation_sigma: 0.010489430942726353\n",
      "Epoch 2580 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141 - mutation_sigma: 0.01045075935456971\n",
      "Epoch 2595 - loss: 1.5552105820665192 - val_loss: 1.351794120345545 - mutation_sigma: 0.010427602781619645\n",
      "Epoch 2635 - loss: 1.5550931974759377 - val_loss: 1.3515422641632662 - mutation_sigma: 0.010366021512641689\n",
      "Epoch 2640 - loss: 1.554777994940189 - val_loss: 1.361606326160278 - mutation_sigma: 0.010358341163068226\n",
      "Epoch 2657 - loss: 1.5546114879558162 - val_loss: 1.3403047028027593 - mutation_sigma: 0.010332256685191925\n",
      "Epoch 2658 - loss: 1.5537020935593076 - val_loss: 1.343732385692427 - mutation_sigma: 0.010330723684856498\n",
      "Epoch 2660 - loss: 1.553456589492552 - val_loss: 1.3592594974186003 - mutation_sigma: 0.010327658144111532\n",
      "Epoch 2671 - loss: 1.5534287597153176 - val_loss: 1.349661232605175 - mutation_sigma: 0.01031080862637232\n",
      "Epoch 2674 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433 - mutation_sigma: 0.01030621651955729\n",
      "Epoch 2689 - loss: 1.5524552672687926 - val_loss: 1.3418883766063174 - mutation_sigma: 0.010283276640770618\n",
      "Epoch 2694 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952 - mutation_sigma: 0.010275637658659943\n",
      "Epoch 2719 - loss: 1.5511113930844524 - val_loss: 1.3268620191680884 - mutation_sigma: 0.010237499992084235\n",
      "Epoch 2725 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762 - mutation_sigma: 0.010228361131366156\n",
      "Epoch 2737 - loss: 1.5508092854129407 - val_loss: 1.347663042607589 - mutation_sigma: 0.01021009985230208\n",
      "Epoch 2750 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978 - mutation_sigma: 0.010190341513843893\n",
      "Epoch 2781 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333 - mutation_sigma: 0.010143329002948929\n",
      "Epoch 2799 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658 - mutation_sigma: 0.010116098220053972\n",
      "Epoch 2815 - loss: 1.5494832467618311 - val_loss: 1.3401901755194499 - mutation_sigma: 0.010091934193320922\n",
      "Epoch 2817 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617 - mutation_sigma: 0.010088916407450417\n",
      "Epoch 2858 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014 - mutation_sigma: 0.01002718461494382\n",
      "Epoch 2877 - loss: 1.5480200665634962 - val_loss: 1.3478229909913135 - mutation_sigma: 0.009998662904182477\n",
      "Epoch 2881 - loss: 1.5472726440601234 - val_loss: 1.361534530544385 - mutation_sigma: 0.009992665235261114\n",
      "Epoch 2905 - loss: 1.5470738747735755 - val_loss: 1.3472224616177744 - mutation_sigma: 0.00995672955545757\n",
      "Epoch 2907 - loss: 1.5467655286946798 - val_loss: 1.3587130611676121 - mutation_sigma: 0.009953738806441157\n",
      "Epoch 2909 - loss: 1.5465063883981667 - val_loss: 1.3431249188959222 - mutation_sigma: 0.009950748655475013\n",
      "Epoch 2910 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187 - mutation_sigma: 0.009949253804223322\n",
      "Epoch 2954 - loss: 1.545050455142064 - val_loss: 1.3482194369955756 - mutation_sigma: 0.009883628109728513\n",
      "Epoch 2955 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162 - mutation_sigma: 0.00988213996971066\n",
      "Epoch 2967 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865 - mutation_sigma: 0.00986429389125289\n",
      "Epoch 2975 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846 - mutation_sigma: 0.009852408396512139\n",
      "Epoch 2982 - loss: 1.5443310784465387 - val_loss: 1.3466216330643277 - mutation_sigma: 0.009842016384984657\n",
      "Epoch 2988 - loss: 1.5440519291121937 - val_loss: 1.322900116698893 - mutation_sigma: 0.009833114734063605\n",
      "Epoch 3000 - loss: 1.5433577749164704 - val_loss: 1.3412658900669032 - mutation_sigma: 0.009815327445863081\n",
      "Epoch 3006 - loss: 1.5430200438076243 - val_loss: 1.323385008232178 - mutation_sigma: 0.009806441802172699\n",
      "Epoch 3031 - loss: 1.5428267052781703 - val_loss: 1.3398620515160897 - mutation_sigma: 0.009769475614831793\n",
      "Epoch 3035 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708 - mutation_sigma: 0.009763569595554331\n",
      "Epoch 3046 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014 - mutation_sigma: 0.009747340217358274\n",
      "Epoch 3070 - loss: 1.5420186039470125 - val_loss: 1.3348140151035488 - mutation_sigma: 0.009711992565243015\n",
      "Epoch 3074 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376 - mutation_sigma: 0.009706109532534635\n",
      "Epoch 3083 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847 - mutation_sigma: 0.009692881308938663\n",
      "Epoch 3130 - loss: 1.540097868114943 - val_loss: 1.348944858849143 - mutation_sigma: 0.009623993662306263\n",
      "Epoch 3136 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821 - mutation_sigma: 0.009615222774109821\n",
      "Epoch 3145 - loss: 1.538906056093952 - val_loss: 1.3341935443537016 - mutation_sigma: 0.009602076304186555\n",
      "Epoch 3172 - loss: 1.538825812803906 - val_loss: 1.3388292322709812 - mutation_sigma: 0.009562707804134481\n",
      "Epoch 3173 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404 - mutation_sigma: 0.009561251751688132\n",
      "Epoch 3200 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405 - mutation_sigma: 0.009521993318719196\n",
      "Epoch 3213 - loss: 1.5372762532117008 - val_loss: 1.336156176223909 - mutation_sigma: 0.009503128877648835\n",
      "Epoch 3230 - loss: 1.5366378782630943 - val_loss: 1.3269456203130479 - mutation_sigma: 0.009478496963944077\n",
      "Epoch 3231 - loss: 1.5364623991683408 - val_loss: 1.3141104503132552 - mutation_sigma: 0.009477049331346611\n",
      "Epoch 3234 - loss: 1.5358648069487544 - val_loss: 1.311986694021345 - mutation_sigma: 0.009472707301947856\n",
      "Epoch 3269 - loss: 1.534926668314523 - val_loss: 1.327199462063306 - mutation_sigma: 0.009422146414242338\n",
      "Epoch 3304 - loss: 1.5342528528081902 - val_loss: 1.30738835574831 - mutation_sigma: 0.009371762163027892\n",
      "Epoch 3317 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371 - mutation_sigma: 0.009353092876486394\n",
      "Epoch 3358 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568 - mutation_sigma: 0.009294371528017365\n",
      "Epoch 3368 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948 - mutation_sigma: 0.00928008572899567\n",
      "Epoch 3391 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287 - mutation_sigma: 0.009247282549922277\n",
      "Epoch 3427 - loss: 1.532170640374761 - val_loss: 1.3088773334041348 - mutation_sigma: 0.009196089654118833\n",
      "Epoch 3433 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404 - mutation_sigma: 0.009187575406223551\n",
      "Epoch 3462 - loss: 1.5313908809471382 - val_loss: 1.31008886880172 - mutation_sigma: 0.009146495140503332\n",
      "Epoch 3472 - loss: 1.53067074969383 - val_loss: 1.315879124302905 - mutation_sigma: 0.009132357129276483\n",
      "Epoch 3484 - loss: 1.530370074402697 - val_loss: 1.3207790992797501 - mutation_sigma: 0.009115410165551213\n",
      "Epoch 3493 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884 - mutation_sigma: 0.009102713280492055\n",
      "Epoch 3522 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574 - mutation_sigma: 0.009061878733991568\n",
      "Epoch 3554 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805 - mutation_sigma: 0.009016957126974694\n",
      "Epoch 3640 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475 - mutation_sigma: 0.008896940109967208\n",
      "Epoch 3652 - loss: 1.5264058532547264 - val_loss: 1.311494474461461 - mutation_sigma: 0.008880275449077043\n",
      "Epoch 3758 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175 - mutation_sigma: 0.008733936131599833\n",
      "Epoch 3806 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998 - mutation_sigma: 0.008668177760312146\n",
      "Epoch 3835 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273 - mutation_sigma: 0.00862860141586256\n",
      "Epoch 3857 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424 - mutation_sigma: 0.008598654441187126\n",
      "Epoch 3869 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522 - mutation_sigma: 0.008582347472688694\n",
      "Epoch 3878 - loss: 1.52356401259396 - val_loss: 1.3002191317782756 - mutation_sigma: 0.008570130080351176\n",
      "Epoch 3894 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515 - mutation_sigma: 0.00854843740025802\n",
      "Epoch 3947 - loss: 1.5225105755410904 - val_loss: 1.30735245729511 - mutation_sigma: 0.008476827776102352\n",
      "Epoch 3963 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654 - mutation_sigma: 0.008455284245431387\n",
      "Epoch 3973 - loss: 1.5220082132768606 - val_loss: 1.3042830884535657 - mutation_sigma: 0.00844183703063403\n",
      "Epoch 3974 - loss: 1.521854410358196 - val_loss: 1.296375638133106 - mutation_sigma: 0.008440493048529278\n",
      "Epoch 3987 - loss: 1.521676187138161 - val_loss: 1.299705876528199 - mutation_sigma: 0.0084230335046812\n",
      "Epoch 3996 - loss: 1.5214498907035865 - val_loss: 1.2958707280956148 - mutation_sigma: 0.008410959416089665\n",
      "Epoch 4002 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175 - mutation_sigma: 0.008402916058023912\n",
      "Epoch 4036 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443 - mutation_sigma: 0.008357428065625724\n",
      "Epoch 4099 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739 - mutation_sigma: 0.008273549152677237\n",
      "Epoch 4114 - loss: 1.5185037806662043 - val_loss: 1.2980556150709521 - mutation_sigma: 0.008253655742076232\n",
      "Epoch 4117 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978 - mutation_sigma: 0.00824968063915903\n",
      "Epoch 4134 - loss: 1.5174934102837228 - val_loss: 1.302223129966856 - mutation_sigma: 0.008227177565410845\n",
      "Epoch 4151 - loss: 1.516925945664128 - val_loss: 1.2971435214958875 - mutation_sigma: 0.008204712710570945\n",
      "Epoch 4175 - loss: 1.516832342710414 - val_loss: 1.2929701543790513 - mutation_sigma: 0.008173062560450632\n",
      "Epoch 4189 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182 - mutation_sigma: 0.008154635017909237\n",
      "Epoch 4196 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916 - mutation_sigma: 0.008145430915618375\n",
      "Epoch 4204 - loss: 1.51579698542343 - val_loss: 1.2988034783434448 - mutation_sigma: 0.00813491982699057\n",
      "Epoch 4213 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305 - mutation_sigma: 0.008123104898154397\n",
      "Epoch 4228 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507 - mutation_sigma: 0.008103436962239807\n",
      "Epoch 4263 - loss: 1.5152437421558547 - val_loss: 1.3080832720925255 - mutation_sigma: 0.008057659667592875\n",
      "Epoch 4268 - loss: 1.515242670143588 - val_loss: 1.3092840476949146 - mutation_sigma: 0.008051133122185868\n",
      "Epoch 4283 - loss: 1.5148942393023568 - val_loss: 1.3065510102969256 - mutation_sigma: 0.00803157305222903\n",
      "Epoch 4286 - loss: 1.5145850236623843 - val_loss: 1.299028914466481 - mutation_sigma: 0.008027664557466334\n",
      "Epoch 4295 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017 - mutation_sigma: 0.008015946105304133\n",
      "Epoch 4315 - loss: 1.513891937956392 - val_loss: 1.298137156801345 - mutation_sigma: 0.007989942825368173\n",
      "Epoch 4316 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222 - mutation_sigma: 0.007988644025906627\n",
      "Epoch 4330 - loss: 1.513382280229381 - val_loss: 1.300556329033807 - mutation_sigma: 0.007970474462888066\n",
      "Epoch 4335 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733 - mutation_sigma: 0.007963991494830455\n",
      "Epoch 4347 - loss: 1.512580323942462 - val_loss: 1.3089504556825093 - mutation_sigma: 0.00794844558903596\n",
      "Epoch 4369 - loss: 1.5125366500400963 - val_loss: 1.2931841025641357 - mutation_sigma: 0.007919993163125711\n",
      "Epoch 4371 - loss: 1.5125217931843176 - val_loss: 1.3008091703251827 - mutation_sigma: 0.00791740968119807\n",
      "Epoch 4376 - loss: 1.5121335510237215 - val_loss: 1.3015006564554483 - mutation_sigma: 0.007910953236247673\n",
      "Epoch 4378 - loss: 1.5119658458277694 - val_loss: 1.2900086225192033 - mutation_sigma: 0.007908371561943881\n",
      "Epoch 4380 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867 - mutation_sigma: 0.0079057904038717\n",
      "Epoch 4398 - loss: 1.5114496678468028 - val_loss: 1.297034011870862 - mutation_sigma: 0.007882583194619222\n",
      "Epoch 4409 - loss: 1.511186739605909 - val_loss: 1.2988388980998415 - mutation_sigma: 0.007868421559595686\n",
      "Epoch 4434 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063 - mutation_sigma: 0.007836293894775602\n",
      "Epoch 4448 - loss: 1.5107704102709076 - val_loss: 1.297934057752117 - mutation_sigma: 0.00781833745141016\n",
      "Epoch 4449 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968 - mutation_sigma: 0.007817055809912307\n",
      "Epoch 4456 - loss: 1.5102090745586767 - val_loss: 1.291476997404381 - mutation_sigma: 0.007808087906767919\n",
      "Epoch 4466 - loss: 1.5100613526521611 - val_loss: 1.291202396889054 - mutation_sigma: 0.007795287500171677\n",
      "Epoch 4479 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693 - mutation_sigma: 0.007778666094816055\n",
      "Epoch 4486 - loss: 1.509853642010719 - val_loss: 1.2913891725156106 - mutation_sigma: 0.0077697250523838185\n",
      "Epoch 4512 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264 - mutation_sigma: 0.007736570202712476\n",
      "Epoch 4525 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841 - mutation_sigma: 0.007720025072626368\n",
      "Epoch 4551 - loss: 1.508909006649633 - val_loss: 1.2791477621236889 - mutation_sigma: 0.007686999262174814\n",
      "Epoch 4552 - loss: 1.508865963767768 - val_loss: 1.3106510429499445 - mutation_sigma: 0.007685730752526098\n",
      "Epoch 4555 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593 - mutation_sigma: 0.007681925984520871\n",
      "Epoch 4570 - loss: 1.5081687463813689 - val_loss: 1.2845910762198764 - mutation_sigma: 0.007662919254827716\n",
      "Epoch 4572 - loss: 1.5080982097189148 - val_loss: 1.283732370635203 - mutation_sigma: 0.007660387177400676\n",
      "Epoch 4575 - loss: 1.5080871613938927 - val_loss: 1.283296489881322 - mutation_sigma: 0.007656590010567634\n",
      "Epoch 4580 - loss: 1.5073057507144547 - val_loss: 1.2893112008414345 - mutation_sigma: 0.0076502639298223875\n",
      "Epoch 4586 - loss: 1.5072098196960784 - val_loss: 1.2926466911640748 - mutation_sigma: 0.007642676806541391\n",
      "Epoch 4591 - loss: 1.507003036716309 - val_loss: 1.2851665934640484 - mutation_sigma: 0.0076363576799640545\n",
      "Epoch 4630 - loss: 1.5068094991537544 - val_loss: 1.2919428799833415 - mutation_sigma: 0.007587176768211814\n",
      "Epoch 4658 - loss: 1.5066375899154258 - val_loss: 1.2879122577230846 - mutation_sigma: 0.007551985483177694\n",
      "Epoch 4703 - loss: 1.5062359777994059 - val_loss: 1.2872495781753723 - mutation_sigma: 0.007495634069409199\n",
      "Epoch 4707 - loss: 1.5061095174006922 - val_loss: 1.3037762680506721 - mutation_sigma: 0.007490637314874412\n",
      "Epoch 4717 - loss: 1.5059598561485006 - val_loss: 1.282721320635646 - mutation_sigma: 0.007478154168487524\n",
      "Epoch 4732 - loss: 1.5055297222377355 - val_loss: 1.2911719620383522 - mutation_sigma: 0.00745945283687281\n",
      "Epoch 4733 - loss: 1.505272576247615 - val_loss: 1.2840301306034452 - mutation_sigma: 0.007458207078453923\n",
      "Epoch 4779 - loss: 1.5051810914713823 - val_loss: 1.2940151466980343 - mutation_sigma: 0.007401036635755931\n",
      "Epoch 4788 - loss: 1.5051765567366318 - val_loss: 1.2988164881251318 - mutation_sigma: 0.007389881838675017\n",
      "Epoch 4792 - loss: 1.5046960061511951 - val_loss: 1.279217641354839 - mutation_sigma: 0.0073849273723454985\n",
      "Epoch 4806 - loss: 1.5044983289245635 - val_loss: 1.2885104590934886 - mutation_sigma: 0.007367602336882057\n",
      "Epoch 4821 - loss: 1.5044722248690192 - val_loss: 1.2928468016675196 - mutation_sigma: 0.00734906669214984\n",
      "Epoch 4822 - loss: 1.5042224924780383 - val_loss: 1.2927753868040095 - mutation_sigma: 0.0073478319706898705\n",
      "Epoch 4836 - loss: 1.5041046576164734 - val_loss: 1.289013941158037 - mutation_sigma: 0.007330558827266641\n",
      "Epoch 4874 - loss: 1.5040781901023623 - val_loss: 1.2814930029061262 - mutation_sigma: 0.007283796285072698\n",
      "Epoch 4885 - loss: 1.5033684040972342 - val_loss: 1.284231924016209 - mutation_sigma: 0.0072702928877288455\n",
      "Epoch 4902 - loss: 1.5032476521506928 - val_loss: 1.2854602429585003 - mutation_sigma: 0.007249453192548516\n",
      "Epoch 4910 - loss: 1.5030883292275052 - val_loss: 1.27869750305631 - mutation_sigma: 0.007239658527849157\n",
      "Epoch 4919 - loss: 1.5030496280049621 - val_loss: 1.2692527206152497 - mutation_sigma: 0.007228648891217317\n",
      "Epoch 4933 - loss: 1.5027202802082984 - val_loss: 1.2821519235393695 - mutation_sigma: 0.007211542470699796\n",
      "Epoch 4942 - loss: 1.502581005147861 - val_loss: 1.2835676685294335 - mutation_sigma: 0.007200558124607883\n",
      "Epoch 4946 - loss: 1.5022849527070081 - val_loss: 1.287627649924723 - mutation_sigma: 0.007195679365050952\n",
      "Epoch 4970 - loss: 1.5018120713155578 - val_loss: 1.2861409120403433 - mutation_sigma: 0.007166447749704549\n",
      "Epoch 4987 - loss: 1.501795179042218 - val_loss: 1.2785904462949464 - mutation_sigma: 0.007145784423665708\n",
      "Epoch 4993 - loss: 1.5016102550300652 - val_loss: 1.272660181326898 - mutation_sigma: 0.007138499867052668\n",
      "Epoch 4996 - loss: 1.5015418648169507 - val_loss: 1.2872474208768367 - mutation_sigma: 0.007134859227279799\n",
      "Epoch 5000 - loss: 1.501196309814991 - val_loss: 1.2741443882820158 - mutation_sigma: 0.007130006739399943\n",
      "Epoch 5018 - loss: 1.5010228723180163 - val_loss: 1.2807667033862433 - mutation_sigma: 0.007108194545351775\n",
      "Epoch 5032 - loss: 1.5008514154413137 - val_loss: 1.2888859887381652 - mutation_sigma: 0.00709125662608994\n",
      "Epoch 5035 - loss: 1.500805393211421 - val_loss: 1.282649837005486 - mutation_sigma: 0.007087630155746895\n",
      "Epoch 5042 - loss: 1.5004736876061073 - val_loss: 1.2755180428946449 - mutation_sigma: 0.007079172620873881\n",
      "Epoch 5056 - loss: 1.5002979797580764 - val_loss: 1.2650779099077214 - mutation_sigma: 0.007062275299821118\n",
      "Epoch 5062 - loss: 1.5002314722179597 - val_loss: 1.2840488332606865 - mutation_sigma: 0.007055040828646706\n",
      "Epoch 5066 - loss: 1.500181513270051 - val_loss: 1.2888854086609605 - mutation_sigma: 0.007050220258550546\n",
      "Epoch 5074 - loss: 1.4997184080840422 - val_loss: 1.2836411383062234 - mutation_sigma: 0.007040584900536546\n",
      "Epoch 5099 - loss: 1.4996359988055088 - val_loss: 1.2816148271062549 - mutation_sigma: 0.0070105240361073165\n",
      "Epoch 5103 - loss: 1.499210111974627 - val_loss: 1.2775283562938307 - mutation_sigma: 0.007005721267387519\n",
      "Epoch 5144 - loss: 1.4991932124319747 - val_loss: 1.2820290405083903 - mutation_sigma: 0.006956603482228253\n",
      "Epoch 5149 - loss: 1.4991253460005922 - val_loss: 1.2783070079731527 - mutation_sigma: 0.006950627272285113\n",
      "Epoch 5164 - loss: 1.4988076971381181 - val_loss: 1.278216310349523 - mutation_sigma: 0.006932716558841034\n",
      "Epoch 5185 - loss: 1.4986866700297619 - val_loss: 1.2780612374841887 - mutation_sigma: 0.006907686647662896\n",
      "Epoch 5198 - loss: 1.49866103200409 - val_loss: 1.2776518049522625 - mutation_sigma: 0.00689221825849106\n",
      "Epoch 5204 - loss: 1.4978695892354414 - val_loss: 1.2732750112198776 - mutation_sigma: 0.006885085780741017\n",
      "Epoch 5240 - loss: 1.4963890926472199 - val_loss: 1.2848576137746726 - mutation_sigma: 0.006842380657780885\n",
      "Epoch 5326 - loss: 1.4963776081194793 - val_loss: 1.2816482023105216 - mutation_sigma: 0.006740982958883678\n",
      "Epoch 5363 - loss: 1.4963152584364467 - val_loss: 1.270320744097884 - mutation_sigma: 0.006697625917624462\n",
      "Epoch 5379 - loss: 1.4960588767470848 - val_loss: 1.2771688202634066 - mutation_sigma: 0.006678926549576307\n",
      "Epoch 5394 - loss: 1.4957058536568655 - val_loss: 1.2751744289441 - mutation_sigma: 0.006661423041015797\n",
      "Epoch 5428 - loss: 1.4951561142458676 - val_loss: 1.2661294500836662 - mutation_sigma: 0.006621845480408002\n",
      "Epoch 5464 - loss: 1.4948015477764829 - val_loss: 1.2749284131882912 - mutation_sigma: 0.0065800862243605\n",
      "Epoch 5479 - loss: 1.4946285288325023 - val_loss: 1.279334029268152 - mutation_sigma: 0.006562730850345679\n",
      "Epoch 5507 - loss: 1.494430116780131 - val_loss: 1.2682605216090237 - mutation_sigma: 0.006530403715784834\n",
      "Epoch 5544 - loss: 1.493798591259605 - val_loss: 1.2697328656494486 - mutation_sigma: 0.006487824300467447\n",
      "Epoch 5557 - loss: 1.4935385478205103 - val_loss: 1.2699178887176656 - mutation_sigma: 0.006472901323211222\n",
      "Epoch 5621 - loss: 1.4933719354027788 - val_loss: 1.2640891657950608 - mutation_sigma: 0.006399716514390779\n",
      "Epoch 5624 - loss: 1.4929995791489263 - val_loss: 1.269367257165318 - mutation_sigma: 0.00639629745422714\n",
      "Epoch 5640 - loss: 1.49264926926856 - val_loss: 1.272248423281841 - mutation_sigma: 0.006378079778094947\n",
      "Epoch 5653 - loss: 1.4925149745024322 - val_loss: 1.2747594368764266 - mutation_sigma: 0.006363299361777027\n",
      "Epoch 5690 - loss: 1.4922584750343144 - val_loss: 1.2583256557327602 - mutation_sigma: 0.006321337028555464\n",
      "Epoch 5714 - loss: 1.492099675261437 - val_loss: 1.2580157619848262 - mutation_sigma: 0.006294201109405766\n",
      "Epoch 5728 - loss: 1.491785141519088 - val_loss: 1.2674778902012185 - mutation_sigma: 0.006278401869824546\n",
      "Epoch 5732 - loss: 1.4910684524268492 - val_loss: 1.2647893731592394 - mutation_sigma: 0.006273891862139049\n",
      "Epoch 5761 - loss: 1.4910105110474055 - val_loss: 1.2689457535274016 - mutation_sigma: 0.006241248196296381\n",
      "Epoch 5797 - loss: 1.4905906844103365 - val_loss: 1.2669432934568952 - mutation_sigma: 0.006200856490649114\n",
      "Epoch 5826 - loss: 1.490150129460951 - val_loss: 1.2624765774103095 - mutation_sigma: 0.006168424299449876\n",
      "Epoch 5850 - loss: 1.4896779277602046 - val_loss: 1.2698350594619634 - mutation_sigma: 0.0061416548942060415\n",
      "Epoch 5852 - loss: 1.4892567590114896 - val_loss: 1.2604117810143074 - mutation_sigma: 0.006139427008811705\n",
      "Epoch 5916 - loss: 1.4892539094450652 - val_loss: 1.2586303125075269 - mutation_sigma: 0.006068369408555014\n",
      "Epoch 5924 - loss: 1.4886303669430194 - val_loss: 1.2665352701115844 - mutation_sigma: 0.006059519138635097\n",
      "Epoch 5957 - loss: 1.4884333129445895 - val_loss: 1.2605915464216064 - mutation_sigma: 0.006023086515627159\n",
      "Epoch 6008 - loss: 1.488175158814361 - val_loss: 1.2613678438614138 - mutation_sigma: 0.00596701747886232\n",
      "Epoch 6014 - loss: 1.4878357362992205 - val_loss: 1.2723715205952864 - mutation_sigma: 0.005960439899604013\n",
      "Epoch 6046 - loss: 1.487445856613044 - val_loss: 1.2614896548875967 - mutation_sigma: 0.0059254260453530045\n",
      "Epoch 6072 - loss: 1.4871824525430277 - val_loss: 1.2585186494829452 - mutation_sigma: 0.0058970596665435466\n",
      "Epoch 6119 - loss: 1.4870384906102312 - val_loss: 1.2653351049541768 - mutation_sigma: 0.005845968752889661\n",
      "Epoch 6122 - loss: 1.4866209625693334 - val_loss: 1.269241198699485 - mutation_sigma: 0.00584271577553253\n",
      "Epoch 6129 - loss: 1.4863231644062105 - val_loss: 1.2596555841405306 - mutation_sigma: 0.005835129288718475\n",
      "Epoch 6208 - loss: 1.4862681235275805 - val_loss: 1.2600821612854556 - mutation_sigma: 0.005749877480496548\n",
      "Epoch 6212 - loss: 1.4858231298994389 - val_loss: 1.2487751311731254 - mutation_sigma: 0.0057455788191600595\n",
      "Epoch 6227 - loss: 1.4857939030442637 - val_loss: 1.260741010983042 - mutation_sigma: 0.005729474142925443\n",
      "Epoch 6231 - loss: 1.485700347236984 - val_loss: 1.258045821535246 - mutation_sigma: 0.005725183640476211\n",
      "Epoch 6236 - loss: 1.4853606720077355 - val_loss: 1.2632172973582798 - mutation_sigma: 0.005719822925018052\n",
      "Epoch 6246 - loss: 1.4853265225842114 - val_loss: 1.2463038172729555 - mutation_sigma: 0.005709109531022125\n",
      "Epoch 6279 - loss: 1.4849563947221607 - val_loss: 1.251250988017374 - mutation_sigma: 0.005673831238593346\n",
      "Epoch 6301 - loss: 1.4847156374814678 - val_loss: 1.2529241836838019 - mutation_sigma: 0.005650376964456348\n",
      "Epoch 6303 - loss: 1.484602711506318 - val_loss: 1.26206999620929 - mutation_sigma: 0.005648247315000447\n",
      "Epoch 6329 - loss: 1.4836579387296518 - val_loss: 1.2635487999718862 - mutation_sigma: 0.005620600592965058\n",
      "Epoch 6444 - loss: 1.4836364680146477 - val_loss: 1.260835673968235 - mutation_sigma: 0.005499175361818644\n",
      "Epoch 6464 - loss: 1.4836304354184013 - val_loss: 1.2526582590968127 - mutation_sigma: 0.005478200090884092\n",
      "Epoch 6469 - loss: 1.4835500192437772 - val_loss: 1.257906615968178 - mutation_sigma: 0.0054729628239911605\n",
      "Epoch 6470 - loss: 1.483420783892503 - val_loss: 1.2486516631486249 - mutation_sigma: 0.005471915684780517\n",
      "Epoch 6476 - loss: 1.4830867700858181 - val_loss: 1.2587798549765263 - mutation_sigma: 0.005465635047812836\n",
      "Epoch 6494 - loss: 1.4824283058535783 - val_loss: 1.2566467790591527 - mutation_sigma: 0.005446815729126167\n",
      "Epoch 6498 - loss: 1.481898698297152 - val_loss: 1.2433329851032071 - mutation_sigma: 0.005442638256132109\n",
      "Epoch 6574 - loss: 1.4818860502537496 - val_loss: 1.258945044880992 - mutation_sigma: 0.005363582901748956\n",
      "Epoch 6581 - loss: 1.481024053973441 - val_loss: 1.261563480733174 - mutation_sigma: 0.0053563316570738985\n",
      "Epoch 6617 - loss: 1.4805951337109031 - val_loss: 1.2486610050887748 - mutation_sigma: 0.0053191196061901\n",
      "Epoch 6639 - loss: 1.4805276660743802 - val_loss: 1.251613473068183 - mutation_sigma: 0.005296444762014099\n",
      "Epoch 6648 - loss: 1.4804723027478688 - val_loss: 1.2587288926814182 - mutation_sigma: 0.005287183056291536\n",
      "Epoch 6649 - loss: 1.4804493522436153 - val_loss: 1.2537419613640182 - mutation_sigma: 0.005286154492271366\n",
      "Epoch 6661 - loss: 1.4802916687581793 - val_loss: 1.2520058984867453 - mutation_sigma: 0.005273819742685373\n",
      "Epoch 6662 - loss: 1.4799181874441314 - val_loss: 1.2640662323200567 - mutation_sigma: 0.0052727925147961425\n",
      "Epoch 6685 - loss: 1.4796055131022696 - val_loss: 1.256177703631446 - mutation_sigma: 0.005249194599807554\n",
      "Epoch 6691 - loss: 1.4793681605337479 - val_loss: 1.2480119550927955 - mutation_sigma: 0.0052430475420551645\n",
      "Epoch 6712 - loss: 1.4791538103001154 - val_loss: 1.2502823462779713 - mutation_sigma: 0.005221561858647966\n",
      "Epoch 6721 - loss: 1.4790388081150136 - val_loss: 1.252721201942059 - mutation_sigma: 0.005212367510487225\n",
      "Epoch 6733 - loss: 1.4788853306142171 - val_loss: 1.253124309550036 - mutation_sigma: 0.005200121243331058\n",
      "Epoch 6741 - loss: 1.4787264883093063 - val_loss: 1.2561613256220774 - mutation_sigma: 0.00519196522478061\n",
      "Epoch 6755 - loss: 1.4785719078017279 - val_loss: 1.2612470775100282 - mutation_sigma: 0.005177707881668874\n",
      "Epoch 6772 - loss: 1.478507365428562 - val_loss: 1.2558384197469021 - mutation_sigma: 0.005160422203826538\n",
      "Epoch 6776 - loss: 1.4783453623983085 - val_loss: 1.2587747613496276 - mutation_sigma: 0.005156359253884157\n",
      "Epoch 6793 - loss: 1.4777691601558105 - val_loss: 1.2515109952121755 - mutation_sigma: 0.005139109834255023\n",
      "Epoch 6799 - loss: 1.4774220401812757 - val_loss: 1.2529132655603898 - mutation_sigma: 0.005133028800950204\n",
      "Epoch 6806 - loss: 1.477393455444324 - val_loss: 1.2546628404535598 - mutation_sigma: 0.005125938871547247\n",
      "Epoch 6820 - loss: 1.4772582684591433 - val_loss: 1.2530169327698737 - mutation_sigma: 0.00511177389142456\n",
      "Epoch 6861 - loss: 1.4772452914543055 - val_loss: 1.2519273598541971 - mutation_sigma: 0.005070404620348177\n",
      "Epoch 6870 - loss: 1.476566884116717 - val_loss: 1.2580959341587945 - mutation_sigma: 0.005061346238911034\n",
      "Epoch 6879 - loss: 1.4765278437749945 - val_loss: 1.2469955094802863 - mutation_sigma: 0.005052296005535199\n",
      "Epoch 6900 - loss: 1.4762581917929547 - val_loss: 1.2508448739772706 - mutation_sigma: 0.0050312104400720295\n",
      "Epoch 6906 - loss: 1.4760136035899813 - val_loss: 1.255754199173026 - mutation_sigma: 0.005025194120516279\n",
      "Epoch 6942 - loss: 1.475897724151448 - val_loss: 1.2479906104542358 - mutation_sigma: 0.0049891719027961865\n",
      "Epoch 6953 - loss: 1.4755585865193164 - val_loss: 1.2464479041635375 - mutation_sigma: 0.004978190952427985\n",
      "Epoch 6966 - loss: 1.475542004887329 - val_loss: 1.25208948970155 - mutation_sigma: 0.004965229027458843\n",
      "Epoch 6979 - loss: 1.4749340147127583 - val_loss: 1.2509937388389687 - mutation_sigma: 0.004952283940361387\n",
      "Epoch 6987 - loss: 1.474810243339331 - val_loss: 1.252249847160468 - mutation_sigma: 0.0049443260925573764\n",
      "Epoch 7001 - loss: 1.4747904452618468 - val_loss: 1.2498538756569153 - mutation_sigma: 0.0049304151670401\n",
      "Epoch 7009 - loss: 1.4746790273675023 - val_loss: 1.2522287384931081 - mutation_sigma: 0.004922474805510676\n",
      "Epoch 7022 - loss: 1.4746596570312098 - val_loss: 1.2517007725990041 - mutation_sigma: 0.004909585257239813\n",
      "Epoch 7027 - loss: 1.4744489408597985 - val_loss: 1.2450102022109362 - mutation_sigma: 0.004904632198285005\n",
      "Epoch 7036 - loss: 1.474135546497918 - val_loss: 1.2440803177658082 - mutation_sigma: 0.004895722930005417\n",
      "Epoch 7045 - loss: 1.4739501815813503 - val_loss: 1.2552955616646286 - mutation_sigma: 0.004886821675659078\n",
      "Epoch 7078 - loss: 1.4732441404240832 - val_loss: 1.2512445244730777 - mutation_sigma: 0.00485425219028266\n",
      "Epoch 7110 - loss: 1.4730569285852226 - val_loss: 1.2485917116822665 - mutation_sigma: 0.004822772126242919\n",
      "Epoch 7145 - loss: 1.473011429557416 - val_loss: 1.2579883340760598 - mutation_sigma: 0.004788455943766245\n",
      "Epoch 7146 - loss: 1.4728304204645564 - val_loss: 1.25760577426447 - mutation_sigma: 0.004787477244977501\n",
      "Epoch 7153 - loss: 1.4723994395857125 - val_loss: 1.2554518258617713 - mutation_sigma: 0.0047806290928540775\n",
      "Epoch 7174 - loss: 1.471834765224373 - val_loss: 1.2597405159056454 - mutation_sigma: 0.0047601133723764065\n",
      "Epoch 7227 - loss: 1.4716252183717609 - val_loss: 1.2472808269525761 - mutation_sigma: 0.00470852675544292\n",
      "Epoch 7245 - loss: 1.4716196686039873 - val_loss: 1.2554037343053444 - mutation_sigma: 0.004691068869881842\n",
      "Epoch 7268 - loss: 1.4712020374582064 - val_loss: 1.2509412012947103 - mutation_sigma: 0.004668807248320747\n",
      "Epoch 7301 - loss: 1.4709313252132767 - val_loss: 1.2410590067473883 - mutation_sigma: 0.004636955953070132\n",
      "Epoch 7328 - loss: 1.4708253355308665 - val_loss: 1.253088441603009 - mutation_sigma: 0.004610973861811709\n",
      "Epoch 7340 - loss: 1.4705562322161618 - val_loss: 1.2522812315754674 - mutation_sigma: 0.004599448762130185\n",
      "Epoch 7363 - loss: 1.4703409421190634 - val_loss: 1.2513505827851208 - mutation_sigma: 0.004577397603645303\n",
      "Epoch 7384 - loss: 1.4701714339620668 - val_loss: 1.2497721730341005 - mutation_sigma: 0.004557308178898232\n",
      "Epoch 7392 - loss: 1.4700819264758138 - val_loss: 1.2469529518791795 - mutation_sigma: 0.004549666153775211\n",
      "Epoch 7402 - loss: 1.4699783981711365 - val_loss: 1.2583510141877021 - mutation_sigma: 0.004540122214780081\n",
      "Epoch 7417 - loss: 1.4698037522961365 - val_loss: 1.2498754597115527 - mutation_sigma: 0.004525824187461743\n",
      "Epoch 7435 - loss: 1.469692970440176 - val_loss: 1.2475151193820921 - mutation_sigma: 0.0045086948378983355\n",
      "Epoch 7459 - loss: 1.4691006332949657 - val_loss: 1.246224181053335 - mutation_sigma: 0.004485903609822573\n",
      "Epoch 7520 - loss: 1.4688863615391285 - val_loss: 1.2534558039634793 - mutation_sigma: 0.004428221475370868\n",
      "Epoch 7564 - loss: 1.468872976179937 - val_loss: 1.2476277335735766 - mutation_sigma: 0.004386832562147066\n",
      "Epoch 7568 - loss: 1.4687588422580797 - val_loss: 1.2545361720414765 - mutation_sigma: 0.004383078955254318\n",
      "Epoch 7574 - loss: 1.468133299642567 - val_loss: 1.2614612762095343 - mutation_sigma: 0.004377451359088443\n",
      "Epoch 7603 - loss: 1.4679581585549961 - val_loss: 1.2474882852590425 - mutation_sigma: 0.004350298855555036\n",
      "Epoch 7623 - loss: 1.467947996988755 - val_loss: 1.2528160864659634 - mutation_sigma: 0.004331618812117767\n",
      "Epoch 7629 - loss: 1.4679248068875588 - val_loss: 1.2517365842950756 - mutation_sigma: 0.004326022079691352\n",
      "Epoch 7630 - loss: 1.4678523994802348 - val_loss: 1.2573363414758487 - mutation_sigma: 0.00432508961735351\n",
      "Epoch 7646 - loss: 1.467682448396118 - val_loss: 1.2468634935448566 - mutation_sigma: 0.004310182893197268\n",
      "Epoch 7674 - loss: 1.4675579369546259 - val_loss: 1.2446245732871677 - mutation_sigma: 0.004284153442276902\n",
      "Epoch 7680 - loss: 1.4674347852429976 - val_loss: 1.252471575987131 - mutation_sigma: 0.004278585177684404\n",
      "Epoch 7687 - loss: 1.4672036610634374 - val_loss: 1.2543171873118528 - mutation_sigma: 0.004272093089764656\n",
      "Epoch 7702 - loss: 1.4671553116908884 - val_loss: 1.24648648639911 - mutation_sigma: 0.00425819676461169\n",
      "Epoch 7723 - loss: 1.467129310689095 - val_loss: 1.261389174137212 - mutation_sigma: 0.004238776891396292\n",
      "Epoch 7737 - loss: 1.466883807078504 - val_loss: 1.2561188454965015 - mutation_sigma: 0.004225852945016141\n",
      "Epoch 7741 - loss: 1.4664519290312104 - val_loss: 1.2651734882835672 - mutation_sigma: 0.004222163710657627\n",
      "Epoch 7743 - loss: 1.466313558623826 - val_loss: 1.2634702893001273 - mutation_sigma: 0.004220319646734426\n",
      "Epoch 7782 - loss: 1.466163400832144 - val_loss: 1.2584104029094432 - mutation_sigma: 0.004184434011145602\n",
      "Epoch 7783 - loss: 1.4661404773355657 - val_loss: 1.2513381662751446 - mutation_sigma: 0.004183515705491101\n",
      "Epoch 7794 - loss: 1.4659437370906003 - val_loss: 1.2528410294660242 - mutation_sigma: 0.004173420401180705\n",
      "Epoch 7800 - loss: 1.465788812236337 - val_loss: 1.2581776614181504 - mutation_sigma: 0.004167918549845569\n",
      "Epoch 7835 - loss: 1.4657330707664877 - val_loss: 1.2447019472860672 - mutation_sigma: 0.004135890120208351\n",
      "Epoch 7842 - loss: 1.465649986051515 - val_loss: 1.2494411707784152 - mutation_sigma: 0.004129497873896037\n",
      "Epoch 7847 - loss: 1.4652955113324515 - val_loss: 1.2590800729503262 - mutation_sigma: 0.0041249347221572535\n",
      "Epoch 7915 - loss: 1.4651427809355935 - val_loss: 1.2555351870583125 - mutation_sigma: 0.004063101819444856\n",
      "Epoch 7917 - loss: 1.4650241192070674 - val_loss: 1.2647280693654568 - mutation_sigma: 0.0040612895615385865\n",
      "Epoch 7922 - loss: 1.4649550358344645 - val_loss: 1.255494715228838 - mutation_sigma: 0.004056760502022995\n",
      "Epoch 7957 - loss: 1.4648262171730269 - val_loss: 1.2583684387454683 - mutation_sigma: 0.004025120406738219\n",
      "Epoch 7982 - loss: 1.4648062753472508 - val_loss: 1.2514673304184338 - mutation_sigma: 0.004002588036156094\n",
      "Epoch 7998 - loss: 1.4647050668314021 - val_loss: 1.2549650421967309 - mutation_sigma: 0.003988196850435205\n",
      "Epoch 8034 - loss: 1.4643003096735945 - val_loss: 1.253537106696657 - mutation_sigma: 0.003955900739261174\n",
      "Epoch 8075 - loss: 1.464110919289541 - val_loss: 1.253048073055666 - mutation_sigma: 0.00391926037433669\n",
      "Epoch 8086 - loss: 1.4639537622732774 - val_loss: 1.2598536125214284 - mutation_sigma: 0.003909455562041464\n",
      "Epoch 8146 - loss: 1.4638198116276793 - val_loss: 1.2650890488440683 - mutation_sigma: 0.0038561641917750694\n",
      "Epoch 8147 - loss: 1.4636230733872584 - val_loss: 1.2564549960438967 - mutation_sigma: 0.003855278708179169\n",
      "Epoch 8195 - loss: 1.463360705857805 - val_loss: 1.2576881403662683 - mutation_sigma: 0.003812879449923953\n",
      "Epoch 8231 - loss: 1.4631709042913092 - val_loss: 1.2554555407903514 - mutation_sigma: 0.0037812132838158643\n",
      "Epoch 8239 - loss: 1.4629975177485792 - val_loss: 1.2541451514665782 - mutation_sigma: 0.003774191824293013\n",
      "Epoch 8241 - loss: 1.4629230038059422 - val_loss: 1.251319983733881 - mutation_sigma: 0.003772437336831494\n",
      "Epoch 8269 - loss: 1.4628878721957725 - val_loss: 1.2613605580832368 - mutation_sigma: 0.0037479113173396654\n",
      "Epoch 8274 - loss: 1.4627207241402977 - val_loss: 1.2625045689318743 - mutation_sigma: 0.003743538892120905\n",
      "Epoch 8287 - loss: 1.4626757492863611 - val_loss: 1.262062442048671 - mutation_sigma: 0.003732180811720884\n",
      "Epoch 8292 - loss: 1.4626334837914976 - val_loss: 1.2535757917883998 - mutation_sigma: 0.003727816249002894\n",
      "Epoch 8295 - loss: 1.4625674877297405 - val_loss: 1.2549694114232786 - mutation_sigma: 0.003725198558570433\n",
      "Epoch 8305 - loss: 1.4624909212710144 - val_loss: 1.2654322832620826 - mutation_sigma: 0.0037164785927179646\n",
      "Epoch 8310 - loss: 1.4624181318965113 - val_loss: 1.251057914987765 - mutation_sigma: 0.003712121878362386\n",
      "Epoch 8318 - loss: 1.4622769939963787 - val_loss: 1.263714510076754 - mutation_sigma: 0.0037051556643382033\n",
      "Epoch 8326 - loss: 1.461962034764587 - val_loss: 1.2543889258277594 - mutation_sigma: 0.003698195020499849\n",
      "Epoch 8332 - loss: 1.4617689630703596 - val_loss: 1.257360597481568 - mutation_sigma: 0.003692978190376087\n",
      "Epoch 8363 - loss: 1.4614424908132608 - val_loss: 1.26110824899517 - mutation_sigma: 0.003666074370831488\n",
      "Epoch 8416 - loss: 1.4613618455529513 - val_loss: 1.255437960790094 - mutation_sigma: 0.0036202702452205636\n",
      "Epoch 8420 - loss: 1.4612360407905334 - val_loss: 1.2574396882051802 - mutation_sigma: 0.003616823171290611\n",
      "Epoch 8446 - loss: 1.4611014923392858 - val_loss: 1.263246147625337 - mutation_sigma: 0.0035944507650159012\n",
      "Epoch 8451 - loss: 1.4608956586069621 - val_loss: 1.2628769475233879 - mutation_sigma: 0.003590155043225505\n",
      "Epoch 8468 - loss: 1.460786441585939 - val_loss: 1.2543145749248623 - mutation_sigma: 0.003575565643095407\n",
      "Epoch 8471 - loss: 1.460784375457062 - val_loss: 1.2628216197695135 - mutation_sigma: 0.0035729936164284335\n",
      "Epoch 8482 - loss: 1.4606356060439114 - val_loss: 1.2568861993822331 - mutation_sigma: 0.0035635694501086465\n",
      "Epoch 8485 - loss: 1.460473288836986 - val_loss: 1.256553023909183 - mutation_sigma: 0.0035610010214000504\n",
      "Epoch 8523 - loss: 1.4597686133321053 - val_loss: 1.2604638884836 - mutation_sigma: 0.003528534190245544\n",
      "Epoch 8597 - loss: 1.4595628839504549 - val_loss: 1.2578171619989145 - mutation_sigma: 0.003465662237534756\n",
      "Epoch 8617 - loss: 1.4593026407952505 - val_loss: 1.2550412798064081 - mutation_sigma: 0.0034487495226830306\n",
      "Epoch 8664 - loss: 1.459150597626344 - val_loss: 1.2701255935435656 - mutation_sigma: 0.003409137522239282\n",
      "Epoch 8675 - loss: 1.4589249376410123 - val_loss: 1.2604641486319077 - mutation_sigma: 0.003399893480523947\n",
      "Epoch 8739 - loss: 1.4588769338087142 - val_loss: 1.2685340394265088 - mutation_sigma: 0.0033463111667598995\n",
      "Epoch 8751 - loss: 1.4587895654913483 - val_loss: 1.2715613274401047 - mutation_sigma: 0.0033363026005570383\n",
      "Epoch 8755 - loss: 1.4586348364550552 - val_loss: 1.2635105899666006 - mutation_sigma: 0.003332969079617539\n",
      "Epoch 8766 - loss: 1.458634395645247 - val_loss: 1.2652708926066274 - mutation_sigma: 0.0033238087687555923\n",
      "Epoch 8767 - loss: 1.458436147691491 - val_loss: 1.2644273790478642 - mutation_sigma: 0.003322976512717817\n",
      "Epoch 8780 - loss: 1.4582444244912005 - val_loss: 1.2636566072510855 - mutation_sigma: 0.003312164753593131\n",
      "Epoch 8789 - loss: 1.4581793171817947 - val_loss: 1.2692673499059652 - mutation_sigma: 0.0033046879180790656\n",
      "Epoch 8805 - loss: 1.4581101746095337 - val_loss: 1.2653724406949298 - mutation_sigma: 0.0032914123682368313\n",
      "Epoch 8815 - loss: 1.4577698830830006 - val_loss: 1.2722279808491792 - mutation_sigma: 0.00328312592842295\n",
      "Epoch 8866 - loss: 1.4576665177266865 - val_loss: 1.2702538349198818 - mutation_sigma: 0.003240993727831934\n",
      "Epoch 8886 - loss: 1.4575769809241927 - val_loss: 1.2710669751270398 - mutation_sigma: 0.0032245298561225577\n",
      "Epoch 8903 - loss: 1.4575057884686498 - val_loss: 1.267888809558722 - mutation_sigma: 0.003210561428736893\n",
      "Epoch 8911 - loss: 1.4571647380645267 - val_loss: 1.2584435215294614 - mutation_sigma: 0.003203996262527116\n",
      "Epoch 8913 - loss: 1.4571498168087997 - val_loss: 1.264199585214308 - mutation_sigma: 0.0032023557913743077\n",
      "Epoch 8959 - loss: 1.4570923734343184 - val_loss: 1.2702732182368892 - mutation_sigma: 0.0031647153581397186\n",
      "Epoch 8960 - loss: 1.4570628823680194 - val_loss: 1.2623917435674663 - mutation_sigma: 0.0031638990090569483\n",
      "Epoch 8967 - loss: 1.4568156021496332 - val_loss: 1.2654909554615272 - mutation_sigma: 0.0031581868504552022\n",
      "Epoch 8968 - loss: 1.456792840726397 - val_loss: 1.2663642932412804 - mutation_sigma: 0.0031573711541252854\n",
      "Epoch 8969 - loss: 1.4566764297722343 - val_loss: 1.266043009509765 - mutation_sigma: 0.0031565555393527683\n",
      "Epoch 8982 - loss: 1.4565965076614016 - val_loss: 1.2665410653048788 - mutation_sigma: 0.0031459599653241915\n",
      "Epoch 9028 - loss: 1.4564703412707258 - val_loss: 1.268318679933858 - mutation_sigma: 0.003108578331314991\n",
      "Epoch 9029 - loss: 1.4564370117354823 - val_loss: 1.2624758863371273 - mutation_sigma: 0.003107767595092968\n",
      "Epoch 9032 - loss: 1.4563137476554258 - val_loss: 1.26638830329814 - mutation_sigma: 0.003105335872763259\n",
      "Epoch 9040 - loss: 1.456264753273992 - val_loss: 1.2660882854796478 - mutation_sigma: 0.0030988548449245876\n",
      "Epoch 9047 - loss: 1.456239126157423 - val_loss: 1.2695099649943973 - mutation_sigma: 0.003093188196756182\n",
      "Epoch 9050 - loss: 1.4561306990521736 - val_loss: 1.2661148098300141 - mutation_sigma: 0.0030907608471527582\n",
      "Epoch 9074 - loss: 1.4561131595664096 - val_loss: 1.2707518589054394 - mutation_sigma: 0.003071368240815349\n",
      "Epoch 9093 - loss: 1.456060055486124 - val_loss: 1.2675780759378823 - mutation_sigma: 0.0030560487312510003\n",
      "Epoch 9116 - loss: 1.4560491285342714 - val_loss: 1.262877951795979 - mutation_sigma: 0.003037542959540905\n",
      "Epoch 9121 - loss: 1.4558628984973614 - val_loss: 1.2708817387617404 - mutation_sigma: 0.003033525594222683\n",
      "Epoch 9135 - loss: 1.4557025126834362 - val_loss: 1.2639891302106097 - mutation_sigma: 0.003022287650581033\n",
      "Epoch 9151 - loss: 1.455696244203747 - val_loss: 1.2681584635387573 - mutation_sigma: 0.0030094635347798623\n",
      "Epoch 9152 - loss: 1.4554625051938184 - val_loss: 1.265658513050937 - mutation_sigma: 0.003008662708550985\n",
      "Epoch 9179 - loss: 1.4553856150162825 - val_loss: 1.2636686170224654 - mutation_sigma: 0.0029870706408519293\n",
      "Epoch 9204 - loss: 1.4551976937266937 - val_loss: 1.2688425605260731 - mutation_sigma: 0.002967129894641947\n",
      "Epoch 9208 - loss: 1.455145576625207 - val_loss: 1.2624926666736218 - mutation_sigma: 0.002963943998495409\n",
      "Epoch 9230 - loss: 1.4551136922574601 - val_loss: 1.2664822291154763 - mutation_sigma: 0.0029464443283603757\n",
      "Epoch 9290 - loss: 1.4550568795078338 - val_loss: 1.2648854554020628 - mutation_sigma: 0.002898913151617304\n",
      "Epoch 9305 - loss: 1.4549139391732506 - val_loss: 1.2663315745111146 - mutation_sigma: 0.002887074846668545\n",
      "Epoch 9329 - loss: 1.4548198768945908 - val_loss: 1.2630288891621357 - mutation_sigma: 0.0028681704518230414\n",
      "Epoch 9356 - loss: 1.4547995524460728 - val_loss: 1.2711661686125897 - mutation_sigma: 0.0028469571637565966\n",
      "Epoch 9374 - loss: 1.454795727773736 - val_loss: 1.2683058162771927 - mutation_sigma: 0.0028328467550799404\n",
      "Epoch 9375 - loss: 1.454735741275274 - val_loss: 1.2694165450877055 - mutation_sigma: 0.0028320635878801665\n",
      "Epoch 9380 - loss: 1.4544278804179336 - val_loss: 1.265497346051344 - mutation_sigma: 0.002828148926299327\n",
      "Epoch 9387 - loss: 1.4543494987239627 - val_loss: 1.2658442633093188 - mutation_sigma: 0.002822671687032219\n",
      "Epoch 9408 - loss: 1.4543197196895525 - val_loss: 1.2717973300905865 - mutation_sigma: 0.0028062629525636967\n",
      "Epoch 9413 - loss: 1.454183515658343 - val_loss: 1.2663926463830726 - mutation_sigma: 0.002802361186786715\n",
      "Epoch 9430 - loss: 1.4541101416693973 - val_loss: 1.2687014621415975 - mutation_sigma: 0.0027891097648111186\n",
      "Epoch 9445 - loss: 1.454020165106509 - val_loss: 1.268792541666699 - mutation_sigma: 0.0027774360250313237\n",
      "Epoch 9457 - loss: 1.4539430334199008 - val_loss: 1.2692012496195786 - mutation_sigma: 0.0027681096313958856\n",
      "Epoch 9464 - loss: 1.453889785432081 - val_loss: 1.2696584952953127 - mutation_sigma: 0.0027626744007296245\n",
      "Epoch 9474 - loss: 1.4538612683863967 - val_loss: 1.2647808090706443 - mutation_sigma: 0.0027549163817866974\n",
      "Epoch 9483 - loss: 1.4537946505220345 - val_loss: 1.2728088896265768 - mutation_sigma: 0.0027479407940871293\n",
      "Epoch 9498 - loss: 1.453638491516716 - val_loss: 1.2690075089166453 - mutation_sigma: 0.0027363287553060014\n",
      "Epoch 9516 - loss: 1.4536367488421338 - val_loss: 1.2653649315859419 - mutation_sigma: 0.002722417278778702\n",
      "Epoch 9518 - loss: 1.4535731701502939 - val_loss: 1.2711649954116406 - mutation_sigma: 0.0027208731041630154\n",
      "Epoch 9525 - loss: 1.453560379686139 - val_loss: 1.2721493533093593 - mutation_sigma: 0.0027154709241916557\n",
      "Epoch 9532 - loss: 1.4535215898139684 - val_loss: 1.2692088579119827 - mutation_sigma: 0.0027100725240452005\n",
      "Epoch 9535 - loss: 1.4534718355458487 - val_loss: 1.2721641921642515 - mutation_sigma: 0.0027077600804162353\n",
      "Epoch 9547 - loss: 1.4531288000010685 - val_loss: 1.2717793985945198 - mutation_sigma: 0.002698517239417465\n",
      "Epoch 9560 - loss: 1.4530633454568072 - val_loss: 1.2690739863258393 - mutation_sigma: 0.002688516668842427\n",
      "Epoch 9584 - loss: 1.4530311912567486 - val_loss: 1.2723404687630064 - mutation_sigma: 0.002670088194698374\n",
      "Epoch 9599 - loss: 1.452986853306886 - val_loss: 1.275115580842589 - mutation_sigma: 0.00265859283561671\n",
      "Epoch 9621 - loss: 1.4528552380729127 - val_loss: 1.2719348550852536 - mutation_sigma: 0.00264176413260886\n",
      "Epoch 9626 - loss: 1.4528316994547925 - val_loss: 1.2702006313593912 - mutation_sigma: 0.0026379445874629226\n",
      "Epoch 9635 - loss: 1.452626291390787 - val_loss: 1.2697462459988293 - mutation_sigma: 0.0026310742165019385\n",
      "Epoch 9643 - loss: 1.4525688421102223 - val_loss: 1.2711750318000816 - mutation_sigma: 0.0026249724083582063\n",
      "Epoch 9650 - loss: 1.4525315394216352 - val_loss: 1.278398661009897 - mutation_sigma: 0.002619637328676039\n",
      "Epoch 9657 - loss: 1.4525051055304044 - val_loss: 1.268936612953278 - mutation_sigma: 0.0026143059818697035\n",
      "Epoch 9661 - loss: 1.4524693110398887 - val_loss: 1.276963145078171 - mutation_sigma: 0.002611261172960222\n",
      "Epoch 9663 - loss: 1.4521947292271966 - val_loss: 1.2747154983938978 - mutation_sigma: 0.002609739225120271\n",
      "Epoch 9684 - loss: 1.4521408818855681 - val_loss: 1.2743153403221372 - mutation_sigma: 0.0025937771350166188\n",
      "Epoch 9691 - loss: 1.4520722220636855 - val_loss: 1.2713402589894685 - mutation_sigma: 0.002588463882202809\n",
      "Epoch 9695 - loss: 1.451916880378828 - val_loss: 1.277870701014077 - mutation_sigma: 0.0025854294070329353\n",
      "Epoch 9709 - loss: 1.4514417440124276 - val_loss: 1.2723826073724942 - mutation_sigma: 0.0025748182964845023\n",
      "Epoch 9731 - loss: 1.4512366465574498 - val_loss: 1.281829526352631 - mutation_sigma: 0.0025581736764888887\n",
      "Epoch 9754 - loss: 1.4511688660984376 - val_loss: 1.2714488281596066 - mutation_sigma: 0.002540811587297476\n",
      "Epoch 9775 - loss: 1.4511263318887089 - val_loss: 1.2770543739240285 - mutation_sigma: 0.0025249940789111485\n",
      "Epoch 9777 - loss: 1.4508894670822658 - val_loss: 1.276399249485962 - mutation_sigma: 0.002523489381039955\n",
      "Epoch 9792 - loss: 1.450860113400768 - val_loss: 1.282934797788122 - mutation_sigma: 0.0025122137333828754\n",
      "Epoch 9794 - loss: 1.4507366626289273 - val_loss: 1.27720391020462 - mutation_sigma: 0.0025107115910696686\n",
      "Epoch 9809 - loss: 1.4505422873404072 - val_loss: 1.276292338598044 - mutation_sigma: 0.0024994550938161122\n",
      "Epoch 9841 - loss: 1.4505238133129412 - val_loss: 1.2790597463317757 - mutation_sigma: 0.0024754975857213543\n",
      "Epoch 9844 - loss: 1.4504537174713945 - val_loss: 1.2774130081334838 - mutation_sigma: 0.0024732554969846355\n",
      "Epoch 9850 - loss: 1.4503898098514183 - val_loss: 1.279990096777203 - mutation_sigma: 0.0024687733366850163\n",
      "Epoch 9858 - loss: 1.4503855458445598 - val_loss: 1.283909078951417 - mutation_sigma: 0.002462801304350312\n",
      "Epoch 9865 - loss: 1.4502811209476891 - val_loss: 1.279557120942712 - mutation_sigma: 0.0024575796933754\n",
      "Epoch 9868 - loss: 1.450256437214313 - val_loss: 1.2816302787216334 - mutation_sigma: 0.0024553429786628393\n",
      "Epoch 9881 - loss: 1.4501817465951718 - val_loss: 1.2789899016972939 - mutation_sigma: 0.0024456582976651155\n",
      "Epoch 9888 - loss: 1.4501614588232328 - val_loss: 1.2805288502801235 - mutation_sigma: 0.0024404486813967754\n",
      "Epoch 9891 - loss: 1.4499512504887841 - val_loss: 1.2796660118010696 - mutation_sigma: 0.0024382171047032638\n",
      "Epoch 9892 - loss: 1.4498012334795032 - val_loss: 1.2791961718127542 - mutation_sigma: 0.002437473394549937\n",
      "Epoch 9909 - loss: 1.4496909518838945 - val_loss: 1.2794263077807257 - mutation_sigma: 0.0024248416929375646\n",
      "Epoch 9932 - loss: 1.4496832851507189 - val_loss: 1.2792257441736319 - mutation_sigma: 0.0024077858843225934\n",
      "Epoch 9934 - loss: 1.4495025273581161 - val_loss: 1.2684052565150536 - mutation_sigma: 0.00240630462340285\n",
      "Epoch 9949 - loss: 1.4494926188391657 - val_loss: 1.278805500526476 - mutation_sigma: 0.002395204603565653\n",
      "Epoch 9957 - loss: 1.4494556609470288 - val_loss: 1.2684694323316266 - mutation_sigma: 0.0023892913968015213\n",
      "Epoch 9976 - loss: 1.4493934997651632 - val_loss: 1.274127130198042 - mutation_sigma: 0.0023752664735357696\n",
      "Epoch 9979 - loss: 1.4493162475286983 - val_loss: 1.2789465455128135 - mutation_sigma: 0.0023730544466170275\n",
      "Epoch 9980 - loss: 1.449230757877797 - val_loss: 1.280669558146814 - mutation_sigma: 0.0023723172517522107\n",
      "Epoch 9998 - loss: 1.4490757463063113 - val_loss: 1.2851728639742785 - mutation_sigma: 0.0023590603411886265\n"
     ]
    }
   ],
   "source": [
    "regressor = EvoMLPRegressor(n = 480 // 2, hidden_layers = [16], activation = \"relu\", random_state = 42)\n",
    "regressor.fit(scaled_X_train, y_train, epochs = 10000, validation_data = (scaled_X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test data: 1.6929183480160375\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = regressor.predict(scaled_X_test)\n",
    "print(f\"Loss on test data: {mean_absolute_error(y_test, y_pred)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(regressor.training_loss_history)\n",
    "ax.plot(regressor.validation_loss_history)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x169ae4e50>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = []\n",
    "xrange = 1000\n",
    "\n",
    "for x in range(1, xrange + 1):\n",
    "    y.append(5 * 1 / math.exp(x / (xrange / (10 * math.log10(xrange)))))\n",
    "\n",
    "plt.plot(list(range(xrange)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17eac0e50>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "#y = lambda epoch: \n",
    "\n",
    "f = lambda x: 1.1 + 0.8 * math.exp(-x * (50 / (epochs)))\n",
    "\n",
    "a = list(range(epochs))\n",
    "alist = [f(x) for x in a]\n",
    "\n",
    "\n",
    "print(alist[-1])\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(alist)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
