{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "X_train, y_train = df[~df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]], df[~df[\"horsepower\"].isna()][\"horsepower\"]\n",
    "X_pred = df[df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred = np.round(y_pred)\n",
    "df.loc[X_pred.index, \"horsepower\"] = y_pred\n",
    "df = pd.get_dummies(df.drop(\"name\", axis = 1), columns = [\"origin\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"mpg\"], axis = 1).values, df[\"mpg\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evolutionary_algos import EvoMLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 7.737057559160331 - val_loss: 8.01487563511419\n",
      "Epoch 1 - loss: 7.510331828695556 - val_loss: 8.968397931066926\n",
      "Epoch 2 - loss: 6.5947106040460755 - val_loss: 7.0458890972361505\n",
      "Epoch 4 - loss: 5.829510974233065 - val_loss: 4.908348079817188\n",
      "Epoch 5 - loss: 5.281573644652448 - val_loss: 4.607294742401278\n",
      "Epoch 10 - loss: 5.112338479928962 - val_loss: 4.755319630232976\n",
      "Epoch 11 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 20 - loss: 4.733582000861924 - val_loss: 4.326982884667847\n",
      "Epoch 25 - loss: 4.634677176188427 - val_loss: 4.266749060398398\n",
      "Epoch 31 - loss: 4.596983524063516 - val_loss: 4.909666057905956\n",
      "Epoch 32 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 48 - loss: 3.913337989896924 - val_loss: 4.15412824898813\n",
      "Epoch 53 - loss: 3.5760343636423015 - val_loss: 3.5443791654741332\n",
      "Epoch 59 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 68 - loss: 3.5000433360136887 - val_loss: 3.3229922460243655\n",
      "Epoch 71 - loss: 3.4039652344390032 - val_loss: 2.491508669678962\n",
      "Epoch 73 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 81 - loss: 3.1005799648925514 - val_loss: 2.8486087312841484\n",
      "Epoch 82 - loss: 3.0222522288176834 - val_loss: 2.542217669668907\n",
      "Epoch 87 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 105 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 133 - loss: 2.559722965143909 - val_loss: 2.278871614253666\n",
      "Epoch 135 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 144 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 152 - loss: 2.3175483599393893 - val_loss: 1.9666911107254528\n",
      "Epoch 155 - loss: 2.2213342418936124 - val_loss: 1.892180138493059\n",
      "Epoch 156 - loss: 2.210068066118549 - val_loss: 1.9522225317515347\n",
      "Epoch 159 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 196 - loss: 2.1693622563992427 - val_loss: 1.8299758409572484\n",
      "Epoch 200 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 208 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 222 - loss: 2.0442635165005583 - val_loss: 1.6074319218259039\n",
      "Epoch 223 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 254 - loss: 2.023776672506467 - val_loss: 1.63546868534046\n",
      "Epoch 255 - loss: 2.008583950839811 - val_loss: 1.7799745180328777\n",
      "Epoch 257 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 287 - loss: 1.9562957160859948 - val_loss: 1.7390892167771905\n",
      "Epoch 289 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 310 - loss: 1.9309500390857222 - val_loss: 1.6945487480502677\n",
      "Epoch 316 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 325 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 335 - loss: 1.9154285492142349 - val_loss: 1.7158586732435797\n",
      "Epoch 338 - loss: 1.9151044388582628 - val_loss: 1.6958512782525275\n",
      "Epoch 339 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 348 - loss: 1.888355758967431 - val_loss: 1.6014800276604366\n",
      "Epoch 349 - loss: 1.8794305645636966 - val_loss: 1.6818342037238376\n",
      "Epoch 353 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 364 - loss: 1.870995206111572 - val_loss: 1.7016134081101768\n",
      "Epoch 369 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 379 - loss: 1.8532092059376457 - val_loss: 1.6204742064508082\n",
      "Epoch 383 - loss: 1.8495022176064686 - val_loss: 1.537384180940168\n",
      "Epoch 388 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 400 - loss: 1.8291662439109284 - val_loss: 1.561813038150841\n",
      "Epoch 402 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 415 - loss: 1.8223668040710084 - val_loss: 1.5079992643264213\n",
      "Epoch 419 - loss: 1.8180591447725498 - val_loss: 1.5916522063030418\n",
      "Epoch 425 - loss: 1.8151129171360803 - val_loss: 1.5854997139467533\n",
      "Epoch 427 - loss: 1.8069069448466806 - val_loss: 1.5124144206687609\n",
      "Epoch 431 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 440 - loss: 1.804257465046809 - val_loss: 1.5614015536611947\n",
      "Epoch 442 - loss: 1.801706834485771 - val_loss: 1.6365161345341235\n",
      "Epoch 446 - loss: 1.8009563614907615 - val_loss: 1.5822342711172328\n",
      "Epoch 448 - loss: 1.7985136144097837 - val_loss: 1.6036817457436192\n",
      "Epoch 449 - loss: 1.7959964813126112 - val_loss: 1.526056797692123\n",
      "Epoch 450 - loss: 1.7897790210188556 - val_loss: 1.541225200561767\n",
      "Epoch 453 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 466 - loss: 1.7881156066846802 - val_loss: 1.5935755067461455\n",
      "Epoch 470 - loss: 1.7799616539797742 - val_loss: 1.5998823158004296\n",
      "Epoch 471 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 479 - loss: 1.7783441329002132 - val_loss: 1.5657429105747838\n",
      "Epoch 481 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885\n",
      "Epoch 488 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654\n",
      "Epoch 495 - loss: 1.776259104217378 - val_loss: 1.6172353922848757\n",
      "Epoch 496 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 511 - loss: 1.764155044742701 - val_loss: 1.5406418243586515\n",
      "Epoch 515 - loss: 1.7631299917064658 - val_loss: 1.5631614281014312\n",
      "Epoch 520 - loss: 1.7623378758170634 - val_loss: 1.570258071146122\n",
      "Epoch 521 - loss: 1.7599696061276071 - val_loss: 1.5707671051647425\n",
      "Epoch 523 - loss: 1.7582424283285596 - val_loss: 1.5680381689850313\n",
      "Epoch 524 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 540 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 554 - loss: 1.7466804076050904 - val_loss: 1.5439246282243797\n",
      "Epoch 559 - loss: 1.7466118735383698 - val_loss: 1.5732276844934583\n",
      "Epoch 560 - loss: 1.7460381342113067 - val_loss: 1.514554438737896\n",
      "Epoch 561 - loss: 1.742950017805513 - val_loss: 1.5361445369192621\n",
      "Epoch 564 - loss: 1.7412651519751683 - val_loss: 1.5111243194623012\n",
      "Epoch 566 - loss: 1.7403107512094358 - val_loss: 1.559605891963243\n",
      "Epoch 569 - loss: 1.739605461935401 - val_loss: 1.530268586265701\n",
      "Epoch 573 - loss: 1.7393697104844608 - val_loss: 1.5512218096661392\n",
      "Epoch 574 - loss: 1.739205797302013 - val_loss: 1.5453294240095399\n",
      "Epoch 575 - loss: 1.7360637365025036 - val_loss: 1.5461656595121493\n",
      "Epoch 578 - loss: 1.735630613300042 - val_loss: 1.4842882173835465\n",
      "Epoch 580 - loss: 1.7333939767503346 - val_loss: 1.531364632105483\n",
      "Epoch 582 - loss: 1.7323768692986115 - val_loss: 1.534465452545016\n",
      "Epoch 583 - loss: 1.7321788366233208 - val_loss: 1.499531703454028\n",
      "Epoch 585 - loss: 1.7307067744682159 - val_loss: 1.498881528236468\n",
      "Epoch 587 - loss: 1.7294842420149017 - val_loss: 1.503549936772614\n",
      "Epoch 591 - loss: 1.7292711298550967 - val_loss: 1.5176654613723755\n",
      "Epoch 594 - loss: 1.726997768850053 - val_loss: 1.5492679058088765\n",
      "Epoch 595 - loss: 1.7261082044570486 - val_loss: 1.5241542283617706\n",
      "Epoch 599 - loss: 1.7256136755329385 - val_loss: 1.4974519908053685\n",
      "Epoch 600 - loss: 1.7252279364529362 - val_loss: 1.5049623990735275\n",
      "Epoch 601 - loss: 1.7243256058350935 - val_loss: 1.5053657713100879\n",
      "Epoch 605 - loss: 1.7212225662129799 - val_loss: 1.5290890937073818\n",
      "Epoch 610 - loss: 1.7209217416447282 - val_loss: 1.490496839719547\n",
      "Epoch 611 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 619 - loss: 1.718658215655511 - val_loss: 1.4796551888575085\n",
      "Epoch 620 - loss: 1.7158997173797115 - val_loss: 1.513453916780404\n",
      "Epoch 625 - loss: 1.715151838834765 - val_loss: 1.5296853566272057\n",
      "Epoch 626 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 635 - loss: 1.7109478138702108 - val_loss: 1.5238941688419954\n",
      "Epoch 638 - loss: 1.7096352101859185 - val_loss: 1.4890912539036238\n",
      "Epoch 642 - loss: 1.708440954604318 - val_loss: 1.510154624032653\n",
      "Epoch 644 - loss: 1.7081257296126242 - val_loss: 1.4958803411039603\n",
      "Epoch 647 - loss: 1.7063782658958269 - val_loss: 1.487920463658274\n",
      "Epoch 648 - loss: 1.705653300556553 - val_loss: 1.4954504084561548\n",
      "Epoch 651 - loss: 1.705333518700015 - val_loss: 1.5066961285634057\n",
      "Epoch 653 - loss: 1.7039811355868277 - val_loss: 1.5104444961734165\n",
      "Epoch 654 - loss: 1.7035523053925126 - val_loss: 1.512511728638961\n",
      "Epoch 659 - loss: 1.7034174007308667 - val_loss: 1.539003342162316\n",
      "Epoch 661 - loss: 1.7030351033931648 - val_loss: 1.5126744468832705\n",
      "Epoch 662 - loss: 1.7027367548497458 - val_loss: 1.5060440586333737\n",
      "Epoch 665 - loss: 1.698695239222831 - val_loss: 1.5155143808052176\n",
      "Epoch 672 - loss: 1.6974853076129377 - val_loss: 1.4745067193513004\n",
      "Epoch 676 - loss: 1.6972898747608398 - val_loss: 1.5467003670344692\n",
      "Epoch 678 - loss: 1.697168381051914 - val_loss: 1.505829908194616\n",
      "Epoch 680 - loss: 1.696914368875435 - val_loss: 1.5008701796143022\n",
      "Epoch 683 - loss: 1.696352378010625 - val_loss: 1.5062800666303593\n",
      "Epoch 685 - loss: 1.6960374554833368 - val_loss: 1.4962515551630509\n",
      "Epoch 690 - loss: 1.6947684487633414 - val_loss: 1.4970305297276991\n",
      "Epoch 692 - loss: 1.6946052096226003 - val_loss: 1.5462865639226144\n",
      "Epoch 693 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 701 - loss: 1.6930717643274076 - val_loss: 1.509371985665412\n",
      "Epoch 706 - loss: 1.692434030765556 - val_loss: 1.5255420358341263\n",
      "Epoch 710 - loss: 1.692142700935924 - val_loss: 1.5159898515246275\n",
      "Epoch 712 - loss: 1.6912990209535448 - val_loss: 1.5087313671464395\n",
      "Epoch 715 - loss: 1.6911185376158928 - val_loss: 1.5056467992673657\n",
      "Epoch 716 - loss: 1.6910082086417622 - val_loss: 1.495912258256612\n",
      "Epoch 718 - loss: 1.6892950900791364 - val_loss: 1.50273339224132\n",
      "Epoch 720 - loss: 1.68875171111645 - val_loss: 1.4964446907206912\n",
      "Epoch 726 - loss: 1.6872407691104763 - val_loss: 1.4929733915197025\n",
      "Epoch 730 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405\n",
      "Epoch 737 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 745 - loss: 1.6843038397447672 - val_loss: 1.4980112666756435\n",
      "Epoch 747 - loss: 1.6837646923798686 - val_loss: 1.4920001984160052\n",
      "Epoch 748 - loss: 1.6815400839026688 - val_loss: 1.5079980592456197\n",
      "Epoch 754 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 764 - loss: 1.678606209189609 - val_loss: 1.5009182064445405\n",
      "Epoch 769 - loss: 1.6775822478516285 - val_loss: 1.5160291855355896\n",
      "Epoch 772 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 781 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927\n",
      "Epoch 788 - loss: 1.675114926767903 - val_loss: 1.5182156300807688\n",
      "Epoch 789 - loss: 1.673824369201371 - val_loss: 1.4987808326893184\n",
      "Epoch 792 - loss: 1.6730280152906596 - val_loss: 1.4862613681490555\n",
      "Epoch 794 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 808 - loss: 1.6705289085350614 - val_loss: 1.4701504725041372\n",
      "Epoch 809 - loss: 1.6704686532500106 - val_loss: 1.4720747509752061\n",
      "Epoch 812 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 821 - loss: 1.6670721445570622 - val_loss: 1.474692828512551\n",
      "Epoch 823 - loss: 1.6658819020704358 - val_loss: 1.4741190159945885\n",
      "Epoch 826 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 837 - loss: 1.6648559849230902 - val_loss: 1.4755556077612546\n",
      "Epoch 840 - loss: 1.6639619720958985 - val_loss: 1.4712610586091115\n",
      "Epoch 841 - loss: 1.6638914869138612 - val_loss: 1.4884123433153642\n",
      "Epoch 847 - loss: 1.6638781942467098 - val_loss: 1.4652805688444184\n",
      "Epoch 849 - loss: 1.6613669182008606 - val_loss: 1.4943225371740951\n",
      "Epoch 850 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 861 - loss: 1.659905797090408 - val_loss: 1.4565844985810863\n",
      "Epoch 864 - loss: 1.6590084626552613 - val_loss: 1.4701893675523645\n",
      "Epoch 869 - loss: 1.6587444026080567 - val_loss: 1.468069603491669\n",
      "Epoch 871 - loss: 1.6583405134688463 - val_loss: 1.4645905686395646\n",
      "Epoch 875 - loss: 1.6568021067649628 - val_loss: 1.487832968400229\n",
      "Epoch 880 - loss: 1.6560872098007888 - val_loss: 1.4688288529518012\n",
      "Epoch 883 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 893 - loss: 1.654787685576 - val_loss: 1.486376028497698\n",
      "Epoch 899 - loss: 1.6535480784899257 - val_loss: 1.4943725310453781\n",
      "Epoch 904 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 927 - loss: 1.6514359646964234 - val_loss: 1.4753617425050969\n",
      "Epoch 932 - loss: 1.651246206537777 - val_loss: 1.4598430881910627\n",
      "Epoch 937 - loss: 1.651135997566617 - val_loss: 1.4942517331738099\n",
      "Epoch 944 - loss: 1.6508516698489393 - val_loss: 1.4582764362354674\n",
      "Epoch 945 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 957 - loss: 1.6495275162810914 - val_loss: 1.4805903245828849\n",
      "Epoch 958 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 966 - loss: 1.6484735653856282 - val_loss: 1.4783408855616238\n",
      "Epoch 970 - loss: 1.6478457331618466 - val_loss: 1.4461332716670796\n",
      "Epoch 975 - loss: 1.6475169451201648 - val_loss: 1.4829689833208737\n",
      "Epoch 978 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 987 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 999 - loss: 1.6432171060057628 - val_loss: 1.4412142395130065\n",
      "Epoch 1005 - loss: 1.6423787383507042 - val_loss: 1.429135197763711\n",
      "Epoch 1007 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1020 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1035 - loss: 1.640139760144246 - val_loss: 1.462198376644603\n",
      "Epoch 1036 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1050 - loss: 1.6383806888283725 - val_loss: 1.4565238873397193\n",
      "Epoch 1055 - loss: 1.6367983936898376 - val_loss: 1.451633576709871\n",
      "Epoch 1057 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1073 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1083 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1091 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805\n",
      "Epoch 1098 - loss: 1.6325507871019767 - val_loss: 1.4624848293839974\n",
      "Epoch 1099 - loss: 1.6323963909816246 - val_loss: 1.4352683463359852\n",
      "Epoch 1105 - loss: 1.6320523203536097 - val_loss: 1.442748436420223\n",
      "Epoch 1112 - loss: 1.6310990515587733 - val_loss: 1.4348160708474755\n",
      "Epoch 1117 - loss: 1.6309782387432177 - val_loss: 1.4450676056125766\n",
      "Epoch 1122 - loss: 1.6309394872736378 - val_loss: 1.4402154068485826\n",
      "Epoch 1124 - loss: 1.6308117877416752 - val_loss: 1.4469543973769583\n",
      "Epoch 1126 - loss: 1.6302946005750518 - val_loss: 1.4542674355530585\n",
      "Epoch 1129 - loss: 1.6286865310588001 - val_loss: 1.4531830846577525\n",
      "Epoch 1135 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1145 - loss: 1.628251488607008 - val_loss: 1.4497247983174926\n",
      "Epoch 1147 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1160 - loss: 1.6274908659627139 - val_loss: 1.463378420713023\n",
      "Epoch 1164 - loss: 1.6274720500515067 - val_loss: 1.4335168875937137\n",
      "Epoch 1166 - loss: 1.627306901284965 - val_loss: 1.4571554896967558\n",
      "Epoch 1173 - loss: 1.6264614606280987 - val_loss: 1.4467500185857407\n",
      "Epoch 1175 - loss: 1.6262930171581862 - val_loss: 1.457137721251174\n",
      "Epoch 1179 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1188 - loss: 1.625127579994084 - val_loss: 1.439401800284108\n",
      "Epoch 1191 - loss: 1.6248521605043231 - val_loss: 1.4417814853160995\n",
      "Epoch 1197 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633\n",
      "Epoch 1204 - loss: 1.6233245589852225 - val_loss: 1.4389355433959061\n",
      "Epoch 1209 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1217 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1243 - loss: 1.6200211047631083 - val_loss: 1.436108879588107\n",
      "Epoch 1244 - loss: 1.619855971261856 - val_loss: 1.428986994191229\n",
      "Epoch 1248 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1258 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1273 - loss: 1.6183982544676203 - val_loss: 1.4366507717559354\n",
      "Epoch 1275 - loss: 1.6181907776349702 - val_loss: 1.4130167894093848\n",
      "Epoch 1279 - loss: 1.617765484813033 - val_loss: 1.4266342654312276\n",
      "Epoch 1282 - loss: 1.6176321458578218 - val_loss: 1.4223267805951552\n",
      "Epoch 1283 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1319 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1338 - loss: 1.614904506640372 - val_loss: 1.4349248220355644\n",
      "Epoch 1340 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1353 - loss: 1.6133852364182015 - val_loss: 1.429062068634201\n",
      "Epoch 1356 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1368 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1394 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1404 - loss: 1.61108893014879 - val_loss: 1.4133569434618303\n",
      "Epoch 1408 - loss: 1.6100370515085605 - val_loss: 1.4248052841520882\n",
      "Epoch 1409 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1450 - loss: 1.607722106586941 - val_loss: 1.4074509710703471\n",
      "Epoch 1451 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1460 - loss: 1.6070412894063324 - val_loss: 1.4066603490026868\n",
      "Epoch 1464 - loss: 1.6069294910239662 - val_loss: 1.4129183863061507\n",
      "Epoch 1465 - loss: 1.6055211443740645 - val_loss: 1.4159526710953128\n",
      "Epoch 1471 - loss: 1.6045739276717523 - val_loss: 1.4153331542996632\n",
      "Epoch 1473 - loss: 1.604516315891886 - val_loss: 1.4217820026536305\n",
      "Epoch 1480 - loss: 1.6044840917131065 - val_loss: 1.3992090312734642\n",
      "Epoch 1482 - loss: 1.603666870503361 - val_loss: 1.4206456593829184\n",
      "Epoch 1485 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1493 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1509 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1518 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1547 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1572 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1587 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1606 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1634 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1646 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1657 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1666 - loss: 1.5935303032250272 - val_loss: 1.4055526184665659\n",
      "Epoch 1671 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1679 - loss: 1.5921838656688483 - val_loss: 1.4127802192663867\n",
      "Epoch 1685 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1701 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1712 - loss: 1.5902763229877228 - val_loss: 1.4044477775034891\n",
      "Epoch 1716 - loss: 1.5901276282991317 - val_loss: 1.3749002354507798\n",
      "Epoch 1717 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1726 - loss: 1.5882287969133588 - val_loss: 1.3942791602441922\n",
      "Epoch 1728 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1785 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1794 - loss: 1.5872908109002555 - val_loss: 1.405288577911579\n",
      "Epoch 1796 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1818 - loss: 1.5865965442565646 - val_loss: 1.3958038407687527\n",
      "Epoch 1820 - loss: 1.5864597096736035 - val_loss: 1.391565936310267\n",
      "Epoch 1822 - loss: 1.5862017395467638 - val_loss: 1.3924337237143682\n",
      "Epoch 1826 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1837 - loss: 1.5858652674646028 - val_loss: 1.393871992174292\n",
      "Epoch 1844 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1871 - loss: 1.58420216043585 - val_loss: 1.4134689494418264\n",
      "Epoch 1873 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1897 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1952 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1964 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1990 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 2006 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2042 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2073 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2089 - loss: 1.5757596803440024 - val_loss: 1.3710288775113657\n",
      "Epoch 2093 - loss: 1.5745429566747737 - val_loss: 1.3727699961498507\n",
      "Epoch 2096 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2110 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2138 - loss: 1.573180087814976 - val_loss: 1.3515296257120644\n",
      "Epoch 2141 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2150 - loss: 1.57288294976354 - val_loss: 1.3664410720075442\n",
      "Epoch 2153 - loss: 1.5723427867801285 - val_loss: 1.3602193086317906\n",
      "Epoch 2154 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2163 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2187 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2197 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2222 - loss: 1.5694723349524686 - val_loss: 1.3619969428617993\n",
      "Epoch 2225 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2238 - loss: 1.5679719856885452 - val_loss: 1.357517687390613\n",
      "Epoch 2242 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2256 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2269 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2286 - loss: 1.567221932423831 - val_loss: 1.3599917622127142\n",
      "Epoch 2290 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2304 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2324 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2347 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2362 - loss: 1.5645828100656556 - val_loss: 1.3634595494291455\n",
      "Epoch 2368 - loss: 1.5641625365543275 - val_loss: 1.361848630328406\n",
      "Epoch 2371 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2409 - loss: 1.5617618107336222 - val_loss: 1.3591983412957955\n",
      "Epoch 2410 - loss: 1.5615659570619882 - val_loss: 1.3410703818692735\n",
      "Epoch 2415 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2436 - loss: 1.5609246493925848 - val_loss: 1.3294379724925294\n",
      "Epoch 2441 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2459 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2482 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2499 - loss: 1.558473087764596 - val_loss: 1.3613298436081642\n",
      "Epoch 2504 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2540 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2549 - loss: 1.557905464325448 - val_loss: 1.3701267708649914\n",
      "Epoch 2555 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2580 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2595 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2635 - loss: 1.5550931974759377 - val_loss: 1.3515422641632662\n",
      "Epoch 2640 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2657 - loss: 1.5546114879558162 - val_loss: 1.3403047028027593\n",
      "Epoch 2658 - loss: 1.5537020935593076 - val_loss: 1.343732385692427\n",
      "Epoch 2660 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2671 - loss: 1.5534287597153176 - val_loss: 1.349661232605175\n",
      "Epoch 2674 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2689 - loss: 1.5524552672687926 - val_loss: 1.3418883766063174\n",
      "Epoch 2694 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2719 - loss: 1.5511113930844524 - val_loss: 1.3268620191680884\n",
      "Epoch 2725 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2737 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2750 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2781 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2799 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2815 - loss: 1.5494832467618311 - val_loss: 1.3401901755194499\n",
      "Epoch 2817 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2858 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2877 - loss: 1.5480200665634962 - val_loss: 1.3478229909913135\n",
      "Epoch 2881 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2905 - loss: 1.5470738747735755 - val_loss: 1.3472224616177744\n",
      "Epoch 2907 - loss: 1.5467655286946798 - val_loss: 1.3587130611676121\n",
      "Epoch 2909 - loss: 1.5465063883981667 - val_loss: 1.3431249188959222\n",
      "Epoch 2910 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2954 - loss: 1.545050455142064 - val_loss: 1.3482194369955756\n",
      "Epoch 2955 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2967 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2975 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846\n",
      "Epoch 2982 - loss: 1.5443310784465387 - val_loss: 1.3466216330643277\n",
      "Epoch 2988 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 3000 - loss: 1.5433577749164704 - val_loss: 1.3412658900669032\n",
      "Epoch 3006 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3031 - loss: 1.5428267052781703 - val_loss: 1.3398620515160897\n",
      "Epoch 3035 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3046 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3070 - loss: 1.5420186039470125 - val_loss: 1.3348140151035488\n",
      "Epoch 3074 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3083 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3130 - loss: 1.540097868114943 - val_loss: 1.348944858849143\n",
      "Epoch 3136 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3145 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3172 - loss: 1.538825812803906 - val_loss: 1.3388292322709812\n",
      "Epoch 3173 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3200 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3213 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3230 - loss: 1.5366378782630943 - val_loss: 1.3269456203130479\n",
      "Epoch 3231 - loss: 1.5364623991683408 - val_loss: 1.3141104503132552\n",
      "Epoch 3234 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3269 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3304 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3317 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3358 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3368 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3391 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3427 - loss: 1.532170640374761 - val_loss: 1.3088773334041348\n",
      "Epoch 3433 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3462 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3472 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3484 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3493 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3522 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3554 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3640 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3652 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3758 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3806 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3835 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3857 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3869 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3878 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3894 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3947 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3963 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3973 - loss: 1.5220082132768606 - val_loss: 1.3042830884535657\n",
      "Epoch 3974 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3987 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3996 - loss: 1.5214498907035865 - val_loss: 1.2958707280956148\n",
      "Epoch 4002 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4036 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4099 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4114 - loss: 1.5185037806662043 - val_loss: 1.2980556150709521\n",
      "Epoch 4117 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4134 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4151 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4175 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4189 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182\n",
      "Epoch 4196 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4204 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4213 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4228 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4263 - loss: 1.5152437421558547 - val_loss: 1.3080832720925255\n",
      "Epoch 4268 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4283 - loss: 1.5148942393023568 - val_loss: 1.3065510102969256\n",
      "Epoch 4286 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4295 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4315 - loss: 1.513891937956392 - val_loss: 1.298137156801345\n",
      "Epoch 4316 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4330 - loss: 1.513382280229381 - val_loss: 1.300556329033807\n",
      "Epoch 4335 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4347 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4369 - loss: 1.5125366500400963 - val_loss: 1.2931841025641357\n",
      "Epoch 4371 - loss: 1.5125217931843176 - val_loss: 1.3008091703251827\n",
      "Epoch 4376 - loss: 1.5121335510237215 - val_loss: 1.3015006564554483\n",
      "Epoch 4378 - loss: 1.5119658458277694 - val_loss: 1.2900086225192033\n",
      "Epoch 4380 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4398 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4409 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4434 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4448 - loss: 1.5107704102709076 - val_loss: 1.297934057752117\n",
      "Epoch 4449 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968\n",
      "Epoch 4456 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4466 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4479 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693\n",
      "Epoch 4486 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4512 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4525 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4551 - loss: 1.508909006649633 - val_loss: 1.2791477621236889\n",
      "Epoch 4552 - loss: 1.508865963767768 - val_loss: 1.3106510429499445\n",
      "Epoch 4555 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4570 - loss: 1.5081687463813689 - val_loss: 1.2845910762198764\n",
      "Epoch 4572 - loss: 1.5080982097189148 - val_loss: 1.283732370635203\n",
      "Epoch 4575 - loss: 1.5080871613938927 - val_loss: 1.283296489881322\n",
      "Epoch 4580 - loss: 1.5073057507144547 - val_loss: 1.2893112008414345\n",
      "Epoch 4586 - loss: 1.5072098196960784 - val_loss: 1.2926466911640748\n",
      "Epoch 4591 - loss: 1.507003036716309 - val_loss: 1.2851665934640484\n",
      "Epoch 4630 - loss: 1.5068094991537544 - val_loss: 1.2919428799833415\n",
      "Epoch 4658 - loss: 1.5066375899154258 - val_loss: 1.2879122577230846\n",
      "Epoch 4703 - loss: 1.5062359777994059 - val_loss: 1.2872495781753723\n",
      "Epoch 4707 - loss: 1.5061095174006922 - val_loss: 1.3037762680506721\n",
      "Epoch 4717 - loss: 1.5059598561485006 - val_loss: 1.282721320635646\n",
      "Epoch 4732 - loss: 1.5055297222377355 - val_loss: 1.2911719620383522\n",
      "Epoch 4733 - loss: 1.505272576247615 - val_loss: 1.2840301306034452\n",
      "Epoch 4779 - loss: 1.5051810914713823 - val_loss: 1.2940151466980343\n",
      "Epoch 4788 - loss: 1.5051765567366318 - val_loss: 1.2988164881251318\n",
      "Epoch 4792 - loss: 1.5046960061511951 - val_loss: 1.279217641354839\n",
      "Epoch 4806 - loss: 1.5044983289245635 - val_loss: 1.2885104590934886\n",
      "Epoch 4821 - loss: 1.5044722248690192 - val_loss: 1.2928468016675196\n",
      "Epoch 4822 - loss: 1.5042224924780383 - val_loss: 1.2927753868040095\n",
      "Epoch 4836 - loss: 1.5041046576164734 - val_loss: 1.289013941158037\n",
      "Epoch 4874 - loss: 1.5040781901023623 - val_loss: 1.2814930029061262\n",
      "Epoch 4885 - loss: 1.5033684040972342 - val_loss: 1.284231924016209\n",
      "Epoch 4902 - loss: 1.5032476521506928 - val_loss: 1.2854602429585003\n",
      "Epoch 4910 - loss: 1.5030883292275052 - val_loss: 1.27869750305631\n",
      "Epoch 4919 - loss: 1.5030496280049621 - val_loss: 1.2692527206152497\n",
      "Epoch 4933 - loss: 1.5027202802082984 - val_loss: 1.2821519235393695\n",
      "Epoch 4942 - loss: 1.502581005147861 - val_loss: 1.2835676685294335\n",
      "Epoch 4946 - loss: 1.5022849527070081 - val_loss: 1.287627649924723\n",
      "Epoch 4970 - loss: 1.5018120713155578 - val_loss: 1.2861409120403433\n",
      "Epoch 4987 - loss: 1.501795179042218 - val_loss: 1.2785904462949464\n",
      "Epoch 4993 - loss: 1.5016102550300652 - val_loss: 1.272660181326898\n",
      "Epoch 4996 - loss: 1.5015418648169507 - val_loss: 1.2872474208768367\n",
      "Epoch 5000 - loss: 1.501196309814991 - val_loss: 1.2741443882820158\n",
      "Epoch 5018 - loss: 1.5010228723180163 - val_loss: 1.2807667033862433\n",
      "Epoch 5032 - loss: 1.5008514154413137 - val_loss: 1.2888859887381652\n",
      "Epoch 5035 - loss: 1.500805393211421 - val_loss: 1.282649837005486\n",
      "Epoch 5042 - loss: 1.5004736876061073 - val_loss: 1.2755180428946449\n",
      "Epoch 5056 - loss: 1.5002979797580764 - val_loss: 1.2650779099077214\n",
      "Epoch 5062 - loss: 1.5002314722179597 - val_loss: 1.2840488332606865\n",
      "Epoch 5066 - loss: 1.500181513270051 - val_loss: 1.2888854086609605\n",
      "Epoch 5074 - loss: 1.4997184080840422 - val_loss: 1.2836411383062234\n",
      "Epoch 5099 - loss: 1.4996359988055088 - val_loss: 1.2816148271062549\n",
      "Epoch 5103 - loss: 1.499210111974627 - val_loss: 1.2775283562938307\n",
      "Epoch 5144 - loss: 1.4991932124319747 - val_loss: 1.2820290405083903\n",
      "Epoch 5149 - loss: 1.4991253460005922 - val_loss: 1.2783070079731527\n",
      "Epoch 5164 - loss: 1.4988076971381181 - val_loss: 1.278216310349523\n",
      "Epoch 5185 - loss: 1.4986866700297619 - val_loss: 1.2780612374841887\n",
      "Epoch 5198 - loss: 1.49866103200409 - val_loss: 1.2776518049522625\n",
      "Epoch 5204 - loss: 1.4978695892354414 - val_loss: 1.2732750112198776\n",
      "Epoch 5240 - loss: 1.4963890926472199 - val_loss: 1.2848576137746726\n",
      "Epoch 5326 - loss: 1.4963776081194793 - val_loss: 1.2816482023105216\n",
      "Epoch 5363 - loss: 1.4963152584364467 - val_loss: 1.270320744097884\n",
      "Epoch 5379 - loss: 1.4960588767470848 - val_loss: 1.2771688202634066\n",
      "Epoch 5394 - loss: 1.4957058536568655 - val_loss: 1.2751744289441\n",
      "Epoch 5428 - loss: 1.4951561142458676 - val_loss: 1.2661294500836662\n",
      "Epoch 5464 - loss: 1.4948015477764829 - val_loss: 1.2749284131882912\n",
      "Epoch 5479 - loss: 1.4946285288325023 - val_loss: 1.279334029268152\n",
      "Epoch 5507 - loss: 1.494430116780131 - val_loss: 1.2682605216090237\n",
      "Epoch 5544 - loss: 1.493798591259605 - val_loss: 1.2697328656494486\n",
      "Epoch 5557 - loss: 1.4935385478205103 - val_loss: 1.2699178887176656\n",
      "Epoch 5621 - loss: 1.4933719354027788 - val_loss: 1.2640891657950608\n",
      "Epoch 5624 - loss: 1.4929995791489263 - val_loss: 1.269367257165318\n",
      "Epoch 5640 - loss: 1.49264926926856 - val_loss: 1.272248423281841\n",
      "Epoch 5653 - loss: 1.4925149745024322 - val_loss: 1.2747594368764266\n",
      "Epoch 5690 - loss: 1.4922584750343144 - val_loss: 1.2583256557327602\n",
      "Epoch 5714 - loss: 1.492099675261437 - val_loss: 1.2580157619848262\n",
      "Epoch 5728 - loss: 1.491785141519088 - val_loss: 1.2674778902012185\n",
      "Epoch 5732 - loss: 1.4910684524268492 - val_loss: 1.2647893731592394\n",
      "Epoch 5761 - loss: 1.4910105110474055 - val_loss: 1.2689457535274016\n",
      "Epoch 5797 - loss: 1.4905906844103365 - val_loss: 1.2669432934568952\n",
      "Epoch 5826 - loss: 1.490150129460951 - val_loss: 1.2624765774103095\n",
      "Epoch 5850 - loss: 1.4896779277602046 - val_loss: 1.2698350594619634\n",
      "Epoch 5852 - loss: 1.4892567590114896 - val_loss: 1.2604117810143074\n",
      "Epoch 5916 - loss: 1.4892539094450652 - val_loss: 1.2586303125075269\n",
      "Epoch 5924 - loss: 1.4886303669430194 - val_loss: 1.2665352701115844\n",
      "Epoch 5957 - loss: 1.4884333129445895 - val_loss: 1.2605915464216064\n",
      "Epoch 6008 - loss: 1.488175158814361 - val_loss: 1.2613678438614138\n",
      "Epoch 6014 - loss: 1.4878357362992205 - val_loss: 1.2723715205952864\n",
      "Epoch 6046 - loss: 1.487445856613044 - val_loss: 1.2614896548875967\n",
      "Epoch 6072 - loss: 1.4871824525430277 - val_loss: 1.2585186494829452\n",
      "Epoch 6119 - loss: 1.4870384906102312 - val_loss: 1.2653351049541768\n",
      "Epoch 6122 - loss: 1.4866209625693334 - val_loss: 1.269241198699485\n",
      "Epoch 6129 - loss: 1.4863231644062105 - val_loss: 1.2596555841405306\n",
      "Epoch 6208 - loss: 1.4862681235275805 - val_loss: 1.2600821612854556\n",
      "Epoch 6212 - loss: 1.4858231298994389 - val_loss: 1.2487751311731254\n",
      "Epoch 6227 - loss: 1.4857939030442637 - val_loss: 1.260741010983042\n",
      "Epoch 6231 - loss: 1.485700347236984 - val_loss: 1.258045821535246\n",
      "Epoch 6236 - loss: 1.4853606720077355 - val_loss: 1.2632172973582798\n",
      "Epoch 6246 - loss: 1.4853265225842114 - val_loss: 1.2463038172729555\n",
      "Epoch 6279 - loss: 1.4849563947221607 - val_loss: 1.251250988017374\n",
      "Epoch 6301 - loss: 1.4847156374814678 - val_loss: 1.2529241836838019\n",
      "Epoch 6303 - loss: 1.484602711506318 - val_loss: 1.26206999620929\n",
      "Epoch 6329 - loss: 1.4836579387296518 - val_loss: 1.2635487999718862\n",
      "Epoch 6444 - loss: 1.4836364680146477 - val_loss: 1.260835673968235\n",
      "Epoch 6464 - loss: 1.4836304354184013 - val_loss: 1.2526582590968127\n",
      "Epoch 6469 - loss: 1.4835500192437772 - val_loss: 1.257906615968178\n",
      "Epoch 6470 - loss: 1.483420783892503 - val_loss: 1.2486516631486249\n",
      "Epoch 6476 - loss: 1.4830867700858181 - val_loss: 1.2587798549765263\n",
      "Epoch 6494 - loss: 1.4824283058535783 - val_loss: 1.2566467790591527\n",
      "Epoch 6498 - loss: 1.481898698297152 - val_loss: 1.2433329851032071\n",
      "Epoch 6574 - loss: 1.4818860502537496 - val_loss: 1.258945044880992\n",
      "Epoch 6581 - loss: 1.481024053973441 - val_loss: 1.261563480733174\n",
      "Epoch 6617 - loss: 1.4805951337109031 - val_loss: 1.2486610050887748\n",
      "Epoch 6639 - loss: 1.4805276660743802 - val_loss: 1.251613473068183\n",
      "Epoch 6648 - loss: 1.4804723027478688 - val_loss: 1.2587288926814182\n",
      "Epoch 6649 - loss: 1.4804493522436153 - val_loss: 1.2537419613640182\n",
      "Epoch 6661 - loss: 1.4802916687581793 - val_loss: 1.2520058984867453\n",
      "Epoch 6662 - loss: 1.4799181874441314 - val_loss: 1.2640662323200567\n",
      "Epoch 6685 - loss: 1.4796055131022696 - val_loss: 1.256177703631446\n",
      "Epoch 6691 - loss: 1.4793681605337479 - val_loss: 1.2480119550927955\n",
      "Epoch 6712 - loss: 1.4791538103001154 - val_loss: 1.2502823462779713\n",
      "Epoch 6721 - loss: 1.4790388081150136 - val_loss: 1.252721201942059\n",
      "Epoch 6733 - loss: 1.4788853306142171 - val_loss: 1.253124309550036\n",
      "Epoch 6741 - loss: 1.4787264883093063 - val_loss: 1.2561613256220774\n",
      "Epoch 6755 - loss: 1.4785719078017279 - val_loss: 1.2612470775100282\n",
      "Epoch 6772 - loss: 1.478507365428562 - val_loss: 1.2558384197469021\n",
      "Epoch 6776 - loss: 1.4783453623983085 - val_loss: 1.2587747613496276\n",
      "Epoch 6793 - loss: 1.4777691601558105 - val_loss: 1.2515109952121755\n",
      "Epoch 6799 - loss: 1.4774220401812757 - val_loss: 1.2529132655603898\n",
      "Epoch 6806 - loss: 1.477393455444324 - val_loss: 1.2546628404535598\n",
      "Epoch 6820 - loss: 1.4772582684591433 - val_loss: 1.2530169327698737\n",
      "Epoch 6861 - loss: 1.4772452914543055 - val_loss: 1.2519273598541971\n",
      "Epoch 6870 - loss: 1.476566884116717 - val_loss: 1.2580959341587945\n",
      "Epoch 6879 - loss: 1.4765278437749945 - val_loss: 1.2469955094802863\n",
      "Epoch 6900 - loss: 1.4762581917929547 - val_loss: 1.2508448739772706\n",
      "Epoch 6906 - loss: 1.4760136035899813 - val_loss: 1.255754199173026\n",
      "Epoch 6942 - loss: 1.475897724151448 - val_loss: 1.2479906104542358\n",
      "Epoch 6953 - loss: 1.4755585865193164 - val_loss: 1.2464479041635375\n",
      "Epoch 6966 - loss: 1.475542004887329 - val_loss: 1.25208948970155\n",
      "Epoch 6979 - loss: 1.4749340147127583 - val_loss: 1.2509937388389687\n",
      "Epoch 6987 - loss: 1.474810243339331 - val_loss: 1.252249847160468\n",
      "Epoch 7001 - loss: 1.4747904452618468 - val_loss: 1.2498538756569153\n",
      "Epoch 7009 - loss: 1.4746790273675023 - val_loss: 1.2522287384931081\n",
      "Epoch 7022 - loss: 1.4746596570312098 - val_loss: 1.2517007725990041\n",
      "Epoch 7027 - loss: 1.4744489408597985 - val_loss: 1.2450102022109362\n",
      "Epoch 7036 - loss: 1.474135546497918 - val_loss: 1.2440803177658082\n",
      "Epoch 7045 - loss: 1.4739501815813503 - val_loss: 1.2552955616646286\n",
      "Epoch 7078 - loss: 1.4732441404240832 - val_loss: 1.2512445244730777\n",
      "Epoch 7110 - loss: 1.4730569285852226 - val_loss: 1.2485917116822665\n",
      "Epoch 7145 - loss: 1.473011429557416 - val_loss: 1.2579883340760598\n",
      "Epoch 7146 - loss: 1.4728304204645564 - val_loss: 1.25760577426447\n",
      "Epoch 7153 - loss: 1.4723994395857125 - val_loss: 1.2554518258617713\n",
      "Epoch 7174 - loss: 1.471834765224373 - val_loss: 1.2597405159056454\n",
      "Epoch 7227 - loss: 1.4716252183717609 - val_loss: 1.2472808269525761\n",
      "Epoch 7245 - loss: 1.4716196686039873 - val_loss: 1.2554037343053444\n",
      "Epoch 7268 - loss: 1.4712020374582064 - val_loss: 1.2509412012947103\n",
      "Epoch 7301 - loss: 1.4709313252132767 - val_loss: 1.2410590067473883\n",
      "Epoch 7328 - loss: 1.4708253355308665 - val_loss: 1.253088441603009\n",
      "Epoch 7340 - loss: 1.4705562322161618 - val_loss: 1.2522812315754674\n",
      "Epoch 7363 - loss: 1.4703409421190634 - val_loss: 1.2513505827851208\n",
      "Epoch 7384 - loss: 1.4701714339620668 - val_loss: 1.2497721730341005\n",
      "Epoch 7392 - loss: 1.4700819264758138 - val_loss: 1.2469529518791795\n",
      "Epoch 7402 - loss: 1.4699783981711365 - val_loss: 1.2583510141877021\n",
      "Epoch 7417 - loss: 1.4698037522961365 - val_loss: 1.2498754597115527\n",
      "Epoch 7435 - loss: 1.469692970440176 - val_loss: 1.2475151193820921\n",
      "Epoch 7459 - loss: 1.4691006332949657 - val_loss: 1.246224181053335\n",
      "Epoch 7520 - loss: 1.4688863615391285 - val_loss: 1.2534558039634793\n",
      "Epoch 7564 - loss: 1.468872976179937 - val_loss: 1.2476277335735766\n",
      "Epoch 7568 - loss: 1.4687588422580797 - val_loss: 1.2545361720414765\n",
      "Epoch 7574 - loss: 1.468133299642567 - val_loss: 1.2614612762095343\n",
      "Epoch 7603 - loss: 1.4679581585549961 - val_loss: 1.2474882852590425\n",
      "Epoch 7623 - loss: 1.467947996988755 - val_loss: 1.2528160864659634\n",
      "Epoch 7629 - loss: 1.4679248068875588 - val_loss: 1.2517365842950756\n",
      "Epoch 7630 - loss: 1.4678523994802348 - val_loss: 1.2573363414758487\n",
      "Epoch 7646 - loss: 1.467682448396118 - val_loss: 1.2468634935448566\n",
      "Epoch 7674 - loss: 1.4675579369546259 - val_loss: 1.2446245732871677\n",
      "Epoch 7680 - loss: 1.4674347852429976 - val_loss: 1.252471575987131\n",
      "Epoch 7687 - loss: 1.4672036610634374 - val_loss: 1.2543171873118528\n",
      "Epoch 7702 - loss: 1.4671553116908884 - val_loss: 1.24648648639911\n",
      "Epoch 7723 - loss: 1.467129310689095 - val_loss: 1.261389174137212\n",
      "Epoch 7737 - loss: 1.466883807078504 - val_loss: 1.2561188454965015\n",
      "Epoch 7741 - loss: 1.4664519290312104 - val_loss: 1.2651734882835672\n",
      "Epoch 7743 - loss: 1.466313558623826 - val_loss: 1.2634702893001273\n",
      "Epoch 7782 - loss: 1.466163400832144 - val_loss: 1.2584104029094432\n",
      "Epoch 7783 - loss: 1.4661404773355657 - val_loss: 1.2513381662751446\n",
      "Epoch 7794 - loss: 1.4659437370906003 - val_loss: 1.2528410294660242\n",
      "Epoch 7800 - loss: 1.465788812236337 - val_loss: 1.2581776614181504\n",
      "Epoch 7835 - loss: 1.4657330707664877 - val_loss: 1.2447019472860672\n",
      "Epoch 7842 - loss: 1.465649986051515 - val_loss: 1.2494411707784152\n",
      "Epoch 7847 - loss: 1.4652955113324515 - val_loss: 1.2590800729503262\n",
      "Epoch 7915 - loss: 1.4651427809355935 - val_loss: 1.2555351870583125\n",
      "Epoch 7917 - loss: 1.4650241192070674 - val_loss: 1.2647280693654568\n",
      "Epoch 7922 - loss: 1.4649550358344645 - val_loss: 1.255494715228838\n",
      "Epoch 7957 - loss: 1.4648262171730269 - val_loss: 1.2583684387454683\n",
      "Epoch 7982 - loss: 1.4648062753472508 - val_loss: 1.2514673304184338\n",
      "Epoch 7998 - loss: 1.4647050668314021 - val_loss: 1.2549650421967309\n",
      "Epoch 8034 - loss: 1.4643003096735945 - val_loss: 1.253537106696657\n",
      "Epoch 8075 - loss: 1.464110919289541 - val_loss: 1.253048073055666\n",
      "Epoch 8086 - loss: 1.4639537622732774 - val_loss: 1.2598536125214284\n",
      "Epoch 8146 - loss: 1.4638198116276793 - val_loss: 1.2650890488440683\n",
      "Epoch 8147 - loss: 1.4636230733872584 - val_loss: 1.2564549960438967\n",
      "Epoch 8195 - loss: 1.463360705857805 - val_loss: 1.2576881403662683\n",
      "Epoch 8231 - loss: 1.4631709042913092 - val_loss: 1.2554555407903514\n",
      "Epoch 8239 - loss: 1.4629975177485792 - val_loss: 1.2541451514665782\n",
      "Epoch 8241 - loss: 1.4629230038059422 - val_loss: 1.251319983733881\n",
      "Epoch 8269 - loss: 1.4628878721957725 - val_loss: 1.2613605580832368\n",
      "Epoch 8274 - loss: 1.4627207241402977 - val_loss: 1.2625045689318743\n",
      "Epoch 8287 - loss: 1.4626757492863611 - val_loss: 1.262062442048671\n",
      "Epoch 8292 - loss: 1.4626334837914976 - val_loss: 1.2535757917883998\n",
      "Epoch 8295 - loss: 1.4625674877297405 - val_loss: 1.2549694114232786\n",
      "Epoch 8305 - loss: 1.4624909212710144 - val_loss: 1.2654322832620826\n",
      "Epoch 8310 - loss: 1.4624181318965113 - val_loss: 1.251057914987765\n",
      "Epoch 8318 - loss: 1.4622769939963787 - val_loss: 1.263714510076754\n",
      "Epoch 8326 - loss: 1.461962034764587 - val_loss: 1.2543889258277594\n",
      "Epoch 8332 - loss: 1.4617689630703596 - val_loss: 1.257360597481568\n",
      "Epoch 8363 - loss: 1.4614424908132608 - val_loss: 1.26110824899517\n",
      "Epoch 8416 - loss: 1.4613618455529513 - val_loss: 1.255437960790094\n",
      "Epoch 8420 - loss: 1.4612360407905334 - val_loss: 1.2574396882051802\n",
      "Epoch 8446 - loss: 1.4611014923392858 - val_loss: 1.263246147625337\n",
      "Epoch 8451 - loss: 1.4608956586069621 - val_loss: 1.2628769475233879\n",
      "Epoch 8468 - loss: 1.460786441585939 - val_loss: 1.2543145749248623\n",
      "Epoch 8471 - loss: 1.460784375457062 - val_loss: 1.2628216197695135\n",
      "Epoch 8482 - loss: 1.4606356060439114 - val_loss: 1.2568861993822331\n",
      "Epoch 8485 - loss: 1.460473288836986 - val_loss: 1.256553023909183\n",
      "Epoch 8523 - loss: 1.4597686133321053 - val_loss: 1.2604638884836\n",
      "Epoch 8597 - loss: 1.4595628839504549 - val_loss: 1.2578171619989145\n",
      "Epoch 8617 - loss: 1.4593026407952505 - val_loss: 1.2550412798064081\n",
      "Epoch 8664 - loss: 1.459150597626344 - val_loss: 1.2701255935435656\n",
      "Epoch 8675 - loss: 1.4589249376410123 - val_loss: 1.2604641486319077\n",
      "Epoch 8739 - loss: 1.4588769338087142 - val_loss: 1.2685340394265088\n",
      "Epoch 8751 - loss: 1.4587895654913483 - val_loss: 1.2715613274401047\n",
      "Epoch 8755 - loss: 1.4586348364550552 - val_loss: 1.2635105899666006\n",
      "Epoch 8766 - loss: 1.458634395645247 - val_loss: 1.2652708926066274\n",
      "Epoch 8767 - loss: 1.458436147691491 - val_loss: 1.2644273790478642\n",
      "Epoch 8780 - loss: 1.4582444244912005 - val_loss: 1.2636566072510855\n",
      "Epoch 8789 - loss: 1.4581793171817947 - val_loss: 1.2692673499059652\n",
      "Epoch 8805 - loss: 1.4581101746095337 - val_loss: 1.2653724406949298\n",
      "Epoch 8815 - loss: 1.4577698830830006 - val_loss: 1.2722279808491792\n",
      "Epoch 8866 - loss: 1.4576665177266865 - val_loss: 1.2702538349198818\n",
      "Epoch 8886 - loss: 1.4575769809241927 - val_loss: 1.2710669751270398\n",
      "Epoch 8903 - loss: 1.4575057884686498 - val_loss: 1.267888809558722\n",
      "Epoch 8911 - loss: 1.4571647380645267 - val_loss: 1.2584435215294614\n",
      "Epoch 8913 - loss: 1.4571498168087997 - val_loss: 1.264199585214308\n",
      "Epoch 8959 - loss: 1.4570923734343184 - val_loss: 1.2702732182368892\n",
      "Epoch 8960 - loss: 1.4570628823680194 - val_loss: 1.2623917435674663\n",
      "Epoch 8967 - loss: 1.4568156021496332 - val_loss: 1.2654909554615272\n",
      "Epoch 8968 - loss: 1.456792840726397 - val_loss: 1.2663642932412804\n",
      "Epoch 8969 - loss: 1.4566764297722343 - val_loss: 1.266043009509765\n",
      "Epoch 8982 - loss: 1.4565965076614016 - val_loss: 1.2665410653048788\n",
      "Epoch 9028 - loss: 1.4564703412707258 - val_loss: 1.268318679933858\n",
      "Epoch 9029 - loss: 1.4564370117354823 - val_loss: 1.2624758863371273\n",
      "Epoch 9032 - loss: 1.4563137476554258 - val_loss: 1.26638830329814\n",
      "Epoch 9040 - loss: 1.456264753273992 - val_loss: 1.2660882854796478\n",
      "Epoch 9047 - loss: 1.456239126157423 - val_loss: 1.2695099649943973\n",
      "Epoch 9050 - loss: 1.4561306990521736 - val_loss: 1.2661148098300141\n",
      "Epoch 9074 - loss: 1.4561131595664096 - val_loss: 1.2707518589054394\n",
      "Epoch 9093 - loss: 1.456060055486124 - val_loss: 1.2675780759378823\n",
      "Epoch 9116 - loss: 1.4560491285342714 - val_loss: 1.262877951795979\n",
      "Epoch 9121 - loss: 1.4558628984973614 - val_loss: 1.2708817387617404\n",
      "Epoch 9135 - loss: 1.4557025126834362 - val_loss: 1.2639891302106097\n",
      "Epoch 9151 - loss: 1.455696244203747 - val_loss: 1.2681584635387573\n",
      "Epoch 9152 - loss: 1.4554625051938184 - val_loss: 1.265658513050937\n",
      "Epoch 9179 - loss: 1.4553856150162825 - val_loss: 1.2636686170224654\n",
      "Epoch 9204 - loss: 1.4551976937266937 - val_loss: 1.2688425605260731\n",
      "Epoch 9208 - loss: 1.455145576625207 - val_loss: 1.2624926666736218\n",
      "Epoch 9230 - loss: 1.4551136922574601 - val_loss: 1.2664822291154763\n",
      "Epoch 9290 - loss: 1.4550568795078338 - val_loss: 1.2648854554020628\n",
      "Epoch 9305 - loss: 1.4549139391732506 - val_loss: 1.2663315745111146\n",
      "Epoch 9329 - loss: 1.4548198768945908 - val_loss: 1.2630288891621357\n",
      "Epoch 9356 - loss: 1.4547995524460728 - val_loss: 1.2711661686125897\n",
      "Epoch 9374 - loss: 1.454795727773736 - val_loss: 1.2683058162771927\n",
      "Epoch 9375 - loss: 1.454735741275274 - val_loss: 1.2694165450877055\n",
      "Epoch 9380 - loss: 1.4544278804179336 - val_loss: 1.265497346051344\n",
      "Epoch 9387 - loss: 1.4543494987239627 - val_loss: 1.2658442633093188\n",
      "Epoch 9408 - loss: 1.4543197196895525 - val_loss: 1.2717973300905865\n",
      "Epoch 9413 - loss: 1.454183515658343 - val_loss: 1.2663926463830726\n",
      "Epoch 9430 - loss: 1.4541101416693973 - val_loss: 1.2687014621415975\n",
      "Epoch 9445 - loss: 1.454020165106509 - val_loss: 1.268792541666699\n",
      "Epoch 9457 - loss: 1.4539430334199008 - val_loss: 1.2692012496195786\n",
      "Epoch 9464 - loss: 1.453889785432081 - val_loss: 1.2696584952953127\n",
      "Epoch 9474 - loss: 1.4538612683863967 - val_loss: 1.2647808090706443\n",
      "Epoch 9483 - loss: 1.4537946505220345 - val_loss: 1.2728088896265768\n",
      "Epoch 9498 - loss: 1.453638491516716 - val_loss: 1.2690075089166453\n",
      "Epoch 9516 - loss: 1.4536367488421338 - val_loss: 1.2653649315859419\n",
      "Epoch 9518 - loss: 1.4535731701502939 - val_loss: 1.2711649954116406\n",
      "Epoch 9525 - loss: 1.453560379686139 - val_loss: 1.2721493533093593\n",
      "Epoch 9532 - loss: 1.4535215898139684 - val_loss: 1.2692088579119827\n",
      "Epoch 9535 - loss: 1.4534718355458487 - val_loss: 1.2721641921642515\n",
      "Epoch 9547 - loss: 1.4531288000010685 - val_loss: 1.2717793985945198\n",
      "Epoch 9560 - loss: 1.4530633454568072 - val_loss: 1.2690739863258393\n",
      "Epoch 9584 - loss: 1.4530311912567486 - val_loss: 1.2723404687630064\n",
      "Epoch 9599 - loss: 1.452986853306886 - val_loss: 1.275115580842589\n",
      "Epoch 9621 - loss: 1.4528552380729127 - val_loss: 1.2719348550852536\n",
      "Epoch 9626 - loss: 1.4528316994547925 - val_loss: 1.2702006313593912\n",
      "Epoch 9635 - loss: 1.452626291390787 - val_loss: 1.2697462459988293\n",
      "Epoch 9643 - loss: 1.4525688421102223 - val_loss: 1.2711750318000816\n",
      "Epoch 9650 - loss: 1.4525315394216352 - val_loss: 1.278398661009897\n",
      "Epoch 9657 - loss: 1.4525051055304044 - val_loss: 1.268936612953278\n",
      "Epoch 9661 - loss: 1.4524693110398887 - val_loss: 1.276963145078171\n",
      "Epoch 9663 - loss: 1.4521947292271966 - val_loss: 1.2747154983938978\n",
      "Epoch 9684 - loss: 1.4521408818855681 - val_loss: 1.2743153403221372\n",
      "Epoch 9691 - loss: 1.4520722220636855 - val_loss: 1.2713402589894685\n",
      "Epoch 9695 - loss: 1.451916880378828 - val_loss: 1.277870701014077\n",
      "Epoch 9709 - loss: 1.4514417440124276 - val_loss: 1.2723826073724942\n",
      "Epoch 9731 - loss: 1.4512366465574498 - val_loss: 1.281829526352631\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_regressor_test.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_regressor_test.ipynb#ch0000005?line=0'>1</a>\u001b[0m regressor \u001b[39m=\u001b[39m EvoMLPRegressor(n \u001b[39m=\u001b[39m \u001b[39m240\u001b[39m, hidden_layers \u001b[39m=\u001b[39m [\u001b[39m16\u001b[39m], activation \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m, random_state \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evo_regressor_test.ipynb#ch0000005?line=1'>2</a>\u001b[0m regressor\u001b[39m.\u001b[39;49mfit(scaled_X_train, y_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m10000\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (scaled_X_val, y_val), verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Deep-learning-Daniel-Petersson/evolutionary_algos.py:288\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, epochs, validation_data, verbose)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evolutionary_algos.py?line=284'>285</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_of_layers_minus_one):\n\u001b[1;32m    <a href='file:///Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evolutionary_algos.py?line=285'>286</a>\u001b[0m     weights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, (n, layers[i], layers[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]))]\n\u001b[0;32m--> <a href='file:///Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evolutionary_algos.py?line=287'>288</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m    <a href='file:///Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evolutionary_algos.py?line=288'>289</a>\u001b[0m     forward_pass \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mT\n\u001b[1;32m    <a href='file:///Users/dp/Documents/GitHub/Deep-learning-Daniel-Petersson/evolutionary_algos.py?line=290'>291</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_of_layers_minus_one \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regressor = EvoMLPRegressor(n = 240, hidden_layers = [16], activation = \"relu\", random_state = 42)\n",
    "regressor.fit(scaled_X_train, y_train, epochs = 10000, validation_data = (scaled_X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test data: 1.5985694366734164\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = regressor.predict(scaled_X_test)\n",
    "print(f\"Loss on test data: {mean_absolute_error(y_test, y_pred)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(regressor.training_loss_history)\n",
    "ax.plot(regressor.validation_loss_history)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x155a691c0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = []\n",
    "xrange = 1000\n",
    "\n",
    "for x in range(1, xrange + 1):\n",
    "    y.append(5 * 1 / math.exp(x / (xrange / (10 * math.log10(xrange)))))\n",
    "\n",
    "plt.plot(list(range(xrange)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
