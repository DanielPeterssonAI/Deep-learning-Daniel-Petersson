{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "X_train, y_train = df[~df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]], df[~df[\"horsepower\"].isna()][\"horsepower\"]\n",
    "X_pred = df[df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred = np.round(y_pred)\n",
    "df.loc[X_pred.index, \"horsepower\"] = y_pred\n",
    "df = pd.get_dummies(df.drop(\"name\", axis = 1), columns = [\"origin\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"mpg\"], axis = 1).values, df[\"mpg\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 11.409326214872566 - val_loss: 11.485170808255846\n",
      "Epoch 31 - loss: 8.837977190835439 - val_loss: 9.080621638357371\n",
      "Epoch 36 - loss: 8.49043629316124 - val_loss: 6.999176852274992\n",
      "Epoch 37 - loss: 8.262005957869663 - val_loss: 7.646054903453946\n",
      "Epoch 39 - loss: 7.681841452952463 - val_loss: 6.240437685670597\n",
      "Epoch 42 - loss: 6.751947028898243 - val_loss: 6.687845269889718\n",
      "Epoch 46 - loss: 5.715512300182485 - val_loss: 5.730556055467494\n",
      "Epoch 47 - loss: 5.032308596760075 - val_loss: 4.918378509156658\n",
      "Epoch 56 - loss: 4.236790849675502 - val_loss: 2.91711652083728\n",
      "Epoch 57 - loss: 4.163115979352726 - val_loss: 3.1895908321218367\n",
      "Epoch 65 - loss: 3.6572974121895556 - val_loss: 3.54642655894349\n",
      "Epoch 76 - loss: 3.385523046873998 - val_loss: 2.832014833962699\n",
      "Epoch 78 - loss: 3.214297259032253 - val_loss: 3.205547474073492\n",
      "Epoch 89 - loss: 3.209054762151541 - val_loss: 2.77318690686388\n",
      "Epoch 95 - loss: 2.8717510180697277 - val_loss: 2.032182909421379\n",
      "Epoch 101 - loss: 2.8012717485840546 - val_loss: 2.568330712978267\n",
      "Epoch 106 - loss: 2.7888300600561995 - val_loss: 2.1677538479677\n",
      "Epoch 112 - loss: 2.668809556749257 - val_loss: 2.307702859909867\n",
      "Epoch 121 - loss: 2.65990322587529 - val_loss: 2.159435072288236\n",
      "Epoch 123 - loss: 2.5127269231611287 - val_loss: 2.01130803562422\n",
      "Epoch 146 - loss: 2.4914379424874915 - val_loss: 1.9223547370012206\n",
      "Epoch 161 - loss: 2.4550423908923302 - val_loss: 1.9993579644144035\n",
      "Epoch 171 - loss: 2.427793743113014 - val_loss: 1.9026418428734513\n",
      "Epoch 173 - loss: 2.4192803923511224 - val_loss: 1.8655729490390942\n",
      "Epoch 183 - loss: 2.4146390003565967 - val_loss: 1.7868209513185498\n",
      "Epoch 190 - loss: 2.4007988381862284 - val_loss: 1.7559607294163542\n",
      "Epoch 209 - loss: 2.3688816947329006 - val_loss: 1.9437680343034267\n",
      "Epoch 233 - loss: 2.3669284376576076 - val_loss: 1.8555821507858945\n",
      "Epoch 237 - loss: 2.3545441001619554 - val_loss: 1.8982084796863532\n",
      "Epoch 248 - loss: 2.3320266070427538 - val_loss: 1.8172971197085843\n",
      "Epoch 269 - loss: 2.28854962391714 - val_loss: 1.7701713473716942\n",
      "Epoch 373 - loss: 2.2663343364605035 - val_loss: 1.7666651176504324\n",
      "Epoch 381 - loss: 2.244182798300753 - val_loss: 1.7452485843868772\n",
      "Epoch 412 - loss: 2.234092098481061 - val_loss: 1.7891964743673427\n",
      "Epoch 449 - loss: 2.226500997683449 - val_loss: 1.7542239644011335\n",
      "Epoch 463 - loss: 2.2211282643273953 - val_loss: 1.6080828196565407\n",
      "Epoch 473 - loss: 2.217562949256603 - val_loss: 1.9438931345816244\n",
      "Epoch 488 - loss: 2.174827852179983 - val_loss: 1.815096367562559\n",
      "Epoch 573 - loss: 2.1682352159857223 - val_loss: 1.6728375701745748\n",
      "Epoch 578 - loss: 2.1446172226855826 - val_loss: 1.8760085541862188\n",
      "Epoch 590 - loss: 2.1444367297577624 - val_loss: 1.8036240494479312\n",
      "Epoch 591 - loss: 2.0954337599187456 - val_loss: 1.7082571747850508\n",
      "Epoch 814 - loss: 2.093355580765202 - val_loss: 2.008811311674356\n",
      "Epoch 823 - loss: 2.0929612321309565 - val_loss: 1.7912505957231573\n",
      "Epoch 827 - loss: 2.07067825091293 - val_loss: 1.7853212248024786\n",
      "Epoch 861 - loss: 2.0547061460478835 - val_loss: 2.0037240958823177\n",
      "Epoch 1122 - loss: 2.0407705023529514 - val_loss: 1.8336336026546498\n",
      "Epoch 1246 - loss: 2.0329774226304087 - val_loss: 1.8411321106420822\n",
      "Epoch 1677 - loss: 2.0287070647783616 - val_loss: 1.8330753275175318\n",
      "Epoch 1871 - loss: 2.0142718270911755 - val_loss: 1.8956628828528153\n",
      "Epoch 2025 - loss: 2.0106729273352872 - val_loss: 1.9805533361110232\n",
      "Epoch 2131 - loss: 2.0030095111647936 - val_loss: 1.7168482687371618\n",
      "Epoch 2142 - loss: 1.9926987211671858 - val_loss: 1.871519124948864\n",
      "Epoch 2179 - loss: 1.9918064258541708 - val_loss: 1.7883435306664848\n",
      "Epoch 2202 - loss: 1.970004119643859 - val_loss: 1.8757802311954195\n",
      "Epoch 2317 - loss: 1.9637001035961335 - val_loss: 1.8559226251805658\n",
      "Epoch 2418 - loss: 1.944554711894259 - val_loss: 1.7917047686650516\n",
      "Epoch 2486 - loss: 1.9225902940266184 - val_loss: 1.660199641017316\n",
      "Epoch 3090 - loss: 1.9207780969196098 - val_loss: 1.6833121231776809\n",
      "Epoch 3317 - loss: 1.9158432595142572 - val_loss: 1.770928479989211\n",
      "Epoch 3373 - loss: 1.9129474349569267 - val_loss: 1.7711085080523634\n",
      "Epoch 3655 - loss: 1.9109074875443774 - val_loss: 1.729821290625567\n",
      "Epoch 3762 - loss: 1.9064983795808472 - val_loss: 1.7026754218379956\n",
      "Epoch 3792 - loss: 1.8901538043722688 - val_loss: 1.7540651535395206\n",
      "Epoch 4484 - loss: 1.8816259132407853 - val_loss: 1.691594201858456\n",
      "Epoch 4567 - loss: 1.8815919845972426 - val_loss: 1.7159110470848085\n",
      "Epoch 4734 - loss: 1.8707321389241631 - val_loss: 1.730716987937464\n",
      "Epoch 4895 - loss: 1.8659165434295397 - val_loss: 1.8019023403782857\n",
      "Epoch 5110 - loss: 1.8547589378782434 - val_loss: 1.8235132154922529\n",
      "Epoch 5349 - loss: 1.8534501006032775 - val_loss: 1.6821385503239774\n",
      "Epoch 5447 - loss: 1.8479333254893022 - val_loss: 1.700384379592419\n",
      "Epoch 5786 - loss: 1.8467314995613058 - val_loss: 1.8056529445143532\n",
      "Epoch 5808 - loss: 1.8395583798867285 - val_loss: 1.792811051523517\n",
      "Epoch 6040 - loss: 1.8389073652045729 - val_loss: 1.7420706543946658\n",
      "Epoch 6938 - loss: 1.8383763074881028 - val_loss: 1.90133602972266\n",
      "Epoch 7178 - loss: 1.8362566882459153 - val_loss: 1.7041899110020189\n",
      "Epoch 7226 - loss: 1.8260135226707195 - val_loss: 1.748791678531072\n",
      "Epoch 7323 - loss: 1.8104650036828127 - val_loss: 1.8611907707277393\n",
      "Epoch 8367 - loss: 1.8100682492399363 - val_loss: 1.8268977241216113\n",
      "Epoch 8644 - loss: 1.8074107580747873 - val_loss: 1.7850304383975684\n",
      "Epoch 9355 - loss: 1.8058167607451725 - val_loss: 1.8217789762796133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 1.91834 s\n",
      "File: /var/folders/xz/f2gwbn5n3vs4pz044n49z3cw0000gn/T/ipykernel_64896/1278720871.py\n",
      "Function: fit at line 26\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    26                                               def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0):\n",
      "    27                                           \n",
      "    28         1          2.0      2.0      0.0          if self.random_state != None:\n",
      "    29         1         13.0     13.0      0.0              np.random.seed(self.random_state)\n",
      "    30                                           \n",
      "    31         1         98.0     98.0      0.0          X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
      "    32                                           \n",
      "    33         1          1.0      1.0      0.0          if validation_data:\n",
      "    34         1          0.0      0.0      0.0              X_val, y_val = validation_data\n",
      "    35                                           \n",
      "    36         1          1.0      1.0      0.0          self.layers = [X_train.shape[1]] + self.layers\n",
      "    37                                           \n",
      "    38         1          3.0      3.0      0.0          self.y_preds = np.zeros((self.n, y_train.shape[0]))\n",
      "    39         1          1.0      1.0      0.0          self.nets_loss = np.zeros(self.n)\n",
      "    40         1          1.0      1.0      0.0          self.sorted_indecies = np.zeros(self.n)\n",
      "    41                                           \n",
      "    42         1          1.0      1.0      0.0          self.weights = []\n",
      "    43                                           \n",
      "    44         3          3.0      1.0      0.0          for i in range(len(self.layers) - 1):\n",
      "    45         2         86.0     43.0      0.0              self.weights += [np.random.uniform(-3, 3, (self.n, self.layers[i], self.layers[i + 1]))]\n",
      "    46                                           \n",
      "    47     10001       3589.0      0.4      0.2          for epoch in range(epochs):\n",
      "    48     10000       4231.0      0.4      0.2              forward_pass = X_train.T\n",
      "    49                                                       \n",
      "    50     20000       9015.0      0.5      0.5              for j in range(0, len(self.layers) - 2):\n",
      "    51     10000     759318.0     75.9     39.6                  forward_pass = self.activation_function(self.weights[j].transpose(0, 2, 1) @ forward_pass)\n",
      "    52                                           \n",
      "    53     10000     139665.0     14.0      7.3              forward_pass = self.weights[-1].transpose(0, 2, 1) @ forward_pass\n",
      "    54     10000       6986.0      0.7      0.4              self.y_preds = forward_pass.reshape(self.n, -1)\n",
      "    55                                           \n",
      "    56     10000     159507.0     16.0      8.3              self.nets_loss = np.mean(np.abs(self.y_preds - y_train), axis = 1)\n",
      "    57                                           \n",
      "    58     10000      25998.0      2.6      1.4              self.sorted_indecies = np.argsort(self.nets_loss)\n",
      "    59                                           \n",
      "    60     10000       7038.0      0.7      0.4              self.mutation_sigma = 0.1 + 5 * 1 / math.exp(epoch / ((epochs + 1) / (100 * math.log10(epochs + 1))))\n",
      "    61                                           \n",
      "    62     30000      13186.0      0.4      0.7              for j in range(0, len(self.layers) - 1):\n",
      "    63     20000     393221.0     19.7     20.5                  self.weights[j][self.sorted_indecies[self.n // 2::2]] = np.mean((self.weights[j][self.sorted_indecies[:self.n // 2:2]], self.weights[j][self.sorted_indecies[1:1 + self.n // 2:2]]), axis = 0) + np.random.normal(0, self.mutation_sigma, (self.n // 4, self.layers[j], self.layers[j + 1]))\n",
      "    64     20000     384447.0     19.2     20.0                  self.weights[j][self.sorted_indecies[1 + self.n // 2::2]] = np.mean((self.weights[j][self.sorted_indecies[:self.n // 2:2]], self.weights[j][self.sorted_indecies[1:1 + self.n // 2:2]]), axis = 0) + np.random.normal(0, self.mutation_sigma, (self.n // 4, self.layers[j], self.layers[j + 1]))\n",
      "    65                                           \n",
      "    66     10000       4907.0      0.5      0.3              if self.best_net != self.sorted_indecies[0]:\n",
      "    67        81         38.0      0.5      0.0                  self.best_net = self.sorted_indecies[0]\n",
      "    68        81         98.0      1.2      0.0                  self.training_loss_history += [self.nets_loss[self.best_net]]\n",
      "    69                                                           \n",
      "    70        81         32.0      0.4      0.0                  if validation_data:\n",
      "    71        81       5640.0     69.6      0.3                      self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
      "    72        81         34.0      0.4      0.0                      if verbose == 1:\n",
      "    73        81       1182.0     14.6      0.1                          print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]}\")\n",
      "    74                                                           else:\n",
      "    75                                                               if verbose == 1:\n",
      "    76                                                                   pass\n",
      "    77                                                                   print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]}\")"
     ]
    }
   ],
   "source": [
    "%reload_ext line_profiler\n",
    "\n",
    "class VectorizedEvoRegressor:\n",
    "    def __init__(self, n = 20, hidden_layers = False, activation = \"sigmoid\", random_state = None):\n",
    "\n",
    "        self.n = n // 2 * 2\n",
    "        self.best_net = -1\n",
    "        self.best_result = None\n",
    "        self.validation_loss_history = []\n",
    "        self.training_loss_history = []\n",
    "        self.mutation_sigma = 0\n",
    "        self.random_state = random_state\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif activation == \"relu\":\n",
    "            self.activation_function = lambda x: np.maximum(0, x)\n",
    "        elif activation == \"leaky_relu\":\n",
    "            self.activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        \n",
    "        if hidden_layers:\n",
    "            self.layers = hidden_layers + [1]\n",
    "        else:\n",
    "            self.layers = [1]\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0):\n",
    "\n",
    "        if self.random_state != None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "\n",
    "        if validation_data:\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        self.layers = [X_train.shape[1]] + self.layers\n",
    "\n",
    "        self.y_preds = np.zeros((self.n, y_train.shape[0]))\n",
    "        self.nets_loss = np.zeros(self.n)\n",
    "        self.sorted_indecies = np.zeros(self.n)\n",
    "\n",
    "        self.weights = []\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.weights += [np.random.uniform(-3, 3, (self.n, self.layers[i], self.layers[i + 1]))]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            forward_pass = X_train.T\n",
    "            \n",
    "            for j in range(0, len(self.layers) - 2):\n",
    "                forward_pass = self.activation_function(self.weights[j].transpose(0, 2, 1) @ forward_pass)\n",
    "\n",
    "            forward_pass = self.weights[-1].transpose(0, 2, 1) @ forward_pass\n",
    "            self.y_preds = forward_pass.reshape(self.n, -1)\n",
    "\n",
    "            self.nets_loss = np.mean(np.abs(self.y_preds - y_train), axis = 1)\n",
    "\n",
    "            self.sorted_indecies = np.argsort(self.nets_loss)\n",
    "\n",
    "            self.mutation_sigma = 0.1 + 5 * 1 / math.exp(epoch / ((epochs + 1) / (100 * math.log10(epochs + 1))))\n",
    "\n",
    "            for j in range(0, len(self.layers) - 1):\n",
    "                self.weights[j][self.sorted_indecies[self.n // 2::2]] = np.mean((self.weights[j][self.sorted_indecies[:self.n // 2:2]], self.weights[j][self.sorted_indecies[1:1 + self.n // 2:2]]), axis = 0) + np.random.normal(0, self.mutation_sigma, (self.n // 4, self.layers[j], self.layers[j + 1]))\n",
    "                self.weights[j][self.sorted_indecies[1 + self.n // 2::2]] = np.mean((self.weights[j][self.sorted_indecies[:self.n // 2:2]], self.weights[j][self.sorted_indecies[1:1 + self.n // 2:2]]), axis = 0) + np.random.normal(0, self.mutation_sigma, (self.n // 4, self.layers[j], self.layers[j + 1]))\n",
    "\n",
    "            if self.best_net != self.sorted_indecies[0]:\n",
    "                self.best_net = self.sorted_indecies[0]\n",
    "                self.training_loss_history += [self.nets_loss[self.best_net]]\n",
    "                \n",
    "                if validation_data:\n",
    "                    self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
    "                    if verbose == 1:\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]}\")\n",
    "                else:\n",
    "                    if verbose == 1:\n",
    "                        pass\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]}\")\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        forward_pass = X.T\n",
    "        for j in range(0, len(self.layers) - 2):\n",
    "            forward_pass = self.activation_function(self.weights[j][self.best_net].T @ forward_pass)\n",
    "\n",
    "        forward_pass = self.weights[-1][self.best_net].T @ forward_pass\n",
    "        return forward_pass.reshape(-1)\n",
    "\n",
    "regressor = VectorizedEvoRegressor(n = 20, hidden_layers = [8], activation = \"relu\", random_state = 42)\n",
    "\n",
    "\n",
    "%lprun -f regressor.fit regressor.fit(scaled_X_train, y_train, epochs = 10000, validation_data = (scaled_X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(17 / 8) * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 7.737057559160331 - val_loss: 8.01487563511419\n",
      "Epoch 1 - loss: 7.510331828695556 - val_loss: 8.968397931066926\n",
      "Epoch 2 - loss: 6.5947106040460755 - val_loss: 7.0458890972361505\n",
      "Epoch 3 - loss: 6.5947106040460755 - val_loss: 7.0458890972361505\n",
      "Epoch 4 - loss: 5.829510974233065 - val_loss: 4.908348079817188\n",
      "Epoch 5 - loss: 5.281573644652448 - val_loss: 4.607294742401278\n",
      "Epoch 6 - loss: 5.281573644652448 - val_loss: 4.607294742401278\n",
      "Epoch 7 - loss: 5.281573644652448 - val_loss: 4.607294742401278\n",
      "Epoch 8 - loss: 5.281573644652448 - val_loss: 4.607294742401278\n",
      "Epoch 9 - loss: 5.281573644652448 - val_loss: 4.607294742401278\n",
      "Epoch 10 - loss: 5.112338479928962 - val_loss: 4.755319630232976\n",
      "Epoch 11 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 12 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 13 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 14 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 15 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 16 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 17 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 18 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 19 - loss: 4.900885896319837 - val_loss: 5.699607911615603\n",
      "Epoch 20 - loss: 4.733582000861924 - val_loss: 4.326982884667847\n",
      "Epoch 21 - loss: 4.733582000861924 - val_loss: 4.326982884667847\n",
      "Epoch 22 - loss: 4.733582000861924 - val_loss: 4.326982884667847\n",
      "Epoch 23 - loss: 4.733582000861924 - val_loss: 4.326982884667847\n",
      "Epoch 24 - loss: 4.733582000861924 - val_loss: 4.326982884667847\n",
      "Epoch 25 - loss: 4.634677176188427 - val_loss: 4.266749060398398\n",
      "Epoch 26 - loss: 4.634677176188427 - val_loss: 4.266749060398398\n",
      "Epoch 27 - loss: 4.634677176188427 - val_loss: 4.266749060398398\n",
      "Epoch 28 - loss: 4.634677176188427 - val_loss: 4.266749060398398\n",
      "Epoch 29 - loss: 4.634677176188427 - val_loss: 4.266749060398398\n",
      "Epoch 30 - loss: 4.634677176188427 - val_loss: 4.266749060398398\n",
      "Epoch 31 - loss: 4.596983524063516 - val_loss: 4.909666057905956\n",
      "Epoch 32 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 33 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 34 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 35 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 36 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 37 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 38 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 39 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 40 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 41 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 42 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 43 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 44 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 45 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 46 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 47 - loss: 3.9444251938768815 - val_loss: 3.7948153497907677\n",
      "Epoch 48 - loss: 3.913337989896924 - val_loss: 4.15412824898813\n",
      "Epoch 49 - loss: 3.913337989896924 - val_loss: 4.15412824898813\n",
      "Epoch 50 - loss: 3.913337989896924 - val_loss: 4.15412824898813\n",
      "Epoch 51 - loss: 3.913337989896924 - val_loss: 4.15412824898813\n",
      "Epoch 52 - loss: 3.913337989896924 - val_loss: 4.15412824898813\n",
      "Epoch 53 - loss: 3.5760343636423015 - val_loss: 3.5443791654741332\n",
      "Epoch 54 - loss: 3.5760343636423015 - val_loss: 3.5443791654741332\n",
      "Epoch 55 - loss: 3.5760343636423015 - val_loss: 3.5443791654741332\n",
      "Epoch 56 - loss: 3.5760343636423015 - val_loss: 3.5443791654741332\n",
      "Epoch 57 - loss: 3.5760343636423015 - val_loss: 3.5443791654741332\n",
      "Epoch 58 - loss: 3.5760343636423015 - val_loss: 3.5443791654741332\n",
      "Epoch 59 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 60 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 61 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 62 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 63 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 64 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 65 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 66 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 67 - loss: 3.505001437926961 - val_loss: 3.342708554591469\n",
      "Epoch 68 - loss: 3.5000433360136887 - val_loss: 3.3229922460243655\n",
      "Epoch 69 - loss: 3.5000433360136887 - val_loss: 3.3229922460243655\n",
      "Epoch 70 - loss: 3.5000433360136887 - val_loss: 3.3229922460243655\n",
      "Epoch 71 - loss: 3.4039652344390032 - val_loss: 2.491508669678962\n",
      "Epoch 72 - loss: 3.4039652344390032 - val_loss: 2.491508669678962\n",
      "Epoch 73 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 74 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 75 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 76 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 77 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 78 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 79 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 80 - loss: 3.339316649783786 - val_loss: 2.528769459576549\n",
      "Epoch 81 - loss: 3.1005799648925514 - val_loss: 2.8486087312841484\n",
      "Epoch 82 - loss: 3.0222522288176834 - val_loss: 2.542217669668907\n",
      "Epoch 83 - loss: 3.0222522288176834 - val_loss: 2.542217669668907\n",
      "Epoch 84 - loss: 3.0222522288176834 - val_loss: 2.542217669668907\n",
      "Epoch 85 - loss: 3.0222522288176834 - val_loss: 2.542217669668907\n",
      "Epoch 86 - loss: 3.0222522288176834 - val_loss: 2.542217669668907\n",
      "Epoch 87 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 88 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 89 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 90 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 91 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 92 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 93 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 94 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 95 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 96 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 97 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 98 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 99 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 100 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 101 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 102 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 103 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 104 - loss: 2.7900852483096266 - val_loss: 2.5776638482262344\n",
      "Epoch 105 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 106 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 107 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 108 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 109 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 110 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 111 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 112 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 113 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 114 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 115 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 116 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 117 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 118 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 119 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 120 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 121 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 122 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 123 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 124 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 125 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 126 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 127 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 128 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 129 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 130 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 131 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 132 - loss: 2.580664007832874 - val_loss: 2.2381378983115447\n",
      "Epoch 133 - loss: 2.559722965143909 - val_loss: 2.278871614253666\n",
      "Epoch 134 - loss: 2.559722965143909 - val_loss: 2.278871614253666\n",
      "Epoch 135 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 136 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 137 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 138 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 139 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 140 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 141 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 142 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 143 - loss: 2.3899918244105205 - val_loss: 2.1923572268733507\n",
      "Epoch 144 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 145 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 146 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 147 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 148 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 149 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 150 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 151 - loss: 2.389766900525124 - val_loss: 2.2600978971897896\n",
      "Epoch 152 - loss: 2.3175483599393893 - val_loss: 1.9666911107254528\n",
      "Epoch 153 - loss: 2.3175483599393893 - val_loss: 1.9666911107254528\n",
      "Epoch 154 - loss: 2.3175483599393893 - val_loss: 1.9666911107254528\n",
      "Epoch 155 - loss: 2.2213342418936124 - val_loss: 1.892180138493059\n",
      "Epoch 156 - loss: 2.210068066118549 - val_loss: 1.9522225317515347\n",
      "Epoch 157 - loss: 2.210068066118549 - val_loss: 1.9522225317515347\n",
      "Epoch 158 - loss: 2.210068066118549 - val_loss: 1.9522225317515347\n",
      "Epoch 159 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 160 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 161 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 162 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 163 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 164 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 165 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 166 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 167 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 168 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 169 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 170 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 171 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 172 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 173 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 174 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 175 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 176 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 177 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 178 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 179 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 180 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 181 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 182 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 183 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 184 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 185 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 186 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 187 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 188 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 189 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 190 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 191 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 192 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 193 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 194 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 195 - loss: 2.1817222405188232 - val_loss: 1.7836109597102072\n",
      "Epoch 196 - loss: 2.1693622563992427 - val_loss: 1.8299758409572484\n",
      "Epoch 197 - loss: 2.1693622563992427 - val_loss: 1.8299758409572484\n",
      "Epoch 198 - loss: 2.1693622563992427 - val_loss: 1.8299758409572484\n",
      "Epoch 199 - loss: 2.1693622563992427 - val_loss: 1.8299758409572484\n",
      "Epoch 200 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 201 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 202 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 203 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 204 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 205 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 206 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 207 - loss: 2.161356898359588 - val_loss: 1.595117302756535\n",
      "Epoch 208 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 209 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 210 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 211 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 212 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 213 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 214 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 215 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 216 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 217 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 218 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 219 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 220 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 221 - loss: 2.0681527193182765 - val_loss: 1.6537737262392518\n",
      "Epoch 222 - loss: 2.0442635165005583 - val_loss: 1.6074319218259039\n",
      "Epoch 223 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 224 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 225 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 226 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 227 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 228 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 229 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 230 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 231 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 232 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 233 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 234 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 235 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 236 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 237 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 238 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 239 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 240 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 241 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 242 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 243 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 244 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 245 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 246 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 247 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 248 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 249 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 250 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 251 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 252 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 253 - loss: 2.0241800940185986 - val_loss: 1.6661519453282914\n",
      "Epoch 254 - loss: 2.023776672506467 - val_loss: 1.63546868534046\n",
      "Epoch 255 - loss: 2.008583950839811 - val_loss: 1.7799745180328777\n",
      "Epoch 256 - loss: 2.008583950839811 - val_loss: 1.7799745180328777\n",
      "Epoch 257 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 258 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 259 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 260 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 261 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 262 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 263 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 264 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 265 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 266 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 267 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 268 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 269 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 270 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 271 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 272 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 273 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 274 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 275 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 276 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 277 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 278 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 279 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 280 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 281 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 282 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 283 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 284 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 285 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 286 - loss: 1.96214626183952 - val_loss: 1.7028261526232193\n",
      "Epoch 287 - loss: 1.9562957160859948 - val_loss: 1.7390892167771905\n",
      "Epoch 288 - loss: 1.9562957160859948 - val_loss: 1.7390892167771905\n",
      "Epoch 289 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 290 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 291 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 292 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 293 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 294 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 295 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 296 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 297 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 298 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 299 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 300 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 301 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 302 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 303 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 304 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 305 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 306 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 307 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 308 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 309 - loss: 1.9319396965167446 - val_loss: 1.7276494760785315\n",
      "Epoch 310 - loss: 1.9309500390857222 - val_loss: 1.6945487480502677\n",
      "Epoch 311 - loss: 1.9309500390857222 - val_loss: 1.6945487480502677\n",
      "Epoch 312 - loss: 1.9309500390857222 - val_loss: 1.6945487480502677\n",
      "Epoch 313 - loss: 1.9309500390857222 - val_loss: 1.6945487480502677\n",
      "Epoch 314 - loss: 1.9309500390857222 - val_loss: 1.6945487480502677\n",
      "Epoch 315 - loss: 1.9309500390857222 - val_loss: 1.6945487480502677\n",
      "Epoch 316 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 317 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 318 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 319 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 320 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 321 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 322 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 323 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 324 - loss: 1.9165329332248093 - val_loss: 1.6412047328107782\n",
      "Epoch 325 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 326 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 327 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 328 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 329 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 330 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 331 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 332 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 333 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 334 - loss: 1.9160439059471277 - val_loss: 1.6794946658731753\n",
      "Epoch 335 - loss: 1.9154285492142349 - val_loss: 1.7158586732435797\n",
      "Epoch 336 - loss: 1.9154285492142349 - val_loss: 1.7158586732435797\n",
      "Epoch 337 - loss: 1.9154285492142349 - val_loss: 1.7158586732435797\n",
      "Epoch 338 - loss: 1.9151044388582628 - val_loss: 1.6958512782525275\n",
      "Epoch 339 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 340 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 341 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 342 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 343 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 344 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 345 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 346 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 347 - loss: 1.8975118971703278 - val_loss: 1.6226258886088811\n",
      "Epoch 348 - loss: 1.888355758967431 - val_loss: 1.6014800276604366\n",
      "Epoch 349 - loss: 1.8794305645636966 - val_loss: 1.6818342037238376\n",
      "Epoch 350 - loss: 1.8794305645636966 - val_loss: 1.6818342037238376\n",
      "Epoch 351 - loss: 1.8794305645636966 - val_loss: 1.6818342037238376\n",
      "Epoch 352 - loss: 1.8794305645636966 - val_loss: 1.6818342037238376\n",
      "Epoch 353 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 354 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 355 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 356 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 357 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 358 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 359 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 360 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 361 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 362 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 363 - loss: 1.8711496975960402 - val_loss: 1.64841652285107\n",
      "Epoch 364 - loss: 1.870995206111572 - val_loss: 1.7016134081101768\n",
      "Epoch 365 - loss: 1.870995206111572 - val_loss: 1.7016134081101768\n",
      "Epoch 366 - loss: 1.870995206111572 - val_loss: 1.7016134081101768\n",
      "Epoch 367 - loss: 1.870995206111572 - val_loss: 1.7016134081101768\n",
      "Epoch 368 - loss: 1.870995206111572 - val_loss: 1.7016134081101768\n",
      "Epoch 369 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 370 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 371 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 372 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 373 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 374 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 375 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 376 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 377 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 378 - loss: 1.854219956480461 - val_loss: 1.5969568338314086\n",
      "Epoch 379 - loss: 1.8532092059376457 - val_loss: 1.6204742064508082\n",
      "Epoch 380 - loss: 1.8532092059376457 - val_loss: 1.6204742064508082\n",
      "Epoch 381 - loss: 1.8532092059376457 - val_loss: 1.6204742064508082\n",
      "Epoch 382 - loss: 1.8532092059376457 - val_loss: 1.6204742064508082\n",
      "Epoch 383 - loss: 1.8495022176064686 - val_loss: 1.537384180940168\n",
      "Epoch 384 - loss: 1.8495022176064686 - val_loss: 1.537384180940168\n",
      "Epoch 385 - loss: 1.8495022176064686 - val_loss: 1.537384180940168\n",
      "Epoch 386 - loss: 1.8495022176064686 - val_loss: 1.537384180940168\n",
      "Epoch 387 - loss: 1.8495022176064686 - val_loss: 1.537384180940168\n",
      "Epoch 388 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 389 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 390 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 391 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 392 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 393 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 394 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 395 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 396 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 397 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 398 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 399 - loss: 1.8301210329013573 - val_loss: 1.5586326251503047\n",
      "Epoch 400 - loss: 1.8291662439109284 - val_loss: 1.561813038150841\n",
      "Epoch 401 - loss: 1.8291662439109284 - val_loss: 1.561813038150841\n",
      "Epoch 402 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 403 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 404 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 405 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 406 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 407 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 408 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 409 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 410 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 411 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 412 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 413 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 414 - loss: 1.8225492666906704 - val_loss: 1.6198325371073756\n",
      "Epoch 415 - loss: 1.8223668040710084 - val_loss: 1.5079992643264213\n",
      "Epoch 416 - loss: 1.8223668040710084 - val_loss: 1.5079992643264213\n",
      "Epoch 417 - loss: 1.8223668040710084 - val_loss: 1.5079992643264213\n",
      "Epoch 418 - loss: 1.8223668040710084 - val_loss: 1.5079992643264213\n",
      "Epoch 419 - loss: 1.8180591447725498 - val_loss: 1.5916522063030418\n",
      "Epoch 420 - loss: 1.8180591447725498 - val_loss: 1.5916522063030418\n",
      "Epoch 421 - loss: 1.8180591447725498 - val_loss: 1.5916522063030418\n",
      "Epoch 422 - loss: 1.8180591447725498 - val_loss: 1.5916522063030418\n",
      "Epoch 423 - loss: 1.8180591447725498 - val_loss: 1.5916522063030418\n",
      "Epoch 424 - loss: 1.8180591447725498 - val_loss: 1.5916522063030418\n",
      "Epoch 425 - loss: 1.8151129171360803 - val_loss: 1.5854997139467533\n",
      "Epoch 426 - loss: 1.8151129171360803 - val_loss: 1.5854997139467533\n",
      "Epoch 427 - loss: 1.8069069448466806 - val_loss: 1.5124144206687609\n",
      "Epoch 428 - loss: 1.8069069448466806 - val_loss: 1.5124144206687609\n",
      "Epoch 429 - loss: 1.8069069448466806 - val_loss: 1.5124144206687609\n",
      "Epoch 430 - loss: 1.8069069448466806 - val_loss: 1.5124144206687609\n",
      "Epoch 431 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 432 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 433 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 434 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 435 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 436 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 437 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 438 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 439 - loss: 1.806438573789528 - val_loss: 1.6009515284457183\n",
      "Epoch 440 - loss: 1.804257465046809 - val_loss: 1.5614015536611947\n",
      "Epoch 441 - loss: 1.804257465046809 - val_loss: 1.5614015536611947\n",
      "Epoch 442 - loss: 1.801706834485771 - val_loss: 1.6365161345341235\n",
      "Epoch 443 - loss: 1.801706834485771 - val_loss: 1.6365161345341235\n",
      "Epoch 444 - loss: 1.801706834485771 - val_loss: 1.6365161345341235\n",
      "Epoch 445 - loss: 1.801706834485771 - val_loss: 1.6365161345341235\n",
      "Epoch 446 - loss: 1.8009563614907615 - val_loss: 1.5822342711172328\n",
      "Epoch 447 - loss: 1.8009563614907615 - val_loss: 1.5822342711172328\n",
      "Epoch 448 - loss: 1.7985136144097837 - val_loss: 1.6036817457436192\n",
      "Epoch 449 - loss: 1.7959964813126112 - val_loss: 1.526056797692123\n",
      "Epoch 450 - loss: 1.7897790210188556 - val_loss: 1.541225200561767\n",
      "Epoch 451 - loss: 1.7897790210188556 - val_loss: 1.541225200561767\n",
      "Epoch 452 - loss: 1.7897790210188556 - val_loss: 1.541225200561767\n",
      "Epoch 453 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 454 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 455 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 456 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 457 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 458 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 459 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 460 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 461 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 462 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 463 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 464 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 465 - loss: 1.7886037343697552 - val_loss: 1.5767297696738587\n",
      "Epoch 466 - loss: 1.7881156066846802 - val_loss: 1.5935755067461455\n",
      "Epoch 467 - loss: 1.7881156066846802 - val_loss: 1.5935755067461455\n",
      "Epoch 468 - loss: 1.7881156066846802 - val_loss: 1.5935755067461455\n",
      "Epoch 469 - loss: 1.7881156066846802 - val_loss: 1.5935755067461455\n",
      "Epoch 470 - loss: 1.7799616539797742 - val_loss: 1.5998823158004296\n",
      "Epoch 471 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 472 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 473 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 474 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 475 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 476 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 477 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 478 - loss: 1.7788361095724452 - val_loss: 1.5193445797981255\n",
      "Epoch 479 - loss: 1.7783441329002132 - val_loss: 1.5657429105747838\n",
      "Epoch 480 - loss: 1.7783441329002132 - val_loss: 1.5657429105747838\n",
      "Epoch 481 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885\n",
      "Epoch 482 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885\n",
      "Epoch 483 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885\n",
      "Epoch 484 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885\n",
      "Epoch 485 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885\n",
      "Epoch 486 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885\n",
      "Epoch 487 - loss: 1.7769695411887707 - val_loss: 1.5367208702342885\n",
      "Epoch 488 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654\n",
      "Epoch 489 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654\n",
      "Epoch 490 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654\n",
      "Epoch 491 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654\n",
      "Epoch 492 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654\n",
      "Epoch 493 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654\n",
      "Epoch 494 - loss: 1.7768256413790464 - val_loss: 1.5169342520884654\n",
      "Epoch 495 - loss: 1.776259104217378 - val_loss: 1.6172353922848757\n",
      "Epoch 496 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 497 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 498 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 499 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 500 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 501 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 502 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 503 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 504 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 505 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 506 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 507 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 508 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 509 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 510 - loss: 1.7677635434774952 - val_loss: 1.5477715917280654\n",
      "Epoch 511 - loss: 1.764155044742701 - val_loss: 1.5406418243586515\n",
      "Epoch 512 - loss: 1.764155044742701 - val_loss: 1.5406418243586515\n",
      "Epoch 513 - loss: 1.764155044742701 - val_loss: 1.5406418243586515\n",
      "Epoch 514 - loss: 1.764155044742701 - val_loss: 1.5406418243586515\n",
      "Epoch 515 - loss: 1.7631299917064658 - val_loss: 1.5631614281014312\n",
      "Epoch 516 - loss: 1.7631299917064658 - val_loss: 1.5631614281014312\n",
      "Epoch 517 - loss: 1.7631299917064658 - val_loss: 1.5631614281014312\n",
      "Epoch 518 - loss: 1.7631299917064658 - val_loss: 1.5631614281014312\n",
      "Epoch 519 - loss: 1.7631299917064658 - val_loss: 1.5631614281014312\n",
      "Epoch 520 - loss: 1.7623378758170634 - val_loss: 1.570258071146122\n",
      "Epoch 521 - loss: 1.7599696061276071 - val_loss: 1.5707671051647425\n",
      "Epoch 522 - loss: 1.7599696061276071 - val_loss: 1.5707671051647425\n",
      "Epoch 523 - loss: 1.7582424283285596 - val_loss: 1.5680381689850313\n",
      "Epoch 524 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 525 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 526 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 527 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 528 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 529 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 530 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 531 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 532 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 533 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 534 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 535 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 536 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 537 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 538 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 539 - loss: 1.75402615743999 - val_loss: 1.5680926674056992\n",
      "Epoch 540 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 541 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 542 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 543 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 544 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 545 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 546 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 547 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 548 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 549 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 550 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 551 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 552 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 553 - loss: 1.7489373971185744 - val_loss: 1.5329714605588098\n",
      "Epoch 554 - loss: 1.7466804076050904 - val_loss: 1.5439246282243797\n",
      "Epoch 555 - loss: 1.7466804076050904 - val_loss: 1.5439246282243797\n",
      "Epoch 556 - loss: 1.7466804076050904 - val_loss: 1.5439246282243797\n",
      "Epoch 557 - loss: 1.7466804076050904 - val_loss: 1.5439246282243797\n",
      "Epoch 558 - loss: 1.7466804076050904 - val_loss: 1.5439246282243797\n",
      "Epoch 559 - loss: 1.7466118735383698 - val_loss: 1.5732276844934583\n",
      "Epoch 560 - loss: 1.7460381342113067 - val_loss: 1.514554438737896\n",
      "Epoch 561 - loss: 1.742950017805513 - val_loss: 1.5361445369192621\n",
      "Epoch 562 - loss: 1.742950017805513 - val_loss: 1.5361445369192621\n",
      "Epoch 563 - loss: 1.742950017805513 - val_loss: 1.5361445369192621\n",
      "Epoch 564 - loss: 1.7412651519751683 - val_loss: 1.5111243194623012\n",
      "Epoch 565 - loss: 1.7412651519751683 - val_loss: 1.5111243194623012\n",
      "Epoch 566 - loss: 1.7403107512094358 - val_loss: 1.559605891963243\n",
      "Epoch 567 - loss: 1.7403107512094358 - val_loss: 1.559605891963243\n",
      "Epoch 568 - loss: 1.7403107512094358 - val_loss: 1.559605891963243\n",
      "Epoch 569 - loss: 1.739605461935401 - val_loss: 1.530268586265701\n",
      "Epoch 570 - loss: 1.739605461935401 - val_loss: 1.530268586265701\n",
      "Epoch 571 - loss: 1.739605461935401 - val_loss: 1.530268586265701\n",
      "Epoch 572 - loss: 1.739605461935401 - val_loss: 1.530268586265701\n",
      "Epoch 573 - loss: 1.7393697104844608 - val_loss: 1.5512218096661392\n",
      "Epoch 574 - loss: 1.739205797302013 - val_loss: 1.5453294240095399\n",
      "Epoch 575 - loss: 1.7360637365025036 - val_loss: 1.5461656595121493\n",
      "Epoch 576 - loss: 1.7360637365025036 - val_loss: 1.5461656595121493\n",
      "Epoch 577 - loss: 1.7360637365025036 - val_loss: 1.5461656595121493\n",
      "Epoch 578 - loss: 1.735630613300042 - val_loss: 1.4842882173835465\n",
      "Epoch 579 - loss: 1.735630613300042 - val_loss: 1.4842882173835465\n",
      "Epoch 580 - loss: 1.7333939767503346 - val_loss: 1.531364632105483\n",
      "Epoch 581 - loss: 1.7333939767503346 - val_loss: 1.531364632105483\n",
      "Epoch 582 - loss: 1.7323768692986115 - val_loss: 1.534465452545016\n",
      "Epoch 583 - loss: 1.7321788366233208 - val_loss: 1.499531703454028\n",
      "Epoch 584 - loss: 1.7321788366233208 - val_loss: 1.499531703454028\n",
      "Epoch 585 - loss: 1.7307067744682159 - val_loss: 1.498881528236468\n",
      "Epoch 586 - loss: 1.7307067744682159 - val_loss: 1.498881528236468\n",
      "Epoch 587 - loss: 1.7294842420149017 - val_loss: 1.503549936772614\n",
      "Epoch 588 - loss: 1.7294842420149017 - val_loss: 1.503549936772614\n",
      "Epoch 589 - loss: 1.7294842420149017 - val_loss: 1.503549936772614\n",
      "Epoch 590 - loss: 1.7294842420149017 - val_loss: 1.503549936772614\n",
      "Epoch 591 - loss: 1.7292711298550967 - val_loss: 1.5176654613723755\n",
      "Epoch 592 - loss: 1.7292711298550967 - val_loss: 1.5176654613723755\n",
      "Epoch 593 - loss: 1.7292711298550967 - val_loss: 1.5176654613723755\n",
      "Epoch 594 - loss: 1.726997768850053 - val_loss: 1.5492679058088765\n",
      "Epoch 595 - loss: 1.7261082044570486 - val_loss: 1.5241542283617706\n",
      "Epoch 596 - loss: 1.7261082044570486 - val_loss: 1.5241542283617706\n",
      "Epoch 597 - loss: 1.7261082044570486 - val_loss: 1.5241542283617706\n",
      "Epoch 598 - loss: 1.7261082044570486 - val_loss: 1.5241542283617706\n",
      "Epoch 599 - loss: 1.7256136755329385 - val_loss: 1.4974519908053685\n",
      "Epoch 600 - loss: 1.7252279364529362 - val_loss: 1.5049623990735275\n",
      "Epoch 601 - loss: 1.7243256058350935 - val_loss: 1.5053657713100879\n",
      "Epoch 602 - loss: 1.7243256058350935 - val_loss: 1.5053657713100879\n",
      "Epoch 603 - loss: 1.7243256058350935 - val_loss: 1.5053657713100879\n",
      "Epoch 604 - loss: 1.7243256058350935 - val_loss: 1.5053657713100879\n",
      "Epoch 605 - loss: 1.7212225662129799 - val_loss: 1.5290890937073818\n",
      "Epoch 606 - loss: 1.7212225662129799 - val_loss: 1.5290890937073818\n",
      "Epoch 607 - loss: 1.7212225662129799 - val_loss: 1.5290890937073818\n",
      "Epoch 608 - loss: 1.7212225662129799 - val_loss: 1.5290890937073818\n",
      "Epoch 609 - loss: 1.7212225662129799 - val_loss: 1.5290890937073818\n",
      "Epoch 610 - loss: 1.7209217416447282 - val_loss: 1.490496839719547\n",
      "Epoch 611 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 612 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 613 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 614 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 615 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 616 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 617 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 618 - loss: 1.7199605413872066 - val_loss: 1.522133873930876\n",
      "Epoch 619 - loss: 1.718658215655511 - val_loss: 1.4796551888575085\n",
      "Epoch 620 - loss: 1.7158997173797115 - val_loss: 1.513453916780404\n",
      "Epoch 621 - loss: 1.7158997173797115 - val_loss: 1.513453916780404\n",
      "Epoch 622 - loss: 1.7158997173797115 - val_loss: 1.513453916780404\n",
      "Epoch 623 - loss: 1.7158997173797115 - val_loss: 1.513453916780404\n",
      "Epoch 624 - loss: 1.7158997173797115 - val_loss: 1.513453916780404\n",
      "Epoch 625 - loss: 1.715151838834765 - val_loss: 1.5296853566272057\n",
      "Epoch 626 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 627 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 628 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 629 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 630 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 631 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 632 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 633 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 634 - loss: 1.7143720658833508 - val_loss: 1.505212338636334\n",
      "Epoch 635 - loss: 1.7109478138702108 - val_loss: 1.5238941688419954\n",
      "Epoch 636 - loss: 1.7109478138702108 - val_loss: 1.5238941688419954\n",
      "Epoch 637 - loss: 1.7109478138702108 - val_loss: 1.5238941688419954\n",
      "Epoch 638 - loss: 1.7096352101859185 - val_loss: 1.4890912539036238\n",
      "Epoch 639 - loss: 1.7096352101859185 - val_loss: 1.4890912539036238\n",
      "Epoch 640 - loss: 1.7096352101859185 - val_loss: 1.4890912539036238\n",
      "Epoch 641 - loss: 1.7096352101859185 - val_loss: 1.4890912539036238\n",
      "Epoch 642 - loss: 1.708440954604318 - val_loss: 1.510154624032653\n",
      "Epoch 643 - loss: 1.708440954604318 - val_loss: 1.510154624032653\n",
      "Epoch 644 - loss: 1.7081257296126242 - val_loss: 1.4958803411039603\n",
      "Epoch 645 - loss: 1.7081257296126242 - val_loss: 1.4958803411039603\n",
      "Epoch 646 - loss: 1.7081257296126242 - val_loss: 1.4958803411039603\n",
      "Epoch 647 - loss: 1.7063782658958269 - val_loss: 1.487920463658274\n",
      "Epoch 648 - loss: 1.705653300556553 - val_loss: 1.4954504084561548\n",
      "Epoch 649 - loss: 1.705653300556553 - val_loss: 1.4954504084561548\n",
      "Epoch 650 - loss: 1.705653300556553 - val_loss: 1.4954504084561548\n",
      "Epoch 651 - loss: 1.705333518700015 - val_loss: 1.5066961285634057\n",
      "Epoch 652 - loss: 1.705333518700015 - val_loss: 1.5066961285634057\n",
      "Epoch 653 - loss: 1.7039811355868277 - val_loss: 1.5104444961734165\n",
      "Epoch 654 - loss: 1.7035523053925126 - val_loss: 1.512511728638961\n",
      "Epoch 655 - loss: 1.7035523053925126 - val_loss: 1.512511728638961\n",
      "Epoch 656 - loss: 1.7035523053925126 - val_loss: 1.512511728638961\n",
      "Epoch 657 - loss: 1.7035523053925126 - val_loss: 1.512511728638961\n",
      "Epoch 658 - loss: 1.7035523053925126 - val_loss: 1.512511728638961\n",
      "Epoch 659 - loss: 1.7034174007308667 - val_loss: 1.539003342162316\n",
      "Epoch 660 - loss: 1.7034174007308667 - val_loss: 1.539003342162316\n",
      "Epoch 661 - loss: 1.7030351033931648 - val_loss: 1.5126744468832705\n",
      "Epoch 662 - loss: 1.7027367548497458 - val_loss: 1.5060440586333737\n",
      "Epoch 663 - loss: 1.7027367548497458 - val_loss: 1.5060440586333737\n",
      "Epoch 664 - loss: 1.7027367548497458 - val_loss: 1.5060440586333737\n",
      "Epoch 665 - loss: 1.698695239222831 - val_loss: 1.5155143808052176\n",
      "Epoch 666 - loss: 1.698695239222831 - val_loss: 1.5155143808052176\n",
      "Epoch 667 - loss: 1.698695239222831 - val_loss: 1.5155143808052176\n",
      "Epoch 668 - loss: 1.698695239222831 - val_loss: 1.5155143808052176\n",
      "Epoch 669 - loss: 1.698695239222831 - val_loss: 1.5155143808052176\n",
      "Epoch 670 - loss: 1.698695239222831 - val_loss: 1.5155143808052176\n",
      "Epoch 671 - loss: 1.698695239222831 - val_loss: 1.5155143808052176\n",
      "Epoch 672 - loss: 1.6974853076129377 - val_loss: 1.4745067193513004\n",
      "Epoch 673 - loss: 1.6974853076129377 - val_loss: 1.4745067193513004\n",
      "Epoch 674 - loss: 1.6974853076129377 - val_loss: 1.4745067193513004\n",
      "Epoch 675 - loss: 1.6974853076129377 - val_loss: 1.4745067193513004\n",
      "Epoch 676 - loss: 1.6972898747608398 - val_loss: 1.5467003670344692\n",
      "Epoch 677 - loss: 1.6972898747608398 - val_loss: 1.5467003670344692\n",
      "Epoch 678 - loss: 1.697168381051914 - val_loss: 1.505829908194616\n",
      "Epoch 679 - loss: 1.697168381051914 - val_loss: 1.505829908194616\n",
      "Epoch 680 - loss: 1.696914368875435 - val_loss: 1.5008701796143022\n",
      "Epoch 681 - loss: 1.696914368875435 - val_loss: 1.5008701796143022\n",
      "Epoch 682 - loss: 1.696914368875435 - val_loss: 1.5008701796143022\n",
      "Epoch 683 - loss: 1.696352378010625 - val_loss: 1.5062800666303593\n",
      "Epoch 684 - loss: 1.696352378010625 - val_loss: 1.5062800666303593\n",
      "Epoch 685 - loss: 1.6960374554833368 - val_loss: 1.4962515551630509\n",
      "Epoch 686 - loss: 1.6960374554833368 - val_loss: 1.4962515551630509\n",
      "Epoch 687 - loss: 1.6960374554833368 - val_loss: 1.4962515551630509\n",
      "Epoch 688 - loss: 1.6960374554833368 - val_loss: 1.4962515551630509\n",
      "Epoch 689 - loss: 1.6960374554833368 - val_loss: 1.4962515551630509\n",
      "Epoch 690 - loss: 1.6947684487633414 - val_loss: 1.4970305297276991\n",
      "Epoch 691 - loss: 1.6947684487633414 - val_loss: 1.4970305297276991\n",
      "Epoch 692 - loss: 1.6946052096226003 - val_loss: 1.5462865639226144\n",
      "Epoch 693 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 694 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 695 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 696 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 697 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 698 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 699 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 700 - loss: 1.6935893663757093 - val_loss: 1.5517177426951598\n",
      "Epoch 701 - loss: 1.6930717643274076 - val_loss: 1.509371985665412\n",
      "Epoch 702 - loss: 1.6930717643274076 - val_loss: 1.509371985665412\n",
      "Epoch 703 - loss: 1.6930717643274076 - val_loss: 1.509371985665412\n",
      "Epoch 704 - loss: 1.6930717643274076 - val_loss: 1.509371985665412\n",
      "Epoch 705 - loss: 1.6930717643274076 - val_loss: 1.509371985665412\n",
      "Epoch 706 - loss: 1.692434030765556 - val_loss: 1.5255420358341263\n",
      "Epoch 707 - loss: 1.692434030765556 - val_loss: 1.5255420358341263\n",
      "Epoch 708 - loss: 1.692434030765556 - val_loss: 1.5255420358341263\n",
      "Epoch 709 - loss: 1.692434030765556 - val_loss: 1.5255420358341263\n",
      "Epoch 710 - loss: 1.692142700935924 - val_loss: 1.5159898515246275\n",
      "Epoch 711 - loss: 1.692142700935924 - val_loss: 1.5159898515246275\n",
      "Epoch 712 - loss: 1.6912990209535448 - val_loss: 1.5087313671464395\n",
      "Epoch 713 - loss: 1.6912990209535448 - val_loss: 1.5087313671464395\n",
      "Epoch 714 - loss: 1.6912990209535448 - val_loss: 1.5087313671464395\n",
      "Epoch 715 - loss: 1.6911185376158928 - val_loss: 1.5056467992673657\n",
      "Epoch 716 - loss: 1.6910082086417622 - val_loss: 1.495912258256612\n",
      "Epoch 717 - loss: 1.6910082086417622 - val_loss: 1.495912258256612\n",
      "Epoch 718 - loss: 1.6892950900791364 - val_loss: 1.50273339224132\n",
      "Epoch 719 - loss: 1.6892950900791364 - val_loss: 1.50273339224132\n",
      "Epoch 720 - loss: 1.68875171111645 - val_loss: 1.4964446907206912\n",
      "Epoch 721 - loss: 1.68875171111645 - val_loss: 1.4964446907206912\n",
      "Epoch 722 - loss: 1.68875171111645 - val_loss: 1.4964446907206912\n",
      "Epoch 723 - loss: 1.68875171111645 - val_loss: 1.4964446907206912\n",
      "Epoch 724 - loss: 1.68875171111645 - val_loss: 1.4964446907206912\n",
      "Epoch 725 - loss: 1.68875171111645 - val_loss: 1.4964446907206912\n",
      "Epoch 726 - loss: 1.6872407691104763 - val_loss: 1.4929733915197025\n",
      "Epoch 727 - loss: 1.6872407691104763 - val_loss: 1.4929733915197025\n",
      "Epoch 728 - loss: 1.6872407691104763 - val_loss: 1.4929733915197025\n",
      "Epoch 729 - loss: 1.6872407691104763 - val_loss: 1.4929733915197025\n",
      "Epoch 730 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405\n",
      "Epoch 731 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405\n",
      "Epoch 732 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405\n",
      "Epoch 733 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405\n",
      "Epoch 734 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405\n",
      "Epoch 735 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405\n",
      "Epoch 736 - loss: 1.6855010710272462 - val_loss: 1.4965040210249405\n",
      "Epoch 737 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 738 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 739 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 740 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 741 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 742 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 743 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 744 - loss: 1.6850272143135603 - val_loss: 1.4911761178813705\n",
      "Epoch 745 - loss: 1.6843038397447672 - val_loss: 1.4980112666756435\n",
      "Epoch 746 - loss: 1.6843038397447672 - val_loss: 1.4980112666756435\n",
      "Epoch 747 - loss: 1.6837646923798686 - val_loss: 1.4920001984160052\n",
      "Epoch 748 - loss: 1.6815400839026688 - val_loss: 1.5079980592456197\n",
      "Epoch 749 - loss: 1.6815400839026688 - val_loss: 1.5079980592456197\n",
      "Epoch 750 - loss: 1.6815400839026688 - val_loss: 1.5079980592456197\n",
      "Epoch 751 - loss: 1.6815400839026688 - val_loss: 1.5079980592456197\n",
      "Epoch 752 - loss: 1.6815400839026688 - val_loss: 1.5079980592456197\n",
      "Epoch 753 - loss: 1.6815400839026688 - val_loss: 1.5079980592456197\n",
      "Epoch 754 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 755 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 756 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 757 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 758 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 759 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 760 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 761 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 762 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 763 - loss: 1.6791279835449475 - val_loss: 1.4929807109396844\n",
      "Epoch 764 - loss: 1.678606209189609 - val_loss: 1.5009182064445405\n",
      "Epoch 765 - loss: 1.678606209189609 - val_loss: 1.5009182064445405\n",
      "Epoch 766 - loss: 1.678606209189609 - val_loss: 1.5009182064445405\n",
      "Epoch 767 - loss: 1.678606209189609 - val_loss: 1.5009182064445405\n",
      "Epoch 768 - loss: 1.678606209189609 - val_loss: 1.5009182064445405\n",
      "Epoch 769 - loss: 1.6775822478516285 - val_loss: 1.5160291855355896\n",
      "Epoch 770 - loss: 1.6775822478516285 - val_loss: 1.5160291855355896\n",
      "Epoch 771 - loss: 1.6775822478516285 - val_loss: 1.5160291855355896\n",
      "Epoch 772 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 773 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 774 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 775 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 776 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 777 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 778 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 779 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 780 - loss: 1.6754733956587036 - val_loss: 1.5163537531580165\n",
      "Epoch 781 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927\n",
      "Epoch 782 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927\n",
      "Epoch 783 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927\n",
      "Epoch 784 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927\n",
      "Epoch 785 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927\n",
      "Epoch 786 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927\n",
      "Epoch 787 - loss: 1.6751812120523104 - val_loss: 1.5171871909867927\n",
      "Epoch 788 - loss: 1.675114926767903 - val_loss: 1.5182156300807688\n",
      "Epoch 789 - loss: 1.673824369201371 - val_loss: 1.4987808326893184\n",
      "Epoch 790 - loss: 1.673824369201371 - val_loss: 1.4987808326893184\n",
      "Epoch 791 - loss: 1.673824369201371 - val_loss: 1.4987808326893184\n",
      "Epoch 792 - loss: 1.6730280152906596 - val_loss: 1.4862613681490555\n",
      "Epoch 793 - loss: 1.6730280152906596 - val_loss: 1.4862613681490555\n",
      "Epoch 794 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 795 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 796 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 797 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 798 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 799 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 800 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 801 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 802 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 803 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 804 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 805 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 806 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 807 - loss: 1.6709539137333858 - val_loss: 1.4939968609559666\n",
      "Epoch 808 - loss: 1.6705289085350614 - val_loss: 1.4701504725041372\n",
      "Epoch 809 - loss: 1.6704686532500106 - val_loss: 1.4720747509752061\n",
      "Epoch 810 - loss: 1.6704686532500106 - val_loss: 1.4720747509752061\n",
      "Epoch 811 - loss: 1.6704686532500106 - val_loss: 1.4720747509752061\n",
      "Epoch 812 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 813 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 814 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 815 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 816 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 817 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 818 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 819 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 820 - loss: 1.6694183624147694 - val_loss: 1.4768696377773085\n",
      "Epoch 821 - loss: 1.6670721445570622 - val_loss: 1.474692828512551\n",
      "Epoch 822 - loss: 1.6670721445570622 - val_loss: 1.474692828512551\n",
      "Epoch 823 - loss: 1.6658819020704358 - val_loss: 1.4741190159945885\n",
      "Epoch 824 - loss: 1.6658819020704358 - val_loss: 1.4741190159945885\n",
      "Epoch 825 - loss: 1.6658819020704358 - val_loss: 1.4741190159945885\n",
      "Epoch 826 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 827 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 828 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 829 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 830 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 831 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 832 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 833 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 834 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 835 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 836 - loss: 1.6656589624389269 - val_loss: 1.4793079871249442\n",
      "Epoch 837 - loss: 1.6648559849230902 - val_loss: 1.4755556077612546\n",
      "Epoch 838 - loss: 1.6648559849230902 - val_loss: 1.4755556077612546\n",
      "Epoch 839 - loss: 1.6648559849230902 - val_loss: 1.4755556077612546\n",
      "Epoch 840 - loss: 1.6639619720958985 - val_loss: 1.4712610586091115\n",
      "Epoch 841 - loss: 1.6638914869138612 - val_loss: 1.4884123433153642\n",
      "Epoch 842 - loss: 1.6638914869138612 - val_loss: 1.4884123433153642\n",
      "Epoch 843 - loss: 1.6638914869138612 - val_loss: 1.4884123433153642\n",
      "Epoch 844 - loss: 1.6638914869138612 - val_loss: 1.4884123433153642\n",
      "Epoch 845 - loss: 1.6638914869138612 - val_loss: 1.4884123433153642\n",
      "Epoch 846 - loss: 1.6638914869138612 - val_loss: 1.4884123433153642\n",
      "Epoch 847 - loss: 1.6638781942467098 - val_loss: 1.4652805688444184\n",
      "Epoch 848 - loss: 1.6638781942467098 - val_loss: 1.4652805688444184\n",
      "Epoch 849 - loss: 1.6613669182008606 - val_loss: 1.4943225371740951\n",
      "Epoch 850 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 851 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 852 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 853 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 854 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 855 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 856 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 857 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 858 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 859 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 860 - loss: 1.6608108092817093 - val_loss: 1.4844783067472644\n",
      "Epoch 861 - loss: 1.659905797090408 - val_loss: 1.4565844985810863\n",
      "Epoch 862 - loss: 1.659905797090408 - val_loss: 1.4565844985810863\n",
      "Epoch 863 - loss: 1.659905797090408 - val_loss: 1.4565844985810863\n",
      "Epoch 864 - loss: 1.6590084626552613 - val_loss: 1.4701893675523645\n",
      "Epoch 865 - loss: 1.6590084626552613 - val_loss: 1.4701893675523645\n",
      "Epoch 866 - loss: 1.6590084626552613 - val_loss: 1.4701893675523645\n",
      "Epoch 867 - loss: 1.6590084626552613 - val_loss: 1.4701893675523645\n",
      "Epoch 868 - loss: 1.6590084626552613 - val_loss: 1.4701893675523645\n",
      "Epoch 869 - loss: 1.6587444026080567 - val_loss: 1.468069603491669\n",
      "Epoch 870 - loss: 1.6587444026080567 - val_loss: 1.468069603491669\n",
      "Epoch 871 - loss: 1.6583405134688463 - val_loss: 1.4645905686395646\n",
      "Epoch 872 - loss: 1.6583405134688463 - val_loss: 1.4645905686395646\n",
      "Epoch 873 - loss: 1.6583405134688463 - val_loss: 1.4645905686395646\n",
      "Epoch 874 - loss: 1.6583405134688463 - val_loss: 1.4645905686395646\n",
      "Epoch 875 - loss: 1.6568021067649628 - val_loss: 1.487832968400229\n",
      "Epoch 876 - loss: 1.6568021067649628 - val_loss: 1.487832968400229\n",
      "Epoch 877 - loss: 1.6568021067649628 - val_loss: 1.487832968400229\n",
      "Epoch 878 - loss: 1.6568021067649628 - val_loss: 1.487832968400229\n",
      "Epoch 879 - loss: 1.6568021067649628 - val_loss: 1.487832968400229\n",
      "Epoch 880 - loss: 1.6560872098007888 - val_loss: 1.4688288529518012\n",
      "Epoch 881 - loss: 1.6560872098007888 - val_loss: 1.4688288529518012\n",
      "Epoch 882 - loss: 1.6560872098007888 - val_loss: 1.4688288529518012\n",
      "Epoch 883 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 884 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 885 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 886 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 887 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 888 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 889 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 890 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 891 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 892 - loss: 1.655189336770723 - val_loss: 1.494473412397927\n",
      "Epoch 893 - loss: 1.654787685576 - val_loss: 1.486376028497698\n",
      "Epoch 894 - loss: 1.654787685576 - val_loss: 1.486376028497698\n",
      "Epoch 895 - loss: 1.654787685576 - val_loss: 1.486376028497698\n",
      "Epoch 896 - loss: 1.654787685576 - val_loss: 1.486376028497698\n",
      "Epoch 897 - loss: 1.654787685576 - val_loss: 1.486376028497698\n",
      "Epoch 898 - loss: 1.654787685576 - val_loss: 1.486376028497698\n",
      "Epoch 899 - loss: 1.6535480784899257 - val_loss: 1.4943725310453781\n",
      "Epoch 900 - loss: 1.6535480784899257 - val_loss: 1.4943725310453781\n",
      "Epoch 901 - loss: 1.6535480784899257 - val_loss: 1.4943725310453781\n",
      "Epoch 902 - loss: 1.6535480784899257 - val_loss: 1.4943725310453781\n",
      "Epoch 903 - loss: 1.6535480784899257 - val_loss: 1.4943725310453781\n",
      "Epoch 904 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 905 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 906 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 907 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 908 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 909 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 910 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 911 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 912 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 913 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 914 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 915 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 916 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 917 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 918 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 919 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 920 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 921 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 922 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 923 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 924 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 925 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 926 - loss: 1.6515206150841117 - val_loss: 1.4689475165166879\n",
      "Epoch 927 - loss: 1.6514359646964234 - val_loss: 1.4753617425050969\n",
      "Epoch 928 - loss: 1.6514359646964234 - val_loss: 1.4753617425050969\n",
      "Epoch 929 - loss: 1.6514359646964234 - val_loss: 1.4753617425050969\n",
      "Epoch 930 - loss: 1.6514359646964234 - val_loss: 1.4753617425050969\n",
      "Epoch 931 - loss: 1.6514359646964234 - val_loss: 1.4753617425050969\n",
      "Epoch 932 - loss: 1.651246206537777 - val_loss: 1.4598430881910627\n",
      "Epoch 933 - loss: 1.651246206537777 - val_loss: 1.4598430881910627\n",
      "Epoch 934 - loss: 1.651246206537777 - val_loss: 1.4598430881910627\n",
      "Epoch 935 - loss: 1.651246206537777 - val_loss: 1.4598430881910627\n",
      "Epoch 936 - loss: 1.651246206537777 - val_loss: 1.4598430881910627\n",
      "Epoch 937 - loss: 1.651135997566617 - val_loss: 1.4942517331738099\n",
      "Epoch 938 - loss: 1.651135997566617 - val_loss: 1.4942517331738099\n",
      "Epoch 939 - loss: 1.651135997566617 - val_loss: 1.4942517331738099\n",
      "Epoch 940 - loss: 1.651135997566617 - val_loss: 1.4942517331738099\n",
      "Epoch 941 - loss: 1.651135997566617 - val_loss: 1.4942517331738099\n",
      "Epoch 942 - loss: 1.651135997566617 - val_loss: 1.4942517331738099\n",
      "Epoch 943 - loss: 1.651135997566617 - val_loss: 1.4942517331738099\n",
      "Epoch 944 - loss: 1.6508516698489393 - val_loss: 1.4582764362354674\n",
      "Epoch 945 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 946 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 947 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 948 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 949 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 950 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 951 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 952 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 953 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 954 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 955 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 956 - loss: 1.6497937807448522 - val_loss: 1.4757123482655345\n",
      "Epoch 957 - loss: 1.6495275162810914 - val_loss: 1.4805903245828849\n",
      "Epoch 958 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 959 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 960 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 961 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 962 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 963 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 964 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 965 - loss: 1.6489772616657223 - val_loss: 1.4899849088977717\n",
      "Epoch 966 - loss: 1.6484735653856282 - val_loss: 1.4783408855616238\n",
      "Epoch 967 - loss: 1.6484735653856282 - val_loss: 1.4783408855616238\n",
      "Epoch 968 - loss: 1.6484735653856282 - val_loss: 1.4783408855616238\n",
      "Epoch 969 - loss: 1.6484735653856282 - val_loss: 1.4783408855616238\n",
      "Epoch 970 - loss: 1.6478457331618466 - val_loss: 1.4461332716670796\n",
      "Epoch 971 - loss: 1.6478457331618466 - val_loss: 1.4461332716670796\n",
      "Epoch 972 - loss: 1.6478457331618466 - val_loss: 1.4461332716670796\n",
      "Epoch 973 - loss: 1.6478457331618466 - val_loss: 1.4461332716670796\n",
      "Epoch 974 - loss: 1.6478457331618466 - val_loss: 1.4461332716670796\n",
      "Epoch 975 - loss: 1.6475169451201648 - val_loss: 1.4829689833208737\n",
      "Epoch 976 - loss: 1.6475169451201648 - val_loss: 1.4829689833208737\n",
      "Epoch 977 - loss: 1.6475169451201648 - val_loss: 1.4829689833208737\n",
      "Epoch 978 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 979 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 980 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 981 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 982 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 983 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 984 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 985 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 986 - loss: 1.645181907660707 - val_loss: 1.45997006650999\n",
      "Epoch 987 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 988 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 989 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 990 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 991 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 992 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 993 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 994 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 995 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 996 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 997 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 998 - loss: 1.6443724092825462 - val_loss: 1.4672106316173699\n",
      "Epoch 999 - loss: 1.6432171060057628 - val_loss: 1.4412142395130065\n",
      "Epoch 1000 - loss: 1.6432171060057628 - val_loss: 1.4412142395130065\n",
      "Epoch 1001 - loss: 1.6432171060057628 - val_loss: 1.4412142395130065\n",
      "Epoch 1002 - loss: 1.6432171060057628 - val_loss: 1.4412142395130065\n",
      "Epoch 1003 - loss: 1.6432171060057628 - val_loss: 1.4412142395130065\n",
      "Epoch 1004 - loss: 1.6432171060057628 - val_loss: 1.4412142395130065\n",
      "Epoch 1005 - loss: 1.6423787383507042 - val_loss: 1.429135197763711\n",
      "Epoch 1006 - loss: 1.6423787383507042 - val_loss: 1.429135197763711\n",
      "Epoch 1007 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1008 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1009 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1010 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1011 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1012 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1013 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1014 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1015 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1016 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1017 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1018 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1019 - loss: 1.641840988642151 - val_loss: 1.4411689886500796\n",
      "Epoch 1020 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1021 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1022 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1023 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1024 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1025 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1026 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1027 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1028 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1029 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1030 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1031 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1032 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1033 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1034 - loss: 1.641001476442525 - val_loss: 1.4575943784928775\n",
      "Epoch 1035 - loss: 1.640139760144246 - val_loss: 1.462198376644603\n",
      "Epoch 1036 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1037 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1038 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1039 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1040 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1041 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1042 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1043 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1044 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1045 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1046 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1047 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1048 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1049 - loss: 1.6386647865005535 - val_loss: 1.4711522295487387\n",
      "Epoch 1050 - loss: 1.6383806888283725 - val_loss: 1.4565238873397193\n",
      "Epoch 1051 - loss: 1.6383806888283725 - val_loss: 1.4565238873397193\n",
      "Epoch 1052 - loss: 1.6383806888283725 - val_loss: 1.4565238873397193\n",
      "Epoch 1053 - loss: 1.6383806888283725 - val_loss: 1.4565238873397193\n",
      "Epoch 1054 - loss: 1.6383806888283725 - val_loss: 1.4565238873397193\n",
      "Epoch 1055 - loss: 1.6367983936898376 - val_loss: 1.451633576709871\n",
      "Epoch 1056 - loss: 1.6367983936898376 - val_loss: 1.451633576709871\n",
      "Epoch 1057 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1058 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1059 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1060 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1061 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1062 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1063 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1064 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1065 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1066 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1067 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1068 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1069 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1070 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1071 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1072 - loss: 1.6354518655548598 - val_loss: 1.444876708338808\n",
      "Epoch 1073 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1074 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1075 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1076 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1077 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1078 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1079 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1080 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1081 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1082 - loss: 1.6348436148887138 - val_loss: 1.4460860387417547\n",
      "Epoch 1083 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1084 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1085 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1086 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1087 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1088 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1089 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1090 - loss: 1.6332801254750242 - val_loss: 1.4365001464036904\n",
      "Epoch 1091 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805\n",
      "Epoch 1092 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805\n",
      "Epoch 1093 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805\n",
      "Epoch 1094 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805\n",
      "Epoch 1095 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805\n",
      "Epoch 1096 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805\n",
      "Epoch 1097 - loss: 1.6327434693733198 - val_loss: 1.4447669509949805\n",
      "Epoch 1098 - loss: 1.6325507871019767 - val_loss: 1.4624848293839974\n",
      "Epoch 1099 - loss: 1.6323963909816246 - val_loss: 1.4352683463359852\n",
      "Epoch 1100 - loss: 1.6323963909816246 - val_loss: 1.4352683463359852\n",
      "Epoch 1101 - loss: 1.6323963909816246 - val_loss: 1.4352683463359852\n",
      "Epoch 1102 - loss: 1.6323963909816246 - val_loss: 1.4352683463359852\n",
      "Epoch 1103 - loss: 1.6323963909816246 - val_loss: 1.4352683463359852\n",
      "Epoch 1104 - loss: 1.6323963909816246 - val_loss: 1.4352683463359852\n",
      "Epoch 1105 - loss: 1.6320523203536097 - val_loss: 1.442748436420223\n",
      "Epoch 1106 - loss: 1.6320523203536097 - val_loss: 1.442748436420223\n",
      "Epoch 1107 - loss: 1.6320523203536097 - val_loss: 1.442748436420223\n",
      "Epoch 1108 - loss: 1.6320523203536097 - val_loss: 1.442748436420223\n",
      "Epoch 1109 - loss: 1.6320523203536097 - val_loss: 1.442748436420223\n",
      "Epoch 1110 - loss: 1.6320523203536097 - val_loss: 1.442748436420223\n",
      "Epoch 1111 - loss: 1.6320523203536097 - val_loss: 1.442748436420223\n",
      "Epoch 1112 - loss: 1.6310990515587733 - val_loss: 1.4348160708474755\n",
      "Epoch 1113 - loss: 1.6310990515587733 - val_loss: 1.4348160708474755\n",
      "Epoch 1114 - loss: 1.6310990515587733 - val_loss: 1.4348160708474755\n",
      "Epoch 1115 - loss: 1.6310990515587733 - val_loss: 1.4348160708474755\n",
      "Epoch 1116 - loss: 1.6310990515587733 - val_loss: 1.4348160708474755\n",
      "Epoch 1117 - loss: 1.6309782387432177 - val_loss: 1.4450676056125766\n",
      "Epoch 1118 - loss: 1.6309782387432177 - val_loss: 1.4450676056125766\n",
      "Epoch 1119 - loss: 1.6309782387432177 - val_loss: 1.4450676056125766\n",
      "Epoch 1120 - loss: 1.6309782387432177 - val_loss: 1.4450676056125766\n",
      "Epoch 1121 - loss: 1.6309782387432177 - val_loss: 1.4450676056125766\n",
      "Epoch 1122 - loss: 1.6309394872736378 - val_loss: 1.4402154068485826\n",
      "Epoch 1123 - loss: 1.6309394872736378 - val_loss: 1.4402154068485826\n",
      "Epoch 1124 - loss: 1.6308117877416752 - val_loss: 1.4469543973769583\n",
      "Epoch 1125 - loss: 1.6308117877416752 - val_loss: 1.4469543973769583\n",
      "Epoch 1126 - loss: 1.6302946005750518 - val_loss: 1.4542674355530585\n",
      "Epoch 1127 - loss: 1.6302946005750518 - val_loss: 1.4542674355530585\n",
      "Epoch 1128 - loss: 1.6302946005750518 - val_loss: 1.4542674355530585\n",
      "Epoch 1129 - loss: 1.6286865310588001 - val_loss: 1.4531830846577525\n",
      "Epoch 1130 - loss: 1.6286865310588001 - val_loss: 1.4531830846577525\n",
      "Epoch 1131 - loss: 1.6286865310588001 - val_loss: 1.4531830846577525\n",
      "Epoch 1132 - loss: 1.6286865310588001 - val_loss: 1.4531830846577525\n",
      "Epoch 1133 - loss: 1.6286865310588001 - val_loss: 1.4531830846577525\n",
      "Epoch 1134 - loss: 1.6286865310588001 - val_loss: 1.4531830846577525\n",
      "Epoch 1135 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1136 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1137 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1138 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1139 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1140 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1141 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1142 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1143 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1144 - loss: 1.6282664885717237 - val_loss: 1.4463200020301596\n",
      "Epoch 1145 - loss: 1.628251488607008 - val_loss: 1.4497247983174926\n",
      "Epoch 1146 - loss: 1.628251488607008 - val_loss: 1.4497247983174926\n",
      "Epoch 1147 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1148 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1149 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1150 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1151 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1152 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1153 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1154 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1155 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1156 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1157 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1158 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1159 - loss: 1.6282268631856889 - val_loss: 1.4451317659005825\n",
      "Epoch 1160 - loss: 1.6274908659627139 - val_loss: 1.463378420713023\n",
      "Epoch 1161 - loss: 1.6274908659627139 - val_loss: 1.463378420713023\n",
      "Epoch 1162 - loss: 1.6274908659627139 - val_loss: 1.463378420713023\n",
      "Epoch 1163 - loss: 1.6274908659627139 - val_loss: 1.463378420713023\n",
      "Epoch 1164 - loss: 1.6274720500515067 - val_loss: 1.4335168875937137\n",
      "Epoch 1165 - loss: 1.6274720500515067 - val_loss: 1.4335168875937137\n",
      "Epoch 1166 - loss: 1.627306901284965 - val_loss: 1.4571554896967558\n",
      "Epoch 1167 - loss: 1.627306901284965 - val_loss: 1.4571554896967558\n",
      "Epoch 1168 - loss: 1.627306901284965 - val_loss: 1.4571554896967558\n",
      "Epoch 1169 - loss: 1.627306901284965 - val_loss: 1.4571554896967558\n",
      "Epoch 1170 - loss: 1.627306901284965 - val_loss: 1.4571554896967558\n",
      "Epoch 1171 - loss: 1.627306901284965 - val_loss: 1.4571554896967558\n",
      "Epoch 1172 - loss: 1.627306901284965 - val_loss: 1.4571554896967558\n",
      "Epoch 1173 - loss: 1.6264614606280987 - val_loss: 1.4467500185857407\n",
      "Epoch 1174 - loss: 1.6264614606280987 - val_loss: 1.4467500185857407\n",
      "Epoch 1175 - loss: 1.6262930171581862 - val_loss: 1.457137721251174\n",
      "Epoch 1176 - loss: 1.6262930171581862 - val_loss: 1.457137721251174\n",
      "Epoch 1177 - loss: 1.6262930171581862 - val_loss: 1.457137721251174\n",
      "Epoch 1178 - loss: 1.6262930171581862 - val_loss: 1.457137721251174\n",
      "Epoch 1179 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1180 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1181 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1182 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1183 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1184 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1185 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1186 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1187 - loss: 1.6251811909203329 - val_loss: 1.4580910320000475\n",
      "Epoch 1188 - loss: 1.625127579994084 - val_loss: 1.439401800284108\n",
      "Epoch 1189 - loss: 1.625127579994084 - val_loss: 1.439401800284108\n",
      "Epoch 1190 - loss: 1.625127579994084 - val_loss: 1.439401800284108\n",
      "Epoch 1191 - loss: 1.6248521605043231 - val_loss: 1.4417814853160995\n",
      "Epoch 1192 - loss: 1.6248521605043231 - val_loss: 1.4417814853160995\n",
      "Epoch 1193 - loss: 1.6248521605043231 - val_loss: 1.4417814853160995\n",
      "Epoch 1194 - loss: 1.6248521605043231 - val_loss: 1.4417814853160995\n",
      "Epoch 1195 - loss: 1.6248521605043231 - val_loss: 1.4417814853160995\n",
      "Epoch 1196 - loss: 1.6248521605043231 - val_loss: 1.4417814853160995\n",
      "Epoch 1197 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633\n",
      "Epoch 1198 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633\n",
      "Epoch 1199 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633\n",
      "Epoch 1200 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633\n",
      "Epoch 1201 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633\n",
      "Epoch 1202 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633\n",
      "Epoch 1203 - loss: 1.6236293096015841 - val_loss: 1.4303360765146633\n",
      "Epoch 1204 - loss: 1.6233245589852225 - val_loss: 1.4389355433959061\n",
      "Epoch 1205 - loss: 1.6233245589852225 - val_loss: 1.4389355433959061\n",
      "Epoch 1206 - loss: 1.6233245589852225 - val_loss: 1.4389355433959061\n",
      "Epoch 1207 - loss: 1.6233245589852225 - val_loss: 1.4389355433959061\n",
      "Epoch 1208 - loss: 1.6233245589852225 - val_loss: 1.4389355433959061\n",
      "Epoch 1209 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1210 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1211 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1212 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1213 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1214 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1215 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1216 - loss: 1.6227922534211265 - val_loss: 1.4363265762701938\n",
      "Epoch 1217 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1218 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1219 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1220 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1221 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1222 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1223 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1224 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1225 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1226 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1227 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1228 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1229 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1230 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1231 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1232 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1233 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1234 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1235 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1236 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1237 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1238 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1239 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1240 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1241 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1242 - loss: 1.6201124649432055 - val_loss: 1.4275008378065004\n",
      "Epoch 1243 - loss: 1.6200211047631083 - val_loss: 1.436108879588107\n",
      "Epoch 1244 - loss: 1.619855971261856 - val_loss: 1.428986994191229\n",
      "Epoch 1245 - loss: 1.619855971261856 - val_loss: 1.428986994191229\n",
      "Epoch 1246 - loss: 1.619855971261856 - val_loss: 1.428986994191229\n",
      "Epoch 1247 - loss: 1.619855971261856 - val_loss: 1.428986994191229\n",
      "Epoch 1248 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1249 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1250 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1251 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1252 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1253 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1254 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1255 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1256 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1257 - loss: 1.6193780821707704 - val_loss: 1.437371191651899\n",
      "Epoch 1258 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1259 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1260 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1261 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1262 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1263 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1264 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1265 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1266 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1267 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1268 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1269 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1270 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1271 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1272 - loss: 1.6185370437239284 - val_loss: 1.436711970050596\n",
      "Epoch 1273 - loss: 1.6183982544676203 - val_loss: 1.4366507717559354\n",
      "Epoch 1274 - loss: 1.6183982544676203 - val_loss: 1.4366507717559354\n",
      "Epoch 1275 - loss: 1.6181907776349702 - val_loss: 1.4130167894093848\n",
      "Epoch 1276 - loss: 1.6181907776349702 - val_loss: 1.4130167894093848\n",
      "Epoch 1277 - loss: 1.6181907776349702 - val_loss: 1.4130167894093848\n",
      "Epoch 1278 - loss: 1.6181907776349702 - val_loss: 1.4130167894093848\n",
      "Epoch 1279 - loss: 1.617765484813033 - val_loss: 1.4266342654312276\n",
      "Epoch 1280 - loss: 1.617765484813033 - val_loss: 1.4266342654312276\n",
      "Epoch 1281 - loss: 1.617765484813033 - val_loss: 1.4266342654312276\n",
      "Epoch 1282 - loss: 1.6176321458578218 - val_loss: 1.4223267805951552\n",
      "Epoch 1283 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1284 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1285 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1286 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1287 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1288 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1289 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1290 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1291 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1292 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1293 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1294 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1295 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1296 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1297 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1298 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1299 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1300 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1301 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1302 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1303 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1304 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1305 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1306 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1307 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1308 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1309 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1310 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1311 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1312 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1313 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1314 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1315 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1316 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1317 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1318 - loss: 1.6157048372481142 - val_loss: 1.4256702966476502\n",
      "Epoch 1319 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1320 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1321 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1322 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1323 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1324 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1325 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1326 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1327 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1328 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1329 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1330 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1331 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1332 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1333 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1334 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1335 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1336 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1337 - loss: 1.6150821890880886 - val_loss: 1.445944149722168\n",
      "Epoch 1338 - loss: 1.614904506640372 - val_loss: 1.4349248220355644\n",
      "Epoch 1339 - loss: 1.614904506640372 - val_loss: 1.4349248220355644\n",
      "Epoch 1340 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1341 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1342 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1343 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1344 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1345 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1346 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1347 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1348 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1349 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1350 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1351 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1352 - loss: 1.6144670567326984 - val_loss: 1.406961305451305\n",
      "Epoch 1353 - loss: 1.6133852364182015 - val_loss: 1.429062068634201\n",
      "Epoch 1354 - loss: 1.6133852364182015 - val_loss: 1.429062068634201\n",
      "Epoch 1355 - loss: 1.6133852364182015 - val_loss: 1.429062068634201\n",
      "Epoch 1356 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1357 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1358 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1359 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1360 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1361 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1362 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1363 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1364 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1365 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1366 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1367 - loss: 1.6124694867396714 - val_loss: 1.4370409118333178\n",
      "Epoch 1368 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1369 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1370 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1371 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1372 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1373 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1374 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1375 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1376 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1377 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1378 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1379 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1380 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1381 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1382 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1383 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1384 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1385 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1386 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1387 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1388 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1389 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1390 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1391 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1392 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1393 - loss: 1.6115182974636515 - val_loss: 1.4165738770494756\n",
      "Epoch 1394 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1395 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1396 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1397 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1398 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1399 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1400 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1401 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1402 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1403 - loss: 1.611393417969238 - val_loss: 1.4147221352571573\n",
      "Epoch 1404 - loss: 1.61108893014879 - val_loss: 1.4133569434618303\n",
      "Epoch 1405 - loss: 1.61108893014879 - val_loss: 1.4133569434618303\n",
      "Epoch 1406 - loss: 1.61108893014879 - val_loss: 1.4133569434618303\n",
      "Epoch 1407 - loss: 1.61108893014879 - val_loss: 1.4133569434618303\n",
      "Epoch 1408 - loss: 1.6100370515085605 - val_loss: 1.4248052841520882\n",
      "Epoch 1409 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1410 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1411 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1412 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1413 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1414 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1415 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1416 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1417 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1418 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1419 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1420 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1421 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1422 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1423 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1424 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1425 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1426 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1427 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1428 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1429 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1430 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1431 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1432 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1433 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1434 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1435 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1436 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1437 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1438 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1439 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1440 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1441 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1442 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1443 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1444 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1445 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1446 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1447 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1448 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1449 - loss: 1.608086364130082 - val_loss: 1.4044837241798498\n",
      "Epoch 1450 - loss: 1.607722106586941 - val_loss: 1.4074509710703471\n",
      "Epoch 1451 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1452 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1453 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1454 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1455 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1456 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1457 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1458 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1459 - loss: 1.6070694531804026 - val_loss: 1.414723272242064\n",
      "Epoch 1460 - loss: 1.6070412894063324 - val_loss: 1.4066603490026868\n",
      "Epoch 1461 - loss: 1.6070412894063324 - val_loss: 1.4066603490026868\n",
      "Epoch 1462 - loss: 1.6070412894063324 - val_loss: 1.4066603490026868\n",
      "Epoch 1463 - loss: 1.6070412894063324 - val_loss: 1.4066603490026868\n",
      "Epoch 1464 - loss: 1.6069294910239662 - val_loss: 1.4129183863061507\n",
      "Epoch 1465 - loss: 1.6055211443740645 - val_loss: 1.4159526710953128\n",
      "Epoch 1466 - loss: 1.6055211443740645 - val_loss: 1.4159526710953128\n",
      "Epoch 1467 - loss: 1.6055211443740645 - val_loss: 1.4159526710953128\n",
      "Epoch 1468 - loss: 1.6055211443740645 - val_loss: 1.4159526710953128\n",
      "Epoch 1469 - loss: 1.6055211443740645 - val_loss: 1.4159526710953128\n",
      "Epoch 1470 - loss: 1.6055211443740645 - val_loss: 1.4159526710953128\n",
      "Epoch 1471 - loss: 1.6045739276717523 - val_loss: 1.4153331542996632\n",
      "Epoch 1472 - loss: 1.6045739276717523 - val_loss: 1.4153331542996632\n",
      "Epoch 1473 - loss: 1.604516315891886 - val_loss: 1.4217820026536305\n",
      "Epoch 1474 - loss: 1.604516315891886 - val_loss: 1.4217820026536305\n",
      "Epoch 1475 - loss: 1.604516315891886 - val_loss: 1.4217820026536305\n",
      "Epoch 1476 - loss: 1.604516315891886 - val_loss: 1.4217820026536305\n",
      "Epoch 1477 - loss: 1.604516315891886 - val_loss: 1.4217820026536305\n",
      "Epoch 1478 - loss: 1.604516315891886 - val_loss: 1.4217820026536305\n",
      "Epoch 1479 - loss: 1.604516315891886 - val_loss: 1.4217820026536305\n",
      "Epoch 1480 - loss: 1.6044840917131065 - val_loss: 1.3992090312734642\n",
      "Epoch 1481 - loss: 1.6044840917131065 - val_loss: 1.3992090312734642\n",
      "Epoch 1482 - loss: 1.603666870503361 - val_loss: 1.4206456593829184\n",
      "Epoch 1483 - loss: 1.603666870503361 - val_loss: 1.4206456593829184\n",
      "Epoch 1484 - loss: 1.603666870503361 - val_loss: 1.4206456593829184\n",
      "Epoch 1485 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1486 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1487 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1488 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1489 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1490 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1491 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1492 - loss: 1.6034587499871158 - val_loss: 1.4241802793164449\n",
      "Epoch 1493 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1494 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1495 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1496 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1497 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1498 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1499 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1500 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1501 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1502 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1503 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1504 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1505 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1506 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1507 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1508 - loss: 1.6023167973320187 - val_loss: 1.4300243671520931\n",
      "Epoch 1509 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1510 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1511 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1512 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1513 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1514 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1515 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1516 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1517 - loss: 1.6014957749380245 - val_loss: 1.4140323587790558\n",
      "Epoch 1518 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1519 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1520 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1521 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1522 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1523 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1524 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1525 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1526 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1527 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1528 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1529 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1530 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1531 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1532 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1533 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1534 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1535 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1536 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1537 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1538 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1539 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1540 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1541 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1542 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1543 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1544 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1545 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1546 - loss: 1.5991551267515909 - val_loss: 1.4068589005018342\n",
      "Epoch 1547 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1548 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1549 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1550 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1551 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1552 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1553 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1554 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1555 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1556 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1557 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1558 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1559 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1560 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1561 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1562 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1563 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1564 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1565 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1566 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1567 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1568 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1569 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1570 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1571 - loss: 1.5980713642715354 - val_loss: 1.3840300773448924\n",
      "Epoch 1572 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1573 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1574 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1575 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1576 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1577 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1578 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1579 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1580 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1581 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1582 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1583 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1584 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1585 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1586 - loss: 1.597111293194125 - val_loss: 1.4104749087647837\n",
      "Epoch 1587 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1588 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1589 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1590 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1591 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1592 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1593 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1594 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1595 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1596 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1597 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1598 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1599 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1600 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1601 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1602 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1603 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1604 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1605 - loss: 1.5962530980488563 - val_loss: 1.412116405493275\n",
      "Epoch 1606 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1607 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1608 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1609 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1610 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1611 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1612 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1613 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1614 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1615 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1616 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1617 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1618 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1619 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1620 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1621 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1622 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1623 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1624 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1625 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1626 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1627 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1628 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1629 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1630 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1631 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1632 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1633 - loss: 1.5952481782406374 - val_loss: 1.4135322271993132\n",
      "Epoch 1634 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1635 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1636 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1637 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1638 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1639 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1640 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1641 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1642 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1643 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1644 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1645 - loss: 1.594782902662078 - val_loss: 1.4034583696954228\n",
      "Epoch 1646 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1647 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1648 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1649 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1650 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1651 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1652 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1653 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1654 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1655 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1656 - loss: 1.5946893369057102 - val_loss: 1.4008482790733097\n",
      "Epoch 1657 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1658 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1659 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1660 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1661 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1662 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1663 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1664 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1665 - loss: 1.5942859059416725 - val_loss: 1.3882723505649213\n",
      "Epoch 1666 - loss: 1.5935303032250272 - val_loss: 1.4055526184665659\n",
      "Epoch 1667 - loss: 1.5935303032250272 - val_loss: 1.4055526184665659\n",
      "Epoch 1668 - loss: 1.5935303032250272 - val_loss: 1.4055526184665659\n",
      "Epoch 1669 - loss: 1.5935303032250272 - val_loss: 1.4055526184665659\n",
      "Epoch 1670 - loss: 1.5935303032250272 - val_loss: 1.4055526184665659\n",
      "Epoch 1671 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1672 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1673 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1674 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1675 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1676 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1677 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1678 - loss: 1.5930591643789664 - val_loss: 1.411103491493929\n",
      "Epoch 1679 - loss: 1.5921838656688483 - val_loss: 1.4127802192663867\n",
      "Epoch 1680 - loss: 1.5921838656688483 - val_loss: 1.4127802192663867\n",
      "Epoch 1681 - loss: 1.5921838656688483 - val_loss: 1.4127802192663867\n",
      "Epoch 1682 - loss: 1.5921838656688483 - val_loss: 1.4127802192663867\n",
      "Epoch 1683 - loss: 1.5921838656688483 - val_loss: 1.4127802192663867\n",
      "Epoch 1684 - loss: 1.5921838656688483 - val_loss: 1.4127802192663867\n",
      "Epoch 1685 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1686 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1687 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1688 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1689 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1690 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1691 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1692 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1693 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1694 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1695 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1696 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1697 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1698 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1699 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1700 - loss: 1.5915696852003385 - val_loss: 1.402539713195365\n",
      "Epoch 1701 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1702 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1703 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1704 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1705 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1706 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1707 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1708 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1709 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1710 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1711 - loss: 1.5905656169437652 - val_loss: 1.4025104815412899\n",
      "Epoch 1712 - loss: 1.5902763229877228 - val_loss: 1.4044477775034891\n",
      "Epoch 1713 - loss: 1.5902763229877228 - val_loss: 1.4044477775034891\n",
      "Epoch 1714 - loss: 1.5902763229877228 - val_loss: 1.4044477775034891\n",
      "Epoch 1715 - loss: 1.5902763229877228 - val_loss: 1.4044477775034891\n",
      "Epoch 1716 - loss: 1.5901276282991317 - val_loss: 1.3749002354507798\n",
      "Epoch 1717 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1718 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1719 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1720 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1721 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1722 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1723 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1724 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1725 - loss: 1.5897342958489857 - val_loss: 1.3987692244928955\n",
      "Epoch 1726 - loss: 1.5882287969133588 - val_loss: 1.3942791602441922\n",
      "Epoch 1727 - loss: 1.5882287969133588 - val_loss: 1.3942791602441922\n",
      "Epoch 1728 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1729 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1730 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1731 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1732 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1733 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1734 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1735 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1736 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1737 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1738 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1739 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1740 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1741 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1742 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1743 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1744 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1745 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1746 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1747 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1748 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1749 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1750 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1751 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1752 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1753 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1754 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1755 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1756 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1757 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1758 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1759 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1760 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1761 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1762 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1763 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1764 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1765 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1766 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1767 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1768 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1769 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1770 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1771 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1772 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1773 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1774 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1775 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1776 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1777 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1778 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1779 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1780 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1781 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1782 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1783 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1784 - loss: 1.5877148353146349 - val_loss: 1.3963206044069998\n",
      "Epoch 1785 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1786 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1787 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1788 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1789 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1790 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1791 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1792 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1793 - loss: 1.587364776806824 - val_loss: 1.3965704843945712\n",
      "Epoch 1794 - loss: 1.5872908109002555 - val_loss: 1.405288577911579\n",
      "Epoch 1795 - loss: 1.5872908109002555 - val_loss: 1.405288577911579\n",
      "Epoch 1796 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1797 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1798 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1799 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1800 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1801 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1802 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1803 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1804 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1805 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1806 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1807 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1808 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1809 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1810 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1811 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1812 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1813 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1814 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1815 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1816 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1817 - loss: 1.5867100506575598 - val_loss: 1.3938844128442083\n",
      "Epoch 1818 - loss: 1.5865965442565646 - val_loss: 1.3958038407687527\n",
      "Epoch 1819 - loss: 1.5865965442565646 - val_loss: 1.3958038407687527\n",
      "Epoch 1820 - loss: 1.5864597096736035 - val_loss: 1.391565936310267\n",
      "Epoch 1821 - loss: 1.5864597096736035 - val_loss: 1.391565936310267\n",
      "Epoch 1822 - loss: 1.5862017395467638 - val_loss: 1.3924337237143682\n",
      "Epoch 1823 - loss: 1.5862017395467638 - val_loss: 1.3924337237143682\n",
      "Epoch 1824 - loss: 1.5862017395467638 - val_loss: 1.3924337237143682\n",
      "Epoch 1825 - loss: 1.5862017395467638 - val_loss: 1.3924337237143682\n",
      "Epoch 1826 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1827 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1828 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1829 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1830 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1831 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1832 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1833 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1834 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1835 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1836 - loss: 1.585954787361674 - val_loss: 1.3810002157590735\n",
      "Epoch 1837 - loss: 1.5858652674646028 - val_loss: 1.393871992174292\n",
      "Epoch 1838 - loss: 1.5858652674646028 - val_loss: 1.393871992174292\n",
      "Epoch 1839 - loss: 1.5858652674646028 - val_loss: 1.393871992174292\n",
      "Epoch 1840 - loss: 1.5858652674646028 - val_loss: 1.393871992174292\n",
      "Epoch 1841 - loss: 1.5858652674646028 - val_loss: 1.393871992174292\n",
      "Epoch 1842 - loss: 1.5858652674646028 - val_loss: 1.393871992174292\n",
      "Epoch 1843 - loss: 1.5858652674646028 - val_loss: 1.393871992174292\n",
      "Epoch 1844 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1845 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1846 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1847 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1848 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1849 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1850 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1851 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1852 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1853 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1854 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1855 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1856 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1857 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1858 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1859 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1860 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1861 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1862 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1863 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1864 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1865 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1866 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1867 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1868 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1869 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1870 - loss: 1.584520582251103 - val_loss: 1.4031067610714203\n",
      "Epoch 1871 - loss: 1.58420216043585 - val_loss: 1.4134689494418264\n",
      "Epoch 1872 - loss: 1.58420216043585 - val_loss: 1.4134689494418264\n",
      "Epoch 1873 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1874 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1875 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1876 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1877 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1878 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1879 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1880 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1881 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1882 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1883 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1884 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1885 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1886 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1887 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1888 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1889 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1890 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1891 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1892 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1893 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1894 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1895 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1896 - loss: 1.5834533558429873 - val_loss: 1.4012033178630017\n",
      "Epoch 1897 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1898 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1899 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1900 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1901 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1902 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1903 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1904 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1905 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1906 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1907 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1908 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1909 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1910 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1911 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1912 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1913 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1914 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1915 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1916 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1917 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1918 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1919 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1920 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1921 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1922 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1923 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1924 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1925 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1926 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1927 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1928 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1929 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1930 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1931 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1932 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1933 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1934 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1935 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1936 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1937 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1938 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1939 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1940 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1941 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1942 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1943 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1944 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1945 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1946 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1947 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1948 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1949 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1950 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1951 - loss: 1.5809171113227212 - val_loss: 1.3948385266069354\n",
      "Epoch 1952 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1953 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1954 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1955 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1956 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1957 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1958 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1959 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1960 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1961 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1962 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1963 - loss: 1.5800992610312556 - val_loss: 1.3947638620959\n",
      "Epoch 1964 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1965 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1966 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1967 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1968 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1969 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1970 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1971 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1972 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1973 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1974 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1975 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1976 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1977 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1978 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1979 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1980 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1981 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1982 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1983 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1984 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1985 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1986 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1987 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1988 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1989 - loss: 1.5796429133793373 - val_loss: 1.382650600873259\n",
      "Epoch 1990 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1991 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1992 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1993 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1994 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1995 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1996 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1997 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1998 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 1999 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 2000 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 2001 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 2002 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 2003 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 2004 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 2005 - loss: 1.578875380900198 - val_loss: 1.3786316446811473\n",
      "Epoch 2006 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2007 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2008 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2009 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2010 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2011 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2012 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2013 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2014 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2015 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2016 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2017 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2018 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2019 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2020 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2021 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2022 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2023 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2024 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2025 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2026 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2027 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2028 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2029 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2030 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2031 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2032 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2033 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2034 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2035 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2036 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2037 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2038 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2039 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2040 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2041 - loss: 1.577515469377503 - val_loss: 1.3820262076058842\n",
      "Epoch 2042 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2043 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2044 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2045 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2046 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2047 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2048 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2049 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2050 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2051 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2052 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2053 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2054 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2055 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2056 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2057 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2058 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2059 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2060 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2061 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2062 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2063 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2064 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2065 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2066 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2067 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2068 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2069 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2070 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2071 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2072 - loss: 1.576582822600041 - val_loss: 1.379375140348381\n",
      "Epoch 2073 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2074 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2075 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2076 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2077 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2078 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2079 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2080 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2081 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2082 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2083 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2084 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2085 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2086 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2087 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2088 - loss: 1.5760448099181064 - val_loss: 1.3685220815235426\n",
      "Epoch 2089 - loss: 1.5757596803440024 - val_loss: 1.3710288775113657\n",
      "Epoch 2090 - loss: 1.5757596803440024 - val_loss: 1.3710288775113657\n",
      "Epoch 2091 - loss: 1.5757596803440024 - val_loss: 1.3710288775113657\n",
      "Epoch 2092 - loss: 1.5757596803440024 - val_loss: 1.3710288775113657\n",
      "Epoch 2093 - loss: 1.5745429566747737 - val_loss: 1.3727699961498507\n",
      "Epoch 2094 - loss: 1.5745429566747737 - val_loss: 1.3727699961498507\n",
      "Epoch 2095 - loss: 1.5745429566747737 - val_loss: 1.3727699961498507\n",
      "Epoch 2096 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2097 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2098 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2099 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2100 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2101 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2102 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2103 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2104 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2105 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2106 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2107 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2108 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2109 - loss: 1.5745146283496647 - val_loss: 1.367702533132055\n",
      "Epoch 2110 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2111 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2112 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2113 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2114 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2115 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2116 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2117 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2118 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2119 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2120 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2121 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2122 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2123 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2124 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2125 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2126 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2127 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2128 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2129 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2130 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2131 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2132 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2133 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2134 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2135 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2136 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2137 - loss: 1.5738603999103171 - val_loss: 1.3763714163767315\n",
      "Epoch 2138 - loss: 1.573180087814976 - val_loss: 1.3515296257120644\n",
      "Epoch 2139 - loss: 1.573180087814976 - val_loss: 1.3515296257120644\n",
      "Epoch 2140 - loss: 1.573180087814976 - val_loss: 1.3515296257120644\n",
      "Epoch 2141 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2142 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2143 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2144 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2145 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2146 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2147 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2148 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2149 - loss: 1.5729154436153998 - val_loss: 1.3942633574091736\n",
      "Epoch 2150 - loss: 1.57288294976354 - val_loss: 1.3664410720075442\n",
      "Epoch 2151 - loss: 1.57288294976354 - val_loss: 1.3664410720075442\n",
      "Epoch 2152 - loss: 1.57288294976354 - val_loss: 1.3664410720075442\n",
      "Epoch 2153 - loss: 1.5723427867801285 - val_loss: 1.3602193086317906\n",
      "Epoch 2154 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2155 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2156 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2157 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2158 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2159 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2160 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2161 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2162 - loss: 1.5707965243041837 - val_loss: 1.367916348048245\n",
      "Epoch 2163 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2164 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2165 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2166 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2167 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2168 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2169 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2170 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2171 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2172 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2173 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2174 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2175 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2176 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2177 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2178 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2179 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2180 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2181 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2182 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2183 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2184 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2185 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2186 - loss: 1.570563230911838 - val_loss: 1.3512575740668005\n",
      "Epoch 2187 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2188 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2189 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2190 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2191 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2192 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2193 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2194 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2195 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2196 - loss: 1.5704727135564183 - val_loss: 1.3651934374320638\n",
      "Epoch 2197 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2198 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2199 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2200 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2201 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2202 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2203 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2204 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2205 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2206 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2207 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2208 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2209 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2210 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2211 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2212 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2213 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2214 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2215 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2216 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2217 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2218 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2219 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2220 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2221 - loss: 1.5696537633620546 - val_loss: 1.3614142895800385\n",
      "Epoch 2222 - loss: 1.5694723349524686 - val_loss: 1.3619969428617993\n",
      "Epoch 2223 - loss: 1.5694723349524686 - val_loss: 1.3619969428617993\n",
      "Epoch 2224 - loss: 1.5694723349524686 - val_loss: 1.3619969428617993\n",
      "Epoch 2225 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2226 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2227 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2228 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2229 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2230 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2231 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2232 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2233 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2234 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2235 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2236 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2237 - loss: 1.5691582326305606 - val_loss: 1.3518920660606217\n",
      "Epoch 2238 - loss: 1.5679719856885452 - val_loss: 1.357517687390613\n",
      "Epoch 2239 - loss: 1.5679719856885452 - val_loss: 1.357517687390613\n",
      "Epoch 2240 - loss: 1.5679719856885452 - val_loss: 1.357517687390613\n",
      "Epoch 2241 - loss: 1.5679719856885452 - val_loss: 1.357517687390613\n",
      "Epoch 2242 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2243 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2244 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2245 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2246 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2247 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2248 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2249 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2250 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2251 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2252 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2253 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2254 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2255 - loss: 1.5678387535322005 - val_loss: 1.3562706899495809\n",
      "Epoch 2256 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2257 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2258 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2259 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2260 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2261 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2262 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2263 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2264 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2265 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2266 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2267 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2268 - loss: 1.567509202280568 - val_loss: 1.3665762104205987\n",
      "Epoch 2269 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2270 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2271 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2272 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2273 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2274 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2275 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2276 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2277 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2278 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2279 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2280 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2281 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2282 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2283 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2284 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2285 - loss: 1.5673013392915758 - val_loss: 1.3415608126225949\n",
      "Epoch 2286 - loss: 1.567221932423831 - val_loss: 1.3599917622127142\n",
      "Epoch 2287 - loss: 1.567221932423831 - val_loss: 1.3599917622127142\n",
      "Epoch 2288 - loss: 1.567221932423831 - val_loss: 1.3599917622127142\n",
      "Epoch 2289 - loss: 1.567221932423831 - val_loss: 1.3599917622127142\n",
      "Epoch 2290 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2291 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2292 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2293 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2294 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2295 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2296 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2297 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2298 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2299 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2300 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2301 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2302 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2303 - loss: 1.5656952338544103 - val_loss: 1.3624315278317585\n",
      "Epoch 2304 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2305 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2306 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2307 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2308 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2309 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2310 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2311 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2312 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2313 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2314 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2315 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2316 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2317 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2318 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2319 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2320 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2321 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2322 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2323 - loss: 1.565435453775313 - val_loss: 1.3472290376902827\n",
      "Epoch 2324 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2325 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2326 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2327 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2328 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2329 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2330 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2331 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2332 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2333 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2334 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2335 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2336 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2337 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2338 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2339 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2340 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2341 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2342 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2343 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2344 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2345 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2346 - loss: 1.5649595238834075 - val_loss: 1.3739336176147945\n",
      "Epoch 2347 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2348 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2349 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2350 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2351 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2352 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2353 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2354 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2355 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2356 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2357 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2358 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2359 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2360 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2361 - loss: 1.564618393989928 - val_loss: 1.3705626597647815\n",
      "Epoch 2362 - loss: 1.5645828100656556 - val_loss: 1.3634595494291455\n",
      "Epoch 2363 - loss: 1.5645828100656556 - val_loss: 1.3634595494291455\n",
      "Epoch 2364 - loss: 1.5645828100656556 - val_loss: 1.3634595494291455\n",
      "Epoch 2365 - loss: 1.5645828100656556 - val_loss: 1.3634595494291455\n",
      "Epoch 2366 - loss: 1.5645828100656556 - val_loss: 1.3634595494291455\n",
      "Epoch 2367 - loss: 1.5645828100656556 - val_loss: 1.3634595494291455\n",
      "Epoch 2368 - loss: 1.5641625365543275 - val_loss: 1.361848630328406\n",
      "Epoch 2369 - loss: 1.5641625365543275 - val_loss: 1.361848630328406\n",
      "Epoch 2370 - loss: 1.5641625365543275 - val_loss: 1.361848630328406\n",
      "Epoch 2371 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2372 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2373 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2374 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2375 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2376 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2377 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2378 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2379 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2380 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2381 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2382 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2383 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2384 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2385 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2386 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2387 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2388 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2389 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2390 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2391 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2392 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2393 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2394 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2395 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2396 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2397 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2398 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2399 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2400 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2401 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2402 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2403 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2404 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2405 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2406 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2407 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2408 - loss: 1.5621032173642004 - val_loss: 1.3724389771220895\n",
      "Epoch 2409 - loss: 1.5617618107336222 - val_loss: 1.3591983412957955\n",
      "Epoch 2410 - loss: 1.5615659570619882 - val_loss: 1.3410703818692735\n",
      "Epoch 2411 - loss: 1.5615659570619882 - val_loss: 1.3410703818692735\n",
      "Epoch 2412 - loss: 1.5615659570619882 - val_loss: 1.3410703818692735\n",
      "Epoch 2413 - loss: 1.5615659570619882 - val_loss: 1.3410703818692735\n",
      "Epoch 2414 - loss: 1.5615659570619882 - val_loss: 1.3410703818692735\n",
      "Epoch 2415 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2416 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2417 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2418 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2419 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2420 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2421 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2422 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2423 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2424 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2425 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2426 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2427 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2428 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2429 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2430 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2431 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2432 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2433 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2434 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2435 - loss: 1.5614439455453963 - val_loss: 1.365460092874347\n",
      "Epoch 2436 - loss: 1.5609246493925848 - val_loss: 1.3294379724925294\n",
      "Epoch 2437 - loss: 1.5609246493925848 - val_loss: 1.3294379724925294\n",
      "Epoch 2438 - loss: 1.5609246493925848 - val_loss: 1.3294379724925294\n",
      "Epoch 2439 - loss: 1.5609246493925848 - val_loss: 1.3294379724925294\n",
      "Epoch 2440 - loss: 1.5609246493925848 - val_loss: 1.3294379724925294\n",
      "Epoch 2441 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2442 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2443 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2444 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2445 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2446 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2447 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2448 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2449 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2450 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2451 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2452 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2453 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2454 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2455 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2456 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2457 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2458 - loss: 1.5599133830263825 - val_loss: 1.3359290882803763\n",
      "Epoch 2459 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2460 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2461 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2462 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2463 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2464 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2465 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2466 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2467 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2468 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2469 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2470 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2471 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2472 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2473 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2474 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2475 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2476 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2477 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2478 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2479 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2480 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2481 - loss: 1.5597270103048169 - val_loss: 1.3522647415014457\n",
      "Epoch 2482 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2483 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2484 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2485 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2486 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2487 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2488 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2489 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2490 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2491 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2492 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2493 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2494 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2495 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2496 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2497 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2498 - loss: 1.5594848194698567 - val_loss: 1.350115356188767\n",
      "Epoch 2499 - loss: 1.558473087764596 - val_loss: 1.3613298436081642\n",
      "Epoch 2500 - loss: 1.558473087764596 - val_loss: 1.3613298436081642\n",
      "Epoch 2501 - loss: 1.558473087764596 - val_loss: 1.3613298436081642\n",
      "Epoch 2502 - loss: 1.558473087764596 - val_loss: 1.3613298436081642\n",
      "Epoch 2503 - loss: 1.558473087764596 - val_loss: 1.3613298436081642\n",
      "Epoch 2504 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2505 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2506 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2507 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2508 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2509 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2510 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2511 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2512 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2513 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2514 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2515 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2516 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2517 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2518 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2519 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2520 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2521 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2522 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2523 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2524 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2525 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2526 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2527 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2528 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2529 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2530 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2531 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2532 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2533 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2534 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2535 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2536 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2537 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2538 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2539 - loss: 1.5584244993394047 - val_loss: 1.3499486654276631\n",
      "Epoch 2540 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2541 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2542 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2543 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2544 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2545 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2546 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2547 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2548 - loss: 1.5584002023043626 - val_loss: 1.3688439154932524\n",
      "Epoch 2549 - loss: 1.557905464325448 - val_loss: 1.3701267708649914\n",
      "Epoch 2550 - loss: 1.557905464325448 - val_loss: 1.3701267708649914\n",
      "Epoch 2551 - loss: 1.557905464325448 - val_loss: 1.3701267708649914\n",
      "Epoch 2552 - loss: 1.557905464325448 - val_loss: 1.3701267708649914\n",
      "Epoch 2553 - loss: 1.557905464325448 - val_loss: 1.3701267708649914\n",
      "Epoch 2554 - loss: 1.557905464325448 - val_loss: 1.3701267708649914\n",
      "Epoch 2555 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2556 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2557 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2558 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2559 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2560 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2561 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2562 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2563 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2564 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2565 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2566 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2567 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2568 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2569 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2570 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2571 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2572 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2573 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2574 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2575 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2576 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2577 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2578 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2579 - loss: 1.5569057246740912 - val_loss: 1.3310911695559118\n",
      "Epoch 2580 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2581 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2582 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2583 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2584 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2585 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2586 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2587 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2588 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2589 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2590 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2591 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2592 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2593 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2594 - loss: 1.5563961744694315 - val_loss: 1.3563560728764141\n",
      "Epoch 2595 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2596 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2597 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2598 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2599 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2600 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2601 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2602 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2603 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2604 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2605 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2606 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2607 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2608 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2609 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2610 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2611 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2612 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2613 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2614 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2615 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2616 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2617 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2618 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2619 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2620 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2621 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2622 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2623 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2624 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2625 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2626 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2627 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2628 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2629 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2630 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2631 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2632 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2633 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2634 - loss: 1.5552105820665192 - val_loss: 1.351794120345545\n",
      "Epoch 2635 - loss: 1.5550931974759377 - val_loss: 1.3515422641632662\n",
      "Epoch 2636 - loss: 1.5550931974759377 - val_loss: 1.3515422641632662\n",
      "Epoch 2637 - loss: 1.5550931974759377 - val_loss: 1.3515422641632662\n",
      "Epoch 2638 - loss: 1.5550931974759377 - val_loss: 1.3515422641632662\n",
      "Epoch 2639 - loss: 1.5550931974759377 - val_loss: 1.3515422641632662\n",
      "Epoch 2640 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2641 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2642 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2643 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2644 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2645 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2646 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2647 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2648 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2649 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2650 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2651 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2652 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2653 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2654 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2655 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2656 - loss: 1.554777994940189 - val_loss: 1.361606326160278\n",
      "Epoch 2657 - loss: 1.5546114879558162 - val_loss: 1.3403047028027593\n",
      "Epoch 2658 - loss: 1.5537020935593076 - val_loss: 1.343732385692427\n",
      "Epoch 2659 - loss: 1.5537020935593076 - val_loss: 1.343732385692427\n",
      "Epoch 2660 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2661 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2662 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2663 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2664 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2665 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2666 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2667 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2668 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2669 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2670 - loss: 1.553456589492552 - val_loss: 1.3592594974186003\n",
      "Epoch 2671 - loss: 1.5534287597153176 - val_loss: 1.349661232605175\n",
      "Epoch 2672 - loss: 1.5534287597153176 - val_loss: 1.349661232605175\n",
      "Epoch 2673 - loss: 1.5534287597153176 - val_loss: 1.349661232605175\n",
      "Epoch 2674 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2675 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2676 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2677 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2678 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2679 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2680 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2681 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2682 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2683 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2684 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2685 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2686 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2687 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2688 - loss: 1.5526415955436637 - val_loss: 1.3544433209266433\n",
      "Epoch 2689 - loss: 1.5524552672687926 - val_loss: 1.3418883766063174\n",
      "Epoch 2690 - loss: 1.5524552672687926 - val_loss: 1.3418883766063174\n",
      "Epoch 2691 - loss: 1.5524552672687926 - val_loss: 1.3418883766063174\n",
      "Epoch 2692 - loss: 1.5524552672687926 - val_loss: 1.3418883766063174\n",
      "Epoch 2693 - loss: 1.5524552672687926 - val_loss: 1.3418883766063174\n",
      "Epoch 2694 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2695 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2696 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2697 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2698 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2699 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2700 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2701 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2702 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2703 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2704 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2705 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2706 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2707 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2708 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2709 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2710 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2711 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2712 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2713 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2714 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2715 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2716 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2717 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2718 - loss: 1.5512892988306577 - val_loss: 1.3433662090012952\n",
      "Epoch 2719 - loss: 1.5511113930844524 - val_loss: 1.3268620191680884\n",
      "Epoch 2720 - loss: 1.5511113930844524 - val_loss: 1.3268620191680884\n",
      "Epoch 2721 - loss: 1.5511113930844524 - val_loss: 1.3268620191680884\n",
      "Epoch 2722 - loss: 1.5511113930844524 - val_loss: 1.3268620191680884\n",
      "Epoch 2723 - loss: 1.5511113930844524 - val_loss: 1.3268620191680884\n",
      "Epoch 2724 - loss: 1.5511113930844524 - val_loss: 1.3268620191680884\n",
      "Epoch 2725 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2726 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2727 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2728 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2729 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2730 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2731 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2732 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2733 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2734 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2735 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2736 - loss: 1.5509583686378243 - val_loss: 1.3755210492106762\n",
      "Epoch 2737 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2738 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2739 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2740 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2741 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2742 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2743 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2744 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2745 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2746 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2747 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2748 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2749 - loss: 1.5508092854129407 - val_loss: 1.347663042607589\n",
      "Epoch 2750 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2751 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2752 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2753 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2754 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2755 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2756 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2757 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2758 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2759 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2760 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2761 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2762 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2763 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2764 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2765 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2766 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2767 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2768 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2769 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2770 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2771 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2772 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2773 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2774 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2775 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2776 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2777 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2778 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2779 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2780 - loss: 1.5503684777176796 - val_loss: 1.3592550818887978\n",
      "Epoch 2781 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2782 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2783 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2784 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2785 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2786 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2787 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2788 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2789 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2790 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2791 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2792 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2793 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2794 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2795 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2796 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2797 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2798 - loss: 1.5501830224513404 - val_loss: 1.3657874298516333\n",
      "Epoch 2799 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2800 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2801 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2802 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2803 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2804 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2805 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2806 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2807 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2808 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2809 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2810 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2811 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2812 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2813 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2814 - loss: 1.5498719501433857 - val_loss: 1.3598796253800658\n",
      "Epoch 2815 - loss: 1.5494832467618311 - val_loss: 1.3401901755194499\n",
      "Epoch 2816 - loss: 1.5494832467618311 - val_loss: 1.3401901755194499\n",
      "Epoch 2817 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2818 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2819 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2820 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2821 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2822 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2823 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2824 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2825 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2826 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2827 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2828 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2829 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2830 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2831 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2832 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2833 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2834 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2835 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2836 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2837 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2838 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2839 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2840 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2841 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2842 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2843 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2844 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2845 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2846 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2847 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2848 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2849 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2850 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2851 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2852 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2853 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2854 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2855 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2856 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2857 - loss: 1.5488820945679156 - val_loss: 1.3498621088106617\n",
      "Epoch 2858 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2859 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2860 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2861 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2862 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2863 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2864 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2865 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2866 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2867 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2868 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2869 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2870 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2871 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2872 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2873 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2874 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2875 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2876 - loss: 1.5480410687756607 - val_loss: 1.3595238959602014\n",
      "Epoch 2877 - loss: 1.5480200665634962 - val_loss: 1.3478229909913135\n",
      "Epoch 2878 - loss: 1.5480200665634962 - val_loss: 1.3478229909913135\n",
      "Epoch 2879 - loss: 1.5480200665634962 - val_loss: 1.3478229909913135\n",
      "Epoch 2880 - loss: 1.5480200665634962 - val_loss: 1.3478229909913135\n",
      "Epoch 2881 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2882 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2883 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2884 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2885 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2886 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2887 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2888 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2889 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2890 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2891 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2892 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2893 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2894 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2895 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2896 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2897 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2898 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2899 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2900 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2901 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2902 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2903 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2904 - loss: 1.5472726440601234 - val_loss: 1.361534530544385\n",
      "Epoch 2905 - loss: 1.5470738747735755 - val_loss: 1.3472224616177744\n",
      "Epoch 2906 - loss: 1.5470738747735755 - val_loss: 1.3472224616177744\n",
      "Epoch 2907 - loss: 1.5467655286946798 - val_loss: 1.3587130611676121\n",
      "Epoch 2908 - loss: 1.5467655286946798 - val_loss: 1.3587130611676121\n",
      "Epoch 2909 - loss: 1.5465063883981667 - val_loss: 1.3431249188959222\n",
      "Epoch 2910 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2911 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2912 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2913 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2914 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2915 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2916 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2917 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2918 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2919 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2920 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2921 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2922 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2923 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2924 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2925 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2926 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2927 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2928 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2929 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2930 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2931 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2932 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2933 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2934 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2935 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2936 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2937 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2938 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2939 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2940 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2941 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2942 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2943 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2944 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2945 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2946 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2947 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2948 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2949 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2950 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2951 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2952 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2953 - loss: 1.5454527136628116 - val_loss: 1.3560004980108187\n",
      "Epoch 2954 - loss: 1.545050455142064 - val_loss: 1.3482194369955756\n",
      "Epoch 2955 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2956 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2957 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2958 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2959 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2960 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2961 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2962 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2963 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2964 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2965 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2966 - loss: 1.5450065697787307 - val_loss: 1.3394859615901162\n",
      "Epoch 2967 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2968 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2969 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2970 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2971 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2972 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2973 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2974 - loss: 1.5445940020658602 - val_loss: 1.3635868123305865\n",
      "Epoch 2975 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846\n",
      "Epoch 2976 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846\n",
      "Epoch 2977 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846\n",
      "Epoch 2978 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846\n",
      "Epoch 2979 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846\n",
      "Epoch 2980 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846\n",
      "Epoch 2981 - loss: 1.5443913256851485 - val_loss: 1.3401448115996846\n",
      "Epoch 2982 - loss: 1.5443310784465387 - val_loss: 1.3466216330643277\n",
      "Epoch 2983 - loss: 1.5443310784465387 - val_loss: 1.3466216330643277\n",
      "Epoch 2984 - loss: 1.5443310784465387 - val_loss: 1.3466216330643277\n",
      "Epoch 2985 - loss: 1.5443310784465387 - val_loss: 1.3466216330643277\n",
      "Epoch 2986 - loss: 1.5443310784465387 - val_loss: 1.3466216330643277\n",
      "Epoch 2987 - loss: 1.5443310784465387 - val_loss: 1.3466216330643277\n",
      "Epoch 2988 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2989 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2990 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2991 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2992 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2993 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2994 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2995 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2996 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2997 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2998 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 2999 - loss: 1.5440519291121937 - val_loss: 1.322900116698893\n",
      "Epoch 3000 - loss: 1.5433577749164704 - val_loss: 1.3412658900669032\n",
      "Epoch 3001 - loss: 1.5433577749164704 - val_loss: 1.3412658900669032\n",
      "Epoch 3002 - loss: 1.5433577749164704 - val_loss: 1.3412658900669032\n",
      "Epoch 3003 - loss: 1.5433577749164704 - val_loss: 1.3412658900669032\n",
      "Epoch 3004 - loss: 1.5433577749164704 - val_loss: 1.3412658900669032\n",
      "Epoch 3005 - loss: 1.5433577749164704 - val_loss: 1.3412658900669032\n",
      "Epoch 3006 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3007 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3008 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3009 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3010 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3011 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3012 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3013 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3014 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3015 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3016 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3017 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3018 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3019 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3020 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3021 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3022 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3023 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3024 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3025 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3026 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3027 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3028 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3029 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3030 - loss: 1.5430200438076243 - val_loss: 1.323385008232178\n",
      "Epoch 3031 - loss: 1.5428267052781703 - val_loss: 1.3398620515160897\n",
      "Epoch 3032 - loss: 1.5428267052781703 - val_loss: 1.3398620515160897\n",
      "Epoch 3033 - loss: 1.5428267052781703 - val_loss: 1.3398620515160897\n",
      "Epoch 3034 - loss: 1.5428267052781703 - val_loss: 1.3398620515160897\n",
      "Epoch 3035 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3036 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3037 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3038 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3039 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3040 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3041 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3042 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3043 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3044 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3045 - loss: 1.5426259231716604 - val_loss: 1.3453130411301708\n",
      "Epoch 3046 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3047 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3048 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3049 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3050 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3051 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3052 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3053 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3054 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3055 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3056 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3057 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3058 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3059 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3060 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3061 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3062 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3063 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3064 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3065 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3066 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3067 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3068 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3069 - loss: 1.5425326670773387 - val_loss: 1.3428476678750014\n",
      "Epoch 3070 - loss: 1.5420186039470125 - val_loss: 1.3348140151035488\n",
      "Epoch 3071 - loss: 1.5420186039470125 - val_loss: 1.3348140151035488\n",
      "Epoch 3072 - loss: 1.5420186039470125 - val_loss: 1.3348140151035488\n",
      "Epoch 3073 - loss: 1.5420186039470125 - val_loss: 1.3348140151035488\n",
      "Epoch 3074 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3075 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3076 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3077 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3078 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3079 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3080 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3081 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3082 - loss: 1.5417683748236246 - val_loss: 1.3406302800142376\n",
      "Epoch 3083 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3084 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3085 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3086 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3087 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3088 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3089 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3090 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3091 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3092 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3093 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3094 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3095 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3096 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3097 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3098 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3099 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3100 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3101 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3102 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3103 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3104 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3105 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3106 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3107 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3108 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3109 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3110 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3111 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3112 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3113 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3114 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3115 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3116 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3117 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3118 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3119 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3120 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3121 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3122 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3123 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3124 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3125 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3126 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3127 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3128 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3129 - loss: 1.5404130982398399 - val_loss: 1.3239773005881847\n",
      "Epoch 3130 - loss: 1.540097868114943 - val_loss: 1.348944858849143\n",
      "Epoch 3131 - loss: 1.540097868114943 - val_loss: 1.348944858849143\n",
      "Epoch 3132 - loss: 1.540097868114943 - val_loss: 1.348944858849143\n",
      "Epoch 3133 - loss: 1.540097868114943 - val_loss: 1.348944858849143\n",
      "Epoch 3134 - loss: 1.540097868114943 - val_loss: 1.348944858849143\n",
      "Epoch 3135 - loss: 1.540097868114943 - val_loss: 1.348944858849143\n",
      "Epoch 3136 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3137 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3138 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3139 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3140 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3141 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3142 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3143 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3144 - loss: 1.5400052678056442 - val_loss: 1.3290895926669821\n",
      "Epoch 3145 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3146 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3147 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3148 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3149 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3150 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3151 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3152 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3153 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3154 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3155 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3156 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3157 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3158 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3159 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3160 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3161 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3162 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3163 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3164 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3165 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3166 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3167 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3168 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3169 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3170 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3171 - loss: 1.538906056093952 - val_loss: 1.3341935443537016\n",
      "Epoch 3172 - loss: 1.538825812803906 - val_loss: 1.3388292322709812\n",
      "Epoch 3173 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3174 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3175 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3176 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3177 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3178 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3179 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3180 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3181 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3182 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3183 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3184 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3185 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3186 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3187 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3188 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3189 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3190 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3191 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3192 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3193 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3194 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3195 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3196 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3197 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3198 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3199 - loss: 1.5381828062771037 - val_loss: 1.3432432023593404\n",
      "Epoch 3200 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3201 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3202 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3203 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3204 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3205 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3206 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3207 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3208 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3209 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3210 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3211 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3212 - loss: 1.5378941038523504 - val_loss: 1.3219851270094405\n",
      "Epoch 3213 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3214 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3215 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3216 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3217 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3218 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3219 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3220 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3221 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3222 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3223 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3224 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3225 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3226 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3227 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3228 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3229 - loss: 1.5372762532117008 - val_loss: 1.336156176223909\n",
      "Epoch 3230 - loss: 1.5366378782630943 - val_loss: 1.3269456203130479\n",
      "Epoch 3231 - loss: 1.5364623991683408 - val_loss: 1.3141104503132552\n",
      "Epoch 3232 - loss: 1.5364623991683408 - val_loss: 1.3141104503132552\n",
      "Epoch 3233 - loss: 1.5364623991683408 - val_loss: 1.3141104503132552\n",
      "Epoch 3234 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3235 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3236 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3237 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3238 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3239 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3240 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3241 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3242 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3243 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3244 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3245 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3246 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3247 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3248 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3249 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3250 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3251 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3252 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3253 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3254 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3255 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3256 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3257 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3258 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3259 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3260 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3261 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3262 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3263 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3264 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3265 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3266 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3267 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3268 - loss: 1.5358648069487544 - val_loss: 1.311986694021345\n",
      "Epoch 3269 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3270 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3271 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3272 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3273 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3274 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3275 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3276 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3277 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3278 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3279 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3280 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3281 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3282 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3283 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3284 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3285 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3286 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3287 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3288 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3289 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3290 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3291 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3292 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3293 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3294 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3295 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3296 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3297 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3298 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3299 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3300 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3301 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3302 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3303 - loss: 1.534926668314523 - val_loss: 1.327199462063306\n",
      "Epoch 3304 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3305 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3306 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3307 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3308 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3309 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3310 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3311 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3312 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3313 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3314 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3315 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3316 - loss: 1.5342528528081902 - val_loss: 1.30738835574831\n",
      "Epoch 3317 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3318 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3319 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3320 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3321 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3322 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3323 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3324 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3325 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3326 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3327 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3328 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3329 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3330 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3331 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3332 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3333 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3334 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3335 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3336 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3337 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3338 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3339 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3340 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3341 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3342 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3343 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3344 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3345 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3346 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3347 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3348 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3349 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3350 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3351 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3352 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3353 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3354 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3355 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3356 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3357 - loss: 1.5335719680800164 - val_loss: 1.3228671685760371\n",
      "Epoch 3358 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3359 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3360 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3361 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3362 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3363 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3364 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3365 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3366 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3367 - loss: 1.5331022066760174 - val_loss: 1.3102283529771568\n",
      "Epoch 3368 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3369 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3370 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3371 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3372 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3373 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3374 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3375 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3376 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3377 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3378 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3379 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3380 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3381 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3382 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3383 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3384 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3385 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3386 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3387 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3388 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3389 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3390 - loss: 1.5325887709842072 - val_loss: 1.3123486864137948\n",
      "Epoch 3391 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3392 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3393 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3394 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3395 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3396 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3397 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3398 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3399 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3400 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3401 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3402 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3403 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3404 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3405 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3406 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3407 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3408 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3409 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3410 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3411 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3412 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3413 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3414 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3415 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3416 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3417 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3418 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3419 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3420 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3421 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3422 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3423 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3424 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3425 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3426 - loss: 1.5322558143447993 - val_loss: 1.3170734681222287\n",
      "Epoch 3427 - loss: 1.532170640374761 - val_loss: 1.3088773334041348\n",
      "Epoch 3428 - loss: 1.532170640374761 - val_loss: 1.3088773334041348\n",
      "Epoch 3429 - loss: 1.532170640374761 - val_loss: 1.3088773334041348\n",
      "Epoch 3430 - loss: 1.532170640374761 - val_loss: 1.3088773334041348\n",
      "Epoch 3431 - loss: 1.532170640374761 - val_loss: 1.3088773334041348\n",
      "Epoch 3432 - loss: 1.532170640374761 - val_loss: 1.3088773334041348\n",
      "Epoch 3433 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3434 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3435 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3436 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3437 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3438 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3439 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3440 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3441 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3442 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3443 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3444 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3445 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3446 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3447 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3448 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3449 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3450 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3451 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3452 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3453 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3454 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3455 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3456 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3457 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3458 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3459 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3460 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3461 - loss: 1.5315528956576163 - val_loss: 1.3242612179778404\n",
      "Epoch 3462 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3463 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3464 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3465 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3466 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3467 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3468 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3469 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3470 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3471 - loss: 1.5313908809471382 - val_loss: 1.31008886880172\n",
      "Epoch 3472 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3473 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3474 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3475 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3476 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3477 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3478 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3479 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3480 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3481 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3482 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3483 - loss: 1.53067074969383 - val_loss: 1.315879124302905\n",
      "Epoch 3484 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3485 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3486 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3487 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3488 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3489 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3490 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3491 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3492 - loss: 1.530370074402697 - val_loss: 1.3207790992797501\n",
      "Epoch 3493 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3494 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3495 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3496 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3497 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3498 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3499 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3500 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3501 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3502 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3503 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3504 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3505 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3506 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3507 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3508 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3509 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3510 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3511 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3512 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3513 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3514 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3515 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3516 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3517 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3518 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3519 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3520 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3521 - loss: 1.5299584098680732 - val_loss: 1.3344207562235884\n",
      "Epoch 3522 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3523 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3524 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3525 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3526 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3527 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3528 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3529 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3530 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3531 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3532 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3533 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3534 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3535 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3536 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3537 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3538 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3539 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3540 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3541 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3542 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3543 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3544 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3545 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3546 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3547 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3548 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3549 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3550 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3551 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3552 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3553 - loss: 1.5292479037526214 - val_loss: 1.3164782571912574\n",
      "Epoch 3554 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3555 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3556 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3557 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3558 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3559 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3560 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3561 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3562 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3563 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3564 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3565 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3566 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3567 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3568 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3569 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3570 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3571 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3572 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3573 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3574 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3575 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3576 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3577 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3578 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3579 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3580 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3581 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3582 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3583 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3584 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3585 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3586 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3587 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3588 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3589 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3590 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3591 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3592 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3593 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3594 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3595 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3596 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3597 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3598 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3599 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3600 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3601 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3602 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3603 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3604 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3605 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3606 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3607 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3608 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3609 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3610 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3611 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3612 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3613 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3614 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3615 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3616 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3617 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3618 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3619 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3620 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3621 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3622 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3623 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3624 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3625 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3626 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3627 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3628 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3629 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3630 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3631 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3632 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3633 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3634 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3635 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3636 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3637 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3638 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3639 - loss: 1.5284014393563063 - val_loss: 1.3186999695547805\n",
      "Epoch 3640 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3641 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3642 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3643 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3644 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3645 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3646 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3647 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3648 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3649 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3650 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3651 - loss: 1.5275594407380195 - val_loss: 1.3001249197408475\n",
      "Epoch 3652 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3653 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3654 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3655 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3656 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3657 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3658 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3659 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3660 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3661 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3662 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3663 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3664 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3665 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3666 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3667 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3668 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3669 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3670 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3671 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3672 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3673 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3674 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3675 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3676 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3677 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3678 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3679 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3680 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3681 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3682 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3683 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3684 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3685 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3686 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3687 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3688 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3689 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3690 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3691 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3692 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3693 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3694 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3695 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3696 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3697 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3698 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3699 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3700 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3701 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3702 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3703 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3704 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3705 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3706 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3707 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3708 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3709 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3710 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3711 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3712 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3713 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3714 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3715 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3716 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3717 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3718 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3719 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3720 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3721 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3722 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3723 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3724 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3725 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3726 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3727 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3728 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3729 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3730 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3731 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3732 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3733 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3734 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3735 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3736 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3737 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3738 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3739 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3740 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3741 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3742 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3743 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3744 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3745 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3746 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3747 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3748 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3749 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3750 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3751 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3752 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3753 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3754 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3755 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3756 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3757 - loss: 1.5264058532547264 - val_loss: 1.311494474461461\n",
      "Epoch 3758 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3759 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3760 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3761 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3762 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3763 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3764 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3765 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3766 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3767 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3768 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3769 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3770 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3771 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3772 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3773 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3774 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3775 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3776 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3777 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3778 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3779 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3780 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3781 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3782 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3783 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3784 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3785 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3786 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3787 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3788 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3789 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3790 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3791 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3792 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3793 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3794 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3795 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3796 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3797 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3798 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3799 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3800 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3801 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3802 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3803 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3804 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3805 - loss: 1.5255292733831547 - val_loss: 1.3051115737204175\n",
      "Epoch 3806 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3807 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3808 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3809 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3810 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3811 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3812 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3813 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3814 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3815 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3816 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3817 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3818 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3819 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3820 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3821 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3822 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3823 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3824 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3825 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3826 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3827 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3828 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3829 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3830 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3831 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3832 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3833 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3834 - loss: 1.5247093601131163 - val_loss: 1.3175388457761998\n",
      "Epoch 3835 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3836 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3837 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3838 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3839 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3840 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3841 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3842 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3843 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3844 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3845 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3846 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3847 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3848 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3849 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3850 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3851 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3852 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3853 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3854 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3855 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3856 - loss: 1.5239959636703462 - val_loss: 1.3126530712527273\n",
      "Epoch 3857 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3858 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3859 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3860 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3861 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3862 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3863 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3864 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3865 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3866 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3867 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3868 - loss: 1.5239927181913642 - val_loss: 1.2997100577225424\n",
      "Epoch 3869 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3870 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3871 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3872 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3873 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3874 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3875 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3876 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3877 - loss: 1.5237842412108817 - val_loss: 1.2940101053435522\n",
      "Epoch 3878 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3879 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3880 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3881 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3882 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3883 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3884 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3885 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3886 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3887 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3888 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3889 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3890 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3891 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3892 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3893 - loss: 1.52356401259396 - val_loss: 1.3002191317782756\n",
      "Epoch 3894 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3895 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3896 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3897 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3898 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3899 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3900 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3901 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3902 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3903 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3904 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3905 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3906 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3907 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3908 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3909 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3910 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3911 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3912 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3913 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3914 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3915 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3916 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3917 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3918 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3919 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3920 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3921 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3922 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3923 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3924 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3925 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3926 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3927 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3928 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3929 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3930 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3931 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3932 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3933 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3934 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3935 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3936 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3937 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3938 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3939 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3940 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3941 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3942 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3943 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3944 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3945 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3946 - loss: 1.5231685556638184 - val_loss: 1.3006588463072515\n",
      "Epoch 3947 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3948 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3949 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3950 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3951 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3952 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3953 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3954 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3955 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3956 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3957 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3958 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3959 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3960 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3961 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3962 - loss: 1.5225105755410904 - val_loss: 1.30735245729511\n",
      "Epoch 3963 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3964 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3965 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3966 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3967 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3968 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3969 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3970 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3971 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3972 - loss: 1.5221793421142755 - val_loss: 1.2992418905430654\n",
      "Epoch 3973 - loss: 1.5220082132768606 - val_loss: 1.3042830884535657\n",
      "Epoch 3974 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3975 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3976 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3977 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3978 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3979 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3980 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3981 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3982 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3983 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3984 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3985 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3986 - loss: 1.521854410358196 - val_loss: 1.296375638133106\n",
      "Epoch 3987 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3988 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3989 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3990 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3991 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3992 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3993 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3994 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3995 - loss: 1.521676187138161 - val_loss: 1.299705876528199\n",
      "Epoch 3996 - loss: 1.5214498907035865 - val_loss: 1.2958707280956148\n",
      "Epoch 3997 - loss: 1.5214498907035865 - val_loss: 1.2958707280956148\n",
      "Epoch 3998 - loss: 1.5214498907035865 - val_loss: 1.2958707280956148\n",
      "Epoch 3999 - loss: 1.5214498907035865 - val_loss: 1.2958707280956148\n",
      "Epoch 4000 - loss: 1.5214498907035865 - val_loss: 1.2958707280956148\n",
      "Epoch 4001 - loss: 1.5214498907035865 - val_loss: 1.2958707280956148\n",
      "Epoch 4002 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4003 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4004 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4005 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4006 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4007 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4008 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4009 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4010 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4011 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4012 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4013 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4014 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4015 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4016 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4017 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4018 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4019 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4020 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4021 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4022 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4023 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4024 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4025 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4026 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4027 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4028 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4029 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4030 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4031 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4032 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4033 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4034 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4035 - loss: 1.5210581242360743 - val_loss: 1.2997611027917175\n",
      "Epoch 4036 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4037 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4038 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4039 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4040 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4041 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4042 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4043 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4044 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4045 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4046 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4047 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4048 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4049 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4050 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4051 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4052 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4053 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4054 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4055 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4056 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4057 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4058 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4059 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4060 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4061 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4062 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4063 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4064 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4065 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4066 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4067 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4068 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4069 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4070 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4071 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4072 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4073 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4074 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4075 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4076 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4077 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4078 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4079 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4080 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4081 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4082 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4083 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4084 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4085 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4086 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4087 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4088 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4089 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4090 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4091 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4092 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4093 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4094 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4095 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4096 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4097 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4098 - loss: 1.5191746451317272 - val_loss: 1.3068333212091443\n",
      "Epoch 4099 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4100 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4101 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4102 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4103 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4104 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4105 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4106 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4107 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4108 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4109 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4110 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4111 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4112 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4113 - loss: 1.5191457619815516 - val_loss: 1.3028193793607739\n",
      "Epoch 4114 - loss: 1.5185037806662043 - val_loss: 1.2980556150709521\n",
      "Epoch 4115 - loss: 1.5185037806662043 - val_loss: 1.2980556150709521\n",
      "Epoch 4116 - loss: 1.5185037806662043 - val_loss: 1.2980556150709521\n",
      "Epoch 4117 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4118 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4119 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4120 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4121 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4122 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4123 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4124 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4125 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4126 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4127 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4128 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4129 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4130 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4131 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4132 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4133 - loss: 1.5181972254280898 - val_loss: 1.3017513804688978\n",
      "Epoch 4134 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4135 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4136 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4137 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4138 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4139 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4140 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4141 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4142 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4143 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4144 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4145 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4146 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4147 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4148 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4149 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4150 - loss: 1.5174934102837228 - val_loss: 1.302223129966856\n",
      "Epoch 4151 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4152 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4153 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4154 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4155 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4156 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4157 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4158 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4159 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4160 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4161 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4162 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4163 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4164 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4165 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4166 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4167 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4168 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4169 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4170 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4171 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4172 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4173 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4174 - loss: 1.516925945664128 - val_loss: 1.2971435214958875\n",
      "Epoch 4175 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4176 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4177 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4178 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4179 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4180 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4181 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4182 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4183 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4184 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4185 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4186 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4187 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4188 - loss: 1.516832342710414 - val_loss: 1.2929701543790513\n",
      "Epoch 4189 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182\n",
      "Epoch 4190 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182\n",
      "Epoch 4191 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182\n",
      "Epoch 4192 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182\n",
      "Epoch 4193 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182\n",
      "Epoch 4194 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182\n",
      "Epoch 4195 - loss: 1.5165436894027138 - val_loss: 1.2991930550444182\n",
      "Epoch 4196 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4197 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4198 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4199 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4200 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4201 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4202 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4203 - loss: 1.5164900718418224 - val_loss: 1.2994433031208916\n",
      "Epoch 4204 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4205 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4206 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4207 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4208 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4209 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4210 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4211 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4212 - loss: 1.51579698542343 - val_loss: 1.2988034783434448\n",
      "Epoch 4213 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4214 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4215 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4216 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4217 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4218 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4219 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4220 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4221 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4222 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4223 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4224 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4225 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4226 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4227 - loss: 1.5156848448057927 - val_loss: 1.3011599745485305\n",
      "Epoch 4228 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4229 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4230 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4231 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4232 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4233 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4234 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4235 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4236 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4237 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4238 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4239 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4240 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4241 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4242 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4243 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4244 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4245 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4246 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4247 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4248 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4249 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4250 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4251 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4252 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4253 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4254 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4255 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4256 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4257 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4258 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4259 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4260 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4261 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4262 - loss: 1.5153456642810426 - val_loss: 1.3013792678330507\n",
      "Epoch 4263 - loss: 1.5152437421558547 - val_loss: 1.3080832720925255\n",
      "Epoch 4264 - loss: 1.5152437421558547 - val_loss: 1.3080832720925255\n",
      "Epoch 4265 - loss: 1.5152437421558547 - val_loss: 1.3080832720925255\n",
      "Epoch 4266 - loss: 1.5152437421558547 - val_loss: 1.3080832720925255\n",
      "Epoch 4267 - loss: 1.5152437421558547 - val_loss: 1.3080832720925255\n",
      "Epoch 4268 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4269 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4270 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4271 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4272 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4273 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4274 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4275 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4276 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4277 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4278 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4279 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4280 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4281 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4282 - loss: 1.515242670143588 - val_loss: 1.3092840476949146\n",
      "Epoch 4283 - loss: 1.5148942393023568 - val_loss: 1.3065510102969256\n",
      "Epoch 4284 - loss: 1.5148942393023568 - val_loss: 1.3065510102969256\n",
      "Epoch 4285 - loss: 1.5148942393023568 - val_loss: 1.3065510102969256\n",
      "Epoch 4286 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4287 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4288 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4289 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4290 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4291 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4292 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4293 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4294 - loss: 1.5145850236623843 - val_loss: 1.299028914466481\n",
      "Epoch 4295 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4296 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4297 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4298 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4299 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4300 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4301 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4302 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4303 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4304 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4305 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4306 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4307 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4308 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4309 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4310 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4311 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4312 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4313 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4314 - loss: 1.5139961060932385 - val_loss: 1.2957420932572017\n",
      "Epoch 4315 - loss: 1.513891937956392 - val_loss: 1.298137156801345\n",
      "Epoch 4316 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4317 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4318 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4319 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4320 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4321 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4322 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4323 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4324 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4325 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4326 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4327 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4328 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4329 - loss: 1.5134471512593723 - val_loss: 1.2928967481100222\n",
      "Epoch 4330 - loss: 1.513382280229381 - val_loss: 1.300556329033807\n",
      "Epoch 4331 - loss: 1.513382280229381 - val_loss: 1.300556329033807\n",
      "Epoch 4332 - loss: 1.513382280229381 - val_loss: 1.300556329033807\n",
      "Epoch 4333 - loss: 1.513382280229381 - val_loss: 1.300556329033807\n",
      "Epoch 4334 - loss: 1.513382280229381 - val_loss: 1.300556329033807\n",
      "Epoch 4335 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4336 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4337 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4338 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4339 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4340 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4341 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4342 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4343 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4344 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4345 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4346 - loss: 1.5133642616806178 - val_loss: 1.2916160586917733\n",
      "Epoch 4347 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4348 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4349 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4350 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4351 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4352 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4353 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4354 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4355 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4356 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4357 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4358 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4359 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4360 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4361 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4362 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4363 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4364 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4365 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4366 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4367 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4368 - loss: 1.512580323942462 - val_loss: 1.3089504556825093\n",
      "Epoch 4369 - loss: 1.5125366500400963 - val_loss: 1.2931841025641357\n",
      "Epoch 4370 - loss: 1.5125366500400963 - val_loss: 1.2931841025641357\n",
      "Epoch 4371 - loss: 1.5125217931843176 - val_loss: 1.3008091703251827\n",
      "Epoch 4372 - loss: 1.5125217931843176 - val_loss: 1.3008091703251827\n",
      "Epoch 4373 - loss: 1.5125217931843176 - val_loss: 1.3008091703251827\n",
      "Epoch 4374 - loss: 1.5125217931843176 - val_loss: 1.3008091703251827\n",
      "Epoch 4375 - loss: 1.5125217931843176 - val_loss: 1.3008091703251827\n",
      "Epoch 4376 - loss: 1.5121335510237215 - val_loss: 1.3015006564554483\n",
      "Epoch 4377 - loss: 1.5121335510237215 - val_loss: 1.3015006564554483\n",
      "Epoch 4378 - loss: 1.5119658458277694 - val_loss: 1.2900086225192033\n",
      "Epoch 4379 - loss: 1.5119658458277694 - val_loss: 1.2900086225192033\n",
      "Epoch 4380 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4381 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4382 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4383 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4384 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4385 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4386 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4387 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4388 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4389 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4390 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4391 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4392 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4393 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4394 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4395 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4396 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4397 - loss: 1.5115192720413546 - val_loss: 1.2980950111816867\n",
      "Epoch 4398 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4399 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4400 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4401 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4402 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4403 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4404 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4405 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4406 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4407 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4408 - loss: 1.5114496678468028 - val_loss: 1.297034011870862\n",
      "Epoch 4409 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4410 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4411 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4412 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4413 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4414 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4415 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4416 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4417 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4418 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4419 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4420 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4421 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4422 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4423 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4424 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4425 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4426 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4427 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4428 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4429 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4430 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4431 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4432 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4433 - loss: 1.511186739605909 - val_loss: 1.2988388980998415\n",
      "Epoch 4434 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4435 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4436 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4437 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4438 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4439 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4440 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4441 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4442 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4443 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4444 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4445 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4446 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4447 - loss: 1.5108297096039132 - val_loss: 1.2962030832760063\n",
      "Epoch 4448 - loss: 1.5107704102709076 - val_loss: 1.297934057752117\n",
      "Epoch 4449 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968\n",
      "Epoch 4450 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968\n",
      "Epoch 4451 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968\n",
      "Epoch 4452 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968\n",
      "Epoch 4453 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968\n",
      "Epoch 4454 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968\n",
      "Epoch 4455 - loss: 1.5104334021193058 - val_loss: 1.2977668228632968\n",
      "Epoch 4456 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4457 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4458 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4459 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4460 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4461 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4462 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4463 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4464 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4465 - loss: 1.5102090745586767 - val_loss: 1.291476997404381\n",
      "Epoch 4466 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4467 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4468 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4469 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4470 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4471 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4472 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4473 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4474 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4475 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4476 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4477 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4478 - loss: 1.5100613526521611 - val_loss: 1.291202396889054\n",
      "Epoch 4479 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693\n",
      "Epoch 4480 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693\n",
      "Epoch 4481 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693\n",
      "Epoch 4482 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693\n",
      "Epoch 4483 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693\n",
      "Epoch 4484 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693\n",
      "Epoch 4485 - loss: 1.5099036950776097 - val_loss: 1.2945810632929693\n",
      "Epoch 4486 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4487 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4488 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4489 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4490 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4491 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4492 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4493 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4494 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4495 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4496 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4497 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4498 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4499 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4500 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4501 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4502 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4503 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4504 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4505 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4506 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4507 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4508 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4509 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4510 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4511 - loss: 1.509853642010719 - val_loss: 1.2913891725156106\n",
      "Epoch 4512 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4513 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4514 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4515 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4516 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4517 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4518 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4519 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4520 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4521 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4522 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4523 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4524 - loss: 1.5098363393918206 - val_loss: 1.2962152874291264\n",
      "Epoch 4525 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4526 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4527 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4528 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4529 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4530 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4531 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4532 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4533 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4534 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4535 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4536 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4537 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4538 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4539 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4540 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4541 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4542 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4543 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4544 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4545 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4546 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4547 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4548 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4549 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4550 - loss: 1.5090542040130326 - val_loss: 1.2947575803667841\n",
      "Epoch 4551 - loss: 1.508909006649633 - val_loss: 1.2791477621236889\n",
      "Epoch 4552 - loss: 1.508865963767768 - val_loss: 1.3106510429499445\n",
      "Epoch 4553 - loss: 1.508865963767768 - val_loss: 1.3106510429499445\n",
      "Epoch 4554 - loss: 1.508865963767768 - val_loss: 1.3106510429499445\n",
      "Epoch 4555 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4556 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4557 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4558 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4559 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4560 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4561 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4562 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4563 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4564 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4565 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4566 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4567 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4568 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4569 - loss: 1.5081931893822755 - val_loss: 1.3006985727156593\n",
      "Epoch 4570 - loss: 1.5081687463813689 - val_loss: 1.2845910762198764\n",
      "Epoch 4571 - loss: 1.5081687463813689 - val_loss: 1.2845910762198764\n",
      "Epoch 4572 - loss: 1.5080982097189148 - val_loss: 1.283732370635203\n",
      "Epoch 4573 - loss: 1.5080982097189148 - val_loss: 1.283732370635203\n",
      "Epoch 4574 - loss: 1.5080982097189148 - val_loss: 1.283732370635203\n",
      "Epoch 4575 - loss: 1.5080871613938927 - val_loss: 1.283296489881322\n",
      "Epoch 4576 - loss: 1.5080871613938927 - val_loss: 1.283296489881322\n",
      "Epoch 4577 - loss: 1.5080871613938927 - val_loss: 1.283296489881322\n",
      "Epoch 4578 - loss: 1.5080871613938927 - val_loss: 1.283296489881322\n",
      "Epoch 4579 - loss: 1.5080871613938927 - val_loss: 1.283296489881322\n",
      "Epoch 4580 - loss: 1.5073057507144547 - val_loss: 1.2893112008414345\n",
      "Epoch 4581 - loss: 1.5073057507144547 - val_loss: 1.2893112008414345\n",
      "Epoch 4582 - loss: 1.5073057507144547 - val_loss: 1.2893112008414345\n",
      "Epoch 4583 - loss: 1.5073057507144547 - val_loss: 1.2893112008414345\n",
      "Epoch 4584 - loss: 1.5073057507144547 - val_loss: 1.2893112008414345\n",
      "Epoch 4585 - loss: 1.5073057507144547 - val_loss: 1.2893112008414345\n",
      "Epoch 4586 - loss: 1.5072098196960784 - val_loss: 1.2926466911640748\n",
      "Epoch 4587 - loss: 1.5072098196960784 - val_loss: 1.2926466911640748\n",
      "Epoch 4588 - loss: 1.5072098196960784 - val_loss: 1.2926466911640748\n",
      "Epoch 4589 - loss: 1.5072098196960784 - val_loss: 1.2926466911640748\n",
      "Epoch 4590 - loss: 1.5072098196960784 - val_loss: 1.2926466911640748\n",
      "Epoch 4591 - loss: 1.507003036716309 - val_loss: 1.2851665934640484\n",
      "Epoch 4592 - loss: 1.507003036716309 - val_loss: 1.2851665934640484\n",
      "Epoch 4593 - loss: 1.507003036716309 - val_loss: 1.2851665934640484\n",
      "Epoch 4594 - loss: 1.507003036716309 - val_loss: 1.2851665934640484\n",
      "Epoch 4595 - loss: 1.507003036716309 - val_loss: 1.2851665934640484\n",
      "Epoch 4596 - loss: 1.507003036716309 - val_loss: 1.2851665934640484\n",
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 18.2073 s\n",
      "File: /var/folders/xz/f2gwbn5n3vs4pz044n49z3cw0000gn/T/ipykernel_64896/4277616147.py\n",
      "Function: fit at line 24\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    24                                               def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0, lr_sigma = \"old\"):\n",
      "    25                                           \n",
      "    26         1          5.0      5.0      0.0          if self.random_state != None:\n",
      "    27         1        130.0    130.0      0.0              np.random.seed(self.random_state)\n",
      "    28                                           \n",
      "    29         1          1.0      1.0      0.0          if validation_data:\n",
      "    30         1          0.0      0.0      0.0              X_val, y_val = validation_data\n",
      "    31                                           \n",
      "    32         1          1.0      1.0      0.0          if self.activation == \"sigmoid\":\n",
      "    33                                                       activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
      "    34         1          0.0      0.0      0.0          elif self.activation == \"leaky_relu\":\n",
      "    35                                                       activation_function = lambda x: np.maximum(0.1 * x, x)\n",
      "    36                                                   else:\n",
      "    37         1          1.0      1.0      0.0              activation_function = lambda x: np.maximum(0, x)\n",
      "    38                                                       #activation_function = lambda x: (abs(x) + x) / 2\n",
      "    39                                                       #def activation_function(x):\n",
      "    40                                                       #    x[x < 0] = 0\n",
      "    41                                                       #activation_function = lambda x: np.maximum(x, 0, x)\n",
      "    42                                           \n",
      "    43         1        550.0    550.0      0.0          X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
      "    44                                           \n",
      "    45         1          1.0      1.0      0.0          n = self.n\n",
      "    46         1          0.0      0.0      0.0          n_parts = self.n_parts\n",
      "    47         1          1.0      1.0      0.0          n_div_parts = n // n_parts\n",
      "    48                                           \n",
      "    49         1          1.0      1.0      0.0          lr_decay = self.lr_decay\n",
      "    50                                           \n",
      "    51         1          1.0      1.0      0.0          layers = [X_train.shape[1]] + self.layers\n",
      "    52         1          1.0      1.0      0.0          number_of_layers_minus_one = len(layers) - 1\n",
      "    53         1         71.0     71.0      0.0          y_preds = np.zeros((n, y_train.shape[0]))\n",
      "    54         1          3.0      3.0      0.0          nets_loss = np.zeros(n)\n",
      "    55         1          6.0      6.0      0.0          sorted_indecies = np.arange(-(n // 2), n, 1)\n",
      "    56                                                   #sorted_indecies = np.zeros(n)\n",
      "    57         1          0.0      0.0      0.0          best_net_index = -1\n",
      "    58         1          1.0      1.0      0.0          weights = []\n",
      "    59                                           \n",
      "    60                                           \n",
      "    61         3          3.0      1.0      0.0          for i in range(number_of_layers_minus_one):\n",
      "    62                                                       #weights += [np.random.uniform(-3, 3, (n, layers[i], layers[i + 1]))]\n",
      "    63         2       1874.0    937.0      0.0              weights += [np.random.normal(0, 2, (n, layers[i], layers[i + 1]))]\n",
      "    64                                           \n",
      "    65      4598       3251.0      0.7      0.0          for epoch in range(epochs):\n",
      "    66      4598      35461.0      7.7      0.2              forward_pass = X_train.T\n",
      "    67                                                       \n",
      "    68      9195      11212.0      1.2      0.1              for j in range(number_of_layers_minus_one - 1):\n",
      "    69      4598   10866811.0   2363.4     59.7                  forward_pass = activation_function(weights[j][sorted_indecies[n_div_parts:]].transpose(0, 2, 1) @ forward_pass)\n",
      "    70                                                           #forward_pass = activation_function(weights[j].transpose(0, 2, 1) @ forward_pass)\n",
      "    71                                           \n",
      "    72      4597    1867961.0    406.3     10.3              forward_pass = weights[-1][sorted_indecies[n_div_parts:]].transpose(0, 2, 1) @ forward_pass\n",
      "    73                                                       #forward_pass = weights[-1].transpose(0, 2, 1) @ forward_pass\n",
      "    74                                                       \n",
      "    75      4597     242113.0     52.7      1.3              y_preds[sorted_indecies[n_div_parts:]] = forward_pass.reshape(*forward_pass.shape[::2])\n",
      "    76                                                       #y_preds = forward_pass.reshape(n, -1)\n",
      "    77                                           \n",
      "    78      4597    1146614.0    249.4      6.3              nets_loss[sorted_indecies[n_div_parts:]] = np.mean(np.abs(y_preds[sorted_indecies[n_div_parts:]] - y_train), axis = 1)\n",
      "    79                                           \n",
      "    80      4597      82526.0     18.0      0.5              sorted_indecies = np.argsort(nets_loss)\n",
      "    81                                           \n",
      "    82                                                       #mutation_sigma = 0.1 + 5 * 1 / math.exp(epoch / ((epochs + 1) / (100 * math.log10(epochs + 1))))\n",
      "    83      4597       4537.0      1.0      0.0              if lr_sigma == \"old\":\n",
      "    84                                                           mutation_sigma = lr_min + 1 * 1 / math.exp(epoch / ((epochs + 1) / (lr_decay * math.log10(epochs + 1))))\n",
      "    85      4597       2828.0      0.6      0.0              if lr_sigma == \"new\":\n",
      "    86                                                           mutation_sigma = math.exp(-(epoch + 1) * (math.log10((epochs + 1)) / ((epochs + 1) / 10))) + 0.1 * math.exp(-(epoch + 1) * (1 / (epochs + 1)))\n",
      "    87      4597       2834.0      0.6      0.0              if lr_sigma == \"mix\":\n",
      "    88      4597      18557.0      4.0      0.1                  mutation_sigma = math.exp(-epoch / (epochs / (lr_decay * math.log10(epochs + 1)))) + 0.02 * math.exp(-(epoch + 1) * (1 / (epochs + 1))) - 0.005\n",
      "    89                                           \n",
      "    90     13791      15945.0      1.2      0.1              for j in range(number_of_layers_minus_one):\n",
      "    91                                                           #print(weights[j][sorted_indecies[0 + n // 4::4]].shape, weights[j][sorted_indecies[:n // 4:2]].shape, weights[j][sorted_indecies[1:1 + n // 4:2]].shape)\n",
      "    92                                                           #print(sorted_indecies)\n",
      "    93                                                           #print(sorted_indecies[0 + n // 4::4], sorted_indecies[:n // 4:2], sorted_indecies[1:1 + n // 4:2])\n",
      "    94                                                           \n",
      "    95      9194       5776.0      0.6      0.0                  if n_parts == 2:\n",
      "    96                                                               weights[j][sorted_indecies[n_div_parts::2]] = (weights[j][sorted_indecies[:n_div_parts:2]] + weights[j][sorted_indecies[1:1 + n_div_parts:2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
      "    97                                                               weights[j][sorted_indecies[1 + n_div_parts::2]] = (weights[j][sorted_indecies[:n_div_parts:2]] + weights[j][sorted_indecies[1:1 + n_div_parts:2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
      "    98      9194       5463.0      0.6      0.0                  if n_parts == 4:\n",
      "    99      9194     666225.0     72.5      3.7                      weights[j][sorted_indecies[0 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
      "   100      9194     536225.0     58.3      2.9                      weights[j][sorted_indecies[1 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
      "   101      9194     527794.0     57.4      2.9                      weights[j][sorted_indecies[2 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
      "   102      9194     528918.0     57.5      2.9                      weights[j][sorted_indecies[3 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
      "   103      9194     522960.0     56.9      2.9                      weights[j][sorted_indecies[4 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
      "   104      9194     517718.0     56.3      2.8                      weights[j][sorted_indecies[5 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
      "   105                                           \n",
      "   106      4597       5047.0      1.1      0.0              if best_net_index != sorted_indecies[0] or 1 == 1:\n",
      "   107      4597       3201.0      0.7      0.0                  best_net_index = sorted_indecies[0]\n",
      "   108                                                       \n",
      "   109      4597       9514.0      2.1      0.1                  self.training_loss_history += [nets_loss[best_net_index]]\n",
      "   110                                                           \n",
      "   111                                           \n",
      "   112      4597       5052.0      1.1      0.0                  self.best_net_weights = []\n",
      "   113     13791       9845.0      0.7      0.1                  for j in range(number_of_layers_minus_one):\n",
      "   114      9194       8846.0      1.0      0.0                      self.best_net_weights += [weights[j][best_net_index]]\n",
      "   115                                                           \n",
      "   116      4597       3159.0      0.7      0.0                  if validation_data:\n",
      "   117      4597     465806.0    101.3      2.6                      self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
      "   118      4597       3357.0      0.7      0.0                      if verbose == 1:\n",
      "   119      4597      79093.0     17.2      0.4                          print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]}\")\n",
      "   120                                                           else:\n",
      "   121                                                               if verbose == 1:\n",
      "   122                                                                   pass\n",
      "   123                                                                   print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]}\")\n",
      "   124                                                       \n",
      "   125                                                   return self.training_loss_history"
     ]
    }
   ],
   "source": [
    "%reload_ext line_profiler\n",
    "\n",
    "class VectorizedEvoRegressor2:\n",
    "    def __init__(self, n = 20, hidden_layers = False, activation = \"relu\", n_parts = 4, lr_decay = 20, random_state = None):\n",
    "\n",
    "        self.n = n // 2 * 2\n",
    "        self.validation_loss_history = []\n",
    "        self.training_loss_history = []\n",
    "        self.random_state = random_state\n",
    "        self.activation = activation\n",
    "        self.number_of_layers = 0\n",
    "        self.lr_decay = lr_decay\n",
    "        \n",
    "        if hidden_layers:\n",
    "            self.layers = hidden_layers + [1]\n",
    "        else:\n",
    "            self.layers = [1]\n",
    "\n",
    "        if n_parts == 2 or n_parts == 4:\n",
    "            self.n_parts = int(n_parts)\n",
    "        else:\n",
    "            self.n_parts = 4\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs = 100, validation_data = False, verbose = 0, lr_sigma = \"old\"):\n",
    "\n",
    "        if self.random_state != None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        if validation_data:\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == \"leaky_relu\":\n",
    "            activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        else:\n",
    "            activation_function = lambda x: np.maximum(0, x)\n",
    "            #activation_function = lambda x: (abs(x) + x) / 2\n",
    "            #def activation_function(x):\n",
    "            #    x[x < 0] = 0\n",
    "            #activation_function = lambda x: np.maximum(x, 0, x)\n",
    "\n",
    "        X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "\n",
    "        n = self.n\n",
    "        n_parts = self.n_parts\n",
    "        n_div_parts = n // n_parts\n",
    "\n",
    "        lr_decay = self.lr_decay\n",
    "\n",
    "        layers = [X_train.shape[1]] + self.layers\n",
    "        number_of_layers_minus_one = len(layers) - 1\n",
    "        y_preds = np.zeros((n, y_train.shape[0]))\n",
    "        nets_loss = np.zeros(n)\n",
    "        sorted_indecies = np.arange(-(n // 2), n, 1)\n",
    "        #sorted_indecies = np.zeros(n)\n",
    "        best_net_index = -1\n",
    "        weights = []\n",
    "\n",
    "\n",
    "        for i in range(number_of_layers_minus_one):\n",
    "            #weights += [np.random.uniform(-3, 3, (n, layers[i], layers[i + 1]))]\n",
    "            weights += [np.random.normal(0, 2, (n, layers[i], layers[i + 1]))]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            forward_pass = X_train.T\n",
    "            \n",
    "            for j in range(number_of_layers_minus_one - 1):\n",
    "                forward_pass = activation_function(weights[j][sorted_indecies[n_div_parts:]].transpose(0, 2, 1) @ forward_pass)\n",
    "                #forward_pass = activation_function(weights[j].transpose(0, 2, 1) @ forward_pass)\n",
    "\n",
    "            forward_pass = weights[-1][sorted_indecies[n_div_parts:]].transpose(0, 2, 1) @ forward_pass\n",
    "            #forward_pass = weights[-1].transpose(0, 2, 1) @ forward_pass\n",
    "            \n",
    "            y_preds[sorted_indecies[n_div_parts:]] = forward_pass.reshape(*forward_pass.shape[::2])\n",
    "            #y_preds = forward_pass.reshape(n, -1)\n",
    "\n",
    "            nets_loss[sorted_indecies[n_div_parts:]] = np.mean(np.abs(y_preds[sorted_indecies[n_div_parts:]] - y_train), axis = 1)\n",
    "\n",
    "            sorted_indecies = np.argsort(nets_loss)\n",
    "\n",
    "            #mutation_sigma = 0.1 + 5 * 1 / math.exp(epoch / ((epochs + 1) / (100 * math.log10(epochs + 1))))\n",
    "            if lr_sigma == \"old\":\n",
    "                mutation_sigma = lr_min + 1 * 1 / math.exp(epoch / ((epochs + 1) / (lr_decay * math.log10(epochs + 1))))\n",
    "            if lr_sigma == \"new\":\n",
    "                mutation_sigma = math.exp(-(epoch + 1) * (math.log10((epochs + 1)) / ((epochs + 1) / 10))) + 0.1 * math.exp(-(epoch + 1) * (1 / (epochs + 1)))\n",
    "            if lr_sigma == \"mix\":\n",
    "                mutation_sigma = math.exp(-epoch / (epochs / (lr_decay * math.log10(epochs + 1)))) + 0.02 * math.exp(-(epoch + 1) * (1 / (epochs + 1))) - 0.005\n",
    "\n",
    "            for j in range(number_of_layers_minus_one):\n",
    "                #print(weights[j][sorted_indecies[0 + n // 4::4]].shape, weights[j][sorted_indecies[:n // 4:2]].shape, weights[j][sorted_indecies[1:1 + n // 4:2]].shape)\n",
    "                #print(sorted_indecies)\n",
    "                #print(sorted_indecies[0 + n // 4::4], sorted_indecies[:n // 4:2], sorted_indecies[1:1 + n // 4:2])\n",
    "                \n",
    "                if n_parts == 2:\n",
    "                    weights[j][sorted_indecies[n_div_parts::2]] = (weights[j][sorted_indecies[:n_div_parts:2]] + weights[j][sorted_indecies[1:1 + n_div_parts:2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indecies[1 + n_div_parts::2]] = (weights[j][sorted_indecies[:n_div_parts:2]] + weights[j][sorted_indecies[1:1 + n_div_parts:2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
    "                if n_parts == 4:\n",
    "                    weights[j][sorted_indecies[0 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indecies[1 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indecies[2 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indecies[3 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indecies[4 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
    "                    weights[j][sorted_indecies[5 + n_div_parts::6]] = (weights[j][sorted_indecies[0: n_div_parts: 2]] + weights[j][sorted_indecies[1: n_div_parts: 2]]) / 2 + np.random.normal(0, mutation_sigma, (n_div_parts // 2, layers[j], layers[j + 1]))\n",
    "\n",
    "            if best_net_index != sorted_indecies[0] or 1 == 1:\n",
    "                best_net_index = sorted_indecies[0]\n",
    "            \n",
    "                self.training_loss_history += [nets_loss[best_net_index]]\n",
    "                \n",
    "\n",
    "                self.best_net_weights = []\n",
    "                for j in range(number_of_layers_minus_one):\n",
    "                    self.best_net_weights += [weights[j][best_net_index]]\n",
    "                \n",
    "                if validation_data:\n",
    "                    self.validation_loss_history += [np.mean(np.abs(y_val - self.predict(X_val)))]\n",
    "                    if verbose == 1:\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]} - val_loss: {self.validation_loss_history[-1]}\")\n",
    "                else:\n",
    "                    if verbose == 1:\n",
    "                        pass\n",
    "                        print(f\"Epoch {epoch} - loss: {self.training_loss_history[-1]}\")\n",
    "            \n",
    "        return self.training_loss_history\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == \"leaky_relu\":\n",
    "            activation_function = lambda x: np.maximum(0.1 * x, x)\n",
    "        else:\n",
    "            activation_function = lambda x: np.maximum(0, x)\n",
    "\n",
    "        forward_pass = X.T\n",
    "        for j in range(len(self.best_net_weights) - 1):\n",
    "            forward_pass = activation_function(self.best_net_weights[j].T @ forward_pass)\n",
    "\n",
    "        forward_pass = self.best_net_weights[-1].T @ forward_pass\n",
    "        return forward_pass.ravel()\n",
    "\n",
    "regressor = VectorizedEvoRegressor2(n = 480 // 2, hidden_layers = [16], activation = \"relu\", random_state = 42, n_parts = 4, lr_decay = 20)\n",
    "\n",
    "%lprun -f regressor.fit regressor.fit(scaled_X_train, y_train, epochs = 10000, validation_data = (scaled_X_val, y_val), verbose = 1, lr_sigma = \"mix\")\n",
    "#regressor.fit(scaled_X_train, y_train, epochs = 100, validation_data = (scaled_X_val, y_val), verbose = 1, div = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.550102315157615\n",
      "1.4803432604007358\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbNklEQVR4nO3da5Bcd3nn8e9zunumNaO7NFJkjY1kF2Elw0aXWTAb4xg7JlwMVNm8MIU3JAurrV1qF8PWZu3lBcUrNlRI2dnskqggbNZcTGJM1hEGk7WBCmYRGdnGlizLN2Q0siWNxuiumenu8+yLc3qmp+eMpjXTrf73+Pcpt/v0uT6nj/T7H/37dB9zd0REJGxRuwsQEZHZKaxFRDqAwlpEpAMorEVEOoDCWkSkA+RbsdLVq1f7hg0bWrFqEZEFac+ePcfdvW+m6S0J6w0bNjA4ONiKVYuILEhm9vKFpqsbRESkAyisRUQ6gMJaRKQDtKTPWkSkHUqlEkNDQ4yOjra7lBkVi0X6+/spFAoXtZzCWkQWjKGhIZYsWcKGDRsws3aXM427MzIywtDQEBs3bryoZdUNIiILxujoKKtWrQoyqAHMjFWrVs3pzF9hLSILSqhBXTXX+oIK65999b/w1I++3e4yRESCE1RY/9bBv+Lcs4+0uwwRkTk7dOgQ73znO9m8eTNXX30199xzT1PWG9QHjI6Bx+0uQ0RkzvL5PF/84hfZtm0bp0+fZvv27dx0001s3rx5XusN6sxaRKTTrVu3jm3btgGwZMkSNm3axOHDh+e93qDOrEVEmuVzf7+PZ1451dR1br5sKZ99/9UNz3/w4EGeeOIJ3va2t8172w2dWZvZJ81sr5ntM7M75r3VGTgG6J6QItL5zpw5w6233srdd9/N0qVL572+Wc+szezNwL8B3gqMA983s13u/sK8t14n6bNWWIvI/F3MGXCzlUolbr31Vj7ykY9wyy23NGWdjZxZbwJ2u/s5dy8DPwaas/U6DpjOrEWkg7k7H/vYx9i0aROf/vSnm7beRsJ6L/AOM1tlZj3Ae4HLm1ZBjaQbRESkcz322GPce++9PProo2zZsoUtW7bw0EMPzXu9s3aDuPt+M/tj4AfAWeBJoFI/n5ntAHYAXHHFFXMqRmEtIp3u2muvxVvQndvQB4zu/hV33+7u1wG/Bp7LmGenuw+4+0Bf34x3prkgS1Y0p2VFRBayhi7dM7M17n7MzK4g6a++phXFqM9aRCRbo9dZf9vMVgEl4BPufqIVxXjgP8AiItIuDYW1u7+j1YXUbO3SbUpEpEME9XVzfcAoIpItqLAG9AGjiEiGoMJaMS0iC0GlUmHr1q3cfPPNTVtnUGGdUGSLSGe755572LRpU1PXGVhYq89aRDrb0NAQ3/3ud/n4xz/e1PUG+BOpOrMWkSb43p1w5OnmrvM33gLv+W8XnOWOO+7gC1/4AqdPn27qpoM6s9bVICLSyXbt2sWaNWvYvn1709cd3pm1rgYRkWaY5Qy4FR577DEefPBBHnroIUZHRzl16hS33347X/va1+a9bp1Zi4g0yec//3mGhoY4ePAg9913HzfccENTghoCC2vQb4OIiGQJrxtERGQBuP7667n++uubtr7gzqx1NYiIyHRBhXVyD8Z2VyEiEp6gwlpEZL5acZeWZpprfUGFta4GEZH5KBaLjIyMBBvY7s7IyAjFYvGilw3wA8Yw32QRCV9/fz9DQ0MMDw+3u5QZFYtF+vv7L3q5oMLaJ/4nInLxCoUCGzdubHcZLdFQN4iZfcrM9pnZXjP7ppld/Dl8w5TWIiL1Zg1rM1sP/EdgwN3fDOSA21pTjvqsRUSyNPoBYx5YZGZ5oAd4pVUF6RuMIiLTzRrW7n4Y+BPgV8CrwEl3/0H9fGa2w8wGzWxwrp37uhpERCRbI90gK4APAhuBy4BeM7u9fj533+nuA+4+0NfXN4+SdGYtIlKvkW6Q3wV+6e7D7l4CHgD+ZSuK0dUgIiLZGgnrXwHXmFmPmRlwI7C/dSUprUVE6jXSZ70buB94HHg6XWZna8pRn7WISJaGvhTj7p8FPtviWqpbuzSbERHpIPptEBGRDhBUWAOYTqxFRKYJKqx1Zi0iki2osE7o1FpEpF5YYa0TaxGRTGGFNaAzaxGR6YIKa/VZi4hkCyqsAQj0djwiIu0UVFjrzFpEJFtQYQ36PWsRkSzBhbWIiEwXYFjrzFpEpF5QYa0+axGRbEGFNaCrQUREMgQV1jqzFhHJFlRYg75xLiKSpZEb5r7JzJ6seZwysztaU44u3BMRyTLrnWLc/QCwBcDMcsBh4DutKkhxLSIy3cV2g9wIvOjuL7eiGMW0iEi2iw3r24BvZk0wsx1mNmhmg8PDw3OvSFeDiIhM03BYm1kX8AHgb7Omu/tOdx9w94G+vr65VWP6eFFEJMvFnFm/B3jc3Y+2qpiEzqxFROpdTFh/mBm6QJpF11mLiGRrKKzNrBe4CXigteXoahARkSyzXroH4O5ngVUtrgVXVIuIZAruG4y6GkREZLqgwtodjp4aa3cZIiLBCSqso8go5vUho4hIvaDCujuf06XWIiIZggpr0K/uiYhkCSusTVeDiIhkCSus0XXWIiJZggvrlX6i3SWIiAQnqLBeUn6NOKySRESC0NA3GC+V1wrrGK/oI0YRkXpBncaWoy4i4naXISISnKDCOiYiR6XdZYiIBCeosHbLkdOZtYjINIGFtenSPRGRDEGFNSisRUSyBBXWjumuXiIiGRq9U8xyM7vfzJ41s/1m9vbWlKMzaxGRLI1eZ30P8H13/1B6l/OeVhTjpq+bi4hkmTWszWwZcB3wBwDuPg6Mt6YcnVmLiGRppBtkIzAMfNXMnjCzL6c30G0BfXtRRCRLI2GdB7YBX3L3rcBZ4M76mcxsh5kNmtng8PDwnIrRpXsiItkaCeshYMjdd6ev7ycJ7yncfae7D7j7QF9f35yKcXWDiIhkmjWs3f0IcMjM3pSOuhF4pjXlKKxFRLI0ejXIfwC+nl4J8hLwh60pR2EtIpKlobB29yeBgdaWoj5rEZGZBPUNRl0NIiKSLbCw1pdiRESyBBXWuhpERCRbUGGNmTpCREQyhBXWGPrZPRGR6YIKa3WDiIhkCyqsQdeDiIhkCSqs3SKdWYuIZAgrrDHMFdYiIvWCCmv0DUYRkUxhhbU+YBQRyRRYWOsDRhGRLEGFtZuusxYRyRJUWKsbREQkW4BhLSIi9cIKa10NIiKSKaiw9pr/i4jIpIbuFGNmB4HTQAUou3uL7hoTqRtERCRDo/dgBHinux9vWSUAppsPiIhkCawbRL8NIiKSpdGwduAHZrbHzHZkzWBmO8xs0MwGh4eH51iOPmAUEcnSaFhf6+7bgPcAnzCz6+pncPed7j7g7gN9fX1zKsbVDSIikqmhsHb3w+nzMeA7wFtbU46usxYRyTJrWJtZr5ktqQ4D7wL2tqYcdYOIiGRp5GqQtcB3zKw6/zfc/futKMYtIlJYi4hMM2tYu/tLwG9dglrSO8XEl2JTIiIdJbhL93IKaxGRacIKa3WDiIhkCius9aUYEZFMYYW1mbpBREQyBBbWOSJz0B3ORUSmCCqsJ8pxnV2LiNQKKqxjU1iLiGQJKqyphnVcaW8dIiKBCSqsvfrLIDqzFhGZIqywtlw6oLAWEakVWFhXz6zVDSIiUiuwsNaZtYhIlqDCulrOI8+82uY6RETCElRYX335CgD2HT7R3kJERAITVFivWbIIgEpFfdYiIrWCCuvqddamDxhFRKZoOKzNLGdmT5jZrtZVk3zAWCifbdkmREQ60cWcWX8S2N+qQgCICgAsGR9u6WZERDpNQ2FtZv3A+4Avt7SaVVclz15u6WZERDpNo2fWdwN/BDP/2LSZ7TCzQTMbHB6e45mxfshJRCTTrGFtZjcDx9x9z4Xmc/ed7j7g7gN9fX1zq0Y/5CQikqmRM+vfBj5gZgeB+4AbzOxrralG32AUEckya1i7+13u3u/uG4DbgEfd/faWVDNxZq2wFhGpFdh11jqzFhHJkr+Ymd39R8CPWlIJ6EsxIiIzCOvMOu2zVliLiEwVVlinZ9aubhARkSmCDGtTWIuITBFWWOvSPRGRTIGFdfJ55xvOt/YnSEREOk1YYb1kHQBj1t3mQkREwhJWWJtx2nqJ0NUgIiK1wgprICanS/dEROoEGNYRkcJaRGSK4MK6YjlduiciUie4sE7OrHXzARGRWgGGtc6sRUTqhRfWFnH+9GvtLkNEJCjBhXUXJbZEL+Lu7S5FRCQYwYV1qfcyTnovpYrCWkSkKriwPtPTTxdlxsq6fE9EpKqRG+YWzeznZvYLM9tnZp9rZUFxrosuK3H8zHgrNyMi0lEauVPMGHCDu58xswLwEzP7nrv/rBUFRfkiXZQ5OlpqxepFRDrSrGHtySd9Z9KXhfTRsg7l4qIeuimpz1pEpEZDfdZmljOzJ4FjwD+4++6MeXaY2aCZDQ4PD8+9onw3XZQoV3SttYhIVUNh7e4Vd98C9ANvNbM3Z8yz090H3H2gr69v7hXlF5G3mEpZfdYiIlUXdTWIu58Afgi8uyXVAFYoAlAeP9+qTYiIdJxGrgbpM7Pl6fAi4Cbg2VYVVA3reHysVZsQEek4jVwNsg74azPLkYT737j7rlYVVA1rL51r1SZERDpOI1eDPAVsvQS1ABBVz6xLo5dqkyIiwQvuG4xRYVEyUFKftYhIVXBhnSt0ATA0crrNlYiIhCO4sF7ak9zZfLykbzCKiFQFF9aF9Mz64LET7S1ERCQgwYU1UfKZZzGnr5uLiFQFGNYFAErj+gajiEhVgGGdnFmrz1pEZFKAYZ0D4B1jP25zISIi4QgvrFe/EYB1lVfbXIiISDjCC+vuJTy/4jqu4pBumisikgovrIFcLk+REufHy+0uRUQkCEGG9bEVW+m2EkeOHml3KSIiQQgyrH9jzRoAjh1Vv7WICAQa1itXLAfg5OHn2luIiEggggzrJZe/BYDK8RfbXImISBiCDGtb1g/Ar155pc2ViIiEIciwpriM12w5a+J53CVdRGQBaeQejJeb2Q/N7Bkz22dmn7wUhY319rM+PszRU7pjjIhII2fWZeA/uftm4BrgE2a2ubVlQX7ZWv65vcQj+4+1elMiIsGbNazd/VV3fzwdPg3sB9a3urDV669ikY2z+592t3pTIiLBu6g+azPbQHLz3GkJamY7zGzQzAaHh+ff12z/7H0A/OaRB/nBPn05RkRe3xoOazNbDHwbuMPdT9VPd/ed7j7g7gN9fX3zr2zj7wBwS/6nfObv9nLotXPzX6eISIdqKKzNrEAS1F939wdaW9LERmHzB1nHca4efZJbvvRT/vF5XR0iIq9PjVwNYsBXgP3u/qetL6nGjZ8F4Ms9f86K/Bj/6is/5/3//Sfc+/8OcvzM2CUtRUSknWy2nyE1s2uBfwSeBuJ09H9194dmWmZgYMAHBwebU+FLP4b//QHKb7mNb/R9insHj/L8sTMAbLtiOf9iw0q2v2EFb9u4imU9heZsU0TkEjOzPe4+MOP0VvxmdFPDGuCh/ww/3wnFZfhb/y371r6fhw9389MXR/jFoROUY8cM3rR2CVuvWMEbVvWwcXUvV67u5aq+xUSRNa8WEZEWWBhhDfDcw/Cz/wkv/QgwuOoGuPJ3ONe3hb1cxU9ePsfjL/+apw+f5OT5yfs39nTluGJlD2uWFlm/vEj/ih7WLOnmsuWLWLu0m9WLu1laLCjQRaStFk5YV504BHv+Fzz1LTh5KBlnESxdDys3Qs8qxvOLGcmv5YVoA0+cXMz+8ys4dDZi6MQoJ85NvxFvLjKWLyqwbFGBYiFHsRCxdFGBlb1drF7cTXc+YkkxT293nq5cRFc+ojsf0dOVp1jI0ZWPJsb3dOXozifDXfmIQhSpIRCRWS28sK5yh1OvwCuPw5G98NpLcPw5GD8DoyfhbN2VI4tWwJqrGVt+FWeK6zjKSk7kVnKkspRXy4s5NlZgZNQYrcBoKebX58Z57ew4J86VGC1XmM/b1JVLwr23O8+irhz5yCjkIgr5iGI+IjIjFxlRZOQsaTwis4nx+ZyRjyIKueR1IReRj4xcrjof5MzIRRG5iHQ9ybzJ8lH6mol1VrdRfe7KV9ebbCefm2yAcun6ooia4cnnrlxEFEE+iogMks+kReRizBbW+UtZTFOZwbL1yWPT+6dPP3schg/A6Vfh5BCMPA/DB+h+7u/pPv8aq2Za7/IroLcPVq6AtT1Q6MG7ehnL9VAqLKNsBUq5RZRyixitRIzFOUpEjHuOMc8zWoZxjxiPjbGKJc+xcybO8etSnrNxnnNxgfE4YqxcYawcU45jxspOxSGOnUrsxJ48KrFTjp1yxSnHMeWKU6rEybjYcXdih0oczv0qq41BzozuQtJQ5aMobXTShio3GeyRMdE4RdHksKXjCzlL5zdI/puYXh0mnddgYrmkzbB0O7XTk2nVxiZKG7Kpr5Pn7nw0ZX21y9duz9LhifnS6dSMm9rI1exzzetku1MbVSOZbjX7Ur+9iW1F0+soRFFae/r+1dfO5LwTw0weGzW+YejcsJ5N7+rkkWX8XBLgZ4eTx5ljUDoHY6dg5MXk+dwIlA7D+FmsdJbi+RMUvdKc2iwHhR6Sv6H55HWUTx7FpZAvQr4bcoVkvq7FUFiUDOe7IFd9FCaG3SLccsRExBZNPntEhYjY8lQsh5O8rpDM4+SoEDEeQ8nylGOj5BFlN8YrxngMFYyyJ/OVrEDZc5SJKJNL5o+Z0rBU4phKDJU4ZrQUU6rElGoam/FKXNMggbtPeV2JY2JP1hnHznjFKVdinGQcyX/E7rhPPlMzzqmuG2ByO9Xn6nIVd+IYKmkNMrNpIU61kZwe8hdq2Gob0MzlbLJhqjaetQ0QTG8ULS0wmqXGaqM42dhNNnyTtU7OO7l83fy1NaZFmcGSYp7PvK81P520cMP6Qrp6oO83k0ej4gqUx6AyBmNnoHQe4hJUShCXoTKeDHslmTeuJOM9fR4/C6XRZPlzI1Aenzo9LkOlnDQU5bFkfaXzcHYk6dopnU8alMp4Mp2pwWLpoy2/eRvlJxsPi5LGx6LJR5RL/wbWjLNc0iB19aaNltXMUzMvtcvVTMeS9UZ5Jk4XJ+a3yXnqx1O3jinDhmO4RcQYDlTi5C9r0gAkfyk9fbdjjKRZsPRopMtPvCadJ1kmdksaCow4HZc0GsnRTBogS7dtVNzSa2UtnW44Uc38yfik0bWJGqvLx+n2K7Hj6TwxRhwViMlRwYipa+DTR8UKVCyXLE+Ee/q+uBFbtbYcsUHsyftV8RyevlcxJMs4xJY8V3zyfcAgjpN3z6v7U21ImWxYKxON89SGOU4b4YlxMNEQw/SGPJkWJ38tqw36xHLV1+nJQP3yyaZqtjN1fq+pb2VvV3P/btV4fYb1XES5JOTpSfq/2y2upME9moR8tZGYeI6nvo5Lk43ITPNWxrOXrw5XG6Vq4xLXNDTlsbSxiuselfRvYc246vrHTid1VafHMXi6DmqX8cnn2vHV7eNM/O3B6+bLGvaabVAz7JjHmCfxhzuF2vXB1GFpgmojWjvcwDPUjGOyQa4dP9/hiAvPM61uoGc1cN2c340LUVh3qigH0aKke0Taw2cI8inPZIy70DTqGpM4Y9mshoeMcRnL1Da0tY32RGOZjquMTb6ub4CrjW1tI1z9V2Lmfl3oPbjQezfDe5P1vlXfg8z3drZh5rBsRuPtnnRjtojCWmSurPbsSqS1wrytl4iITKGwFhHpAAprEZEOoLAWEekACmsRkQ6gsBYR6QAKaxGRDqCwFhHpAC35iVQzGwZenuPiq4HjTSynE2ifF77X2/6C9vlivcHd+2aa2JKwng8zG7zQb7ouRNrnhe/1tr+gfW42dYOIiHQAhbWISAcIMax3truANtA+L3yvt/0F7XNTBddnLSIi04V4Zi0iInUU1iIiHSCYsDazd5vZATN7wczubHc982Fml5vZD83sGTPbZ2afTMevNLN/MLPn0+cV6Xgzsz9L9/0pM9tWs66PpvM/b2Yfbdc+NcLMcmb2hJntSl9vNLPd6X59y8y60vHd6esX0ukbatZxVzr+gJn9Xpt2pWFmttzM7jezZ81sv5m9fSEfZzP7VPpneq+ZfdPMigvxOJvZX5nZMTPbWzOuacfVzLab2dPpMn9m1sBdLJI7Pbf3AeSAF4ErgS7gF8Dmdtc1j/1ZB2xLh5cAzwGbgS8Ad6bj7wT+OB1+L/A9kpu8XQPsTsevBF5Kn1ekwyvavX8X2O9PA98AdqWv/wa4LR3+C+DfpcP/HviLdPg24Fvp8Ob02HcDG9M/E7l279cs+/zXwMfT4S5g+UI9zsB64JfAoprj+wcL8TiT3EhxG7C3ZlzTjivw83ReS5d9z6w1tftNSQt/O/Bwzeu7gLvaXVcT9+//ADcBB4B16bh1wIF0+C+BD9fMfyCd/mHgL2vGT5kvpAfQDzwC3ADsSv8QHgfy9ccYeBh4ezqcT+ez+uNeO1+ID2BZGl5WN35BHuc0rA+l4ZNPj/PvLdTjDGyoC+umHNd02rM146fMN9MjlG6Q6h+CqqF0XMdL/+m3FdgNrHX3V9NJR4C16fBM+99J78vdwB8B1TuXrgJOuHs5fV1b+8R+pdNPpvN30v5CclY4DHw17f75spn1skCPs7sfBv4E+BXwKslx28PCP85VzTqu69Ph+vEXFEpYL0hmthj4NnCHu5+qneZJk7ogrps0s5uBY+6+p921XGJ5kn8qf8ndtwJnSf55PGGBHecVwAdJGqnLgF7g3W0tqk3acVxDCevDwOU1r/vTcR3LzAokQf11d38gHX3UzNal09cBx9LxM+1/p7wvvw18wMwOAveRdIXcAyw3s3w6T23tE/uVTl8GjNA5+1s1BAy5++709f0k4b1Qj/PvAr9092F3LwEPkBz7hX6cq5p1XA+nw/XjLyiUsP4n4I3pp8pdJB9GPNjmmuYs/WT3K8B+d//TmkkPAtVPhD9K0pddHf/76afK1wAn039uPQy8y8xWpGc170rHBcXd73L3fnffQHLsHnX3jwA/BD6Uzla/v9X34UPp/J6Ovy29imAj8EaSD2KC5O5HgENm9qZ01I3AMyzQ40zS/XGNmfWkf8ar+7ugj3ONphzXdNopM7smfR9/v2ZdM2t3J35NJ/t7Sa6aeBH4TLvrmee+XEvyT6SngCfTx3tJ+useAZ4H/i+wMp3fgP+R7vvTwEDNuv418EL6+MN271sD+349k1eDXEnyl/AF4G+B7nR8MX39Qjr9yprlP5O+Dwdo4BPydj+ALcBgeqz/juRT/wV7nIHPAc8Ce4F7Sa7oWHDHGfgmSb98ieRfUB9r5nEFBtL38EXgz6n7kDrroa+bi4h0gFC6QURE5AIU1iIiHUBhLSLSARTWIiIdQGEtItIBFNYiIh1AYS0i0gH+P4izmnooFeFbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss_history = []\n",
    "learning_rate_decay = [10, 20, 60, 100, 200]\n",
    "lr_mins = [0.2, 0.1, 0.05]\n",
    "lr_sigmas = [\"old\", \"new\", \"mix\"]\n",
    "divs = [2, 4]\n",
    "params = divs\n",
    "\n",
    "for param in params:\n",
    "    regressor = VectorizedEvoRegressor2(n = 96, hidden_layers = [16], activation = \"relu\", random_state = 42)\n",
    "    training_loss_history += [regressor.fit(scaled_X_train, y_train, epochs = 10000, validation_data = (scaled_X_val, y_val), verbose = 0, div = param, lr_decay = 20, lr_min = 0.1, lr_sigma = \"mix\")]\n",
    "    print(regressor.training_loss_history[-1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for training_loss, param in zip(training_loss_history, params):\n",
    "    ax.plot(training_loss, label = param)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmE0lEQVR4nO3deXxU9b3/8dcnyWQPSSABAgHCKoggYGpBkJa6W5fWWq+2trW/9oe9rVXbW61W1Pq7v95rl1/b241b2moX7WJtvWpdiguKKxgWAWWXxbCGQEJCQtbv748zwQhZJmRmzpnk/Xw8eMzkzJk5b04mn3zznfP9fs05h4iIBFeS3wFERKRrKtQiIgGnQi0iEnAq1CIiAadCLSIScCmxeNGCggJXUlISi5cWEemTVqxYccA5V9jRYzEp1CUlJZSVlcXipUVE+iQz29HZY+r6EBEJOBVqEZGAU6EWEQm4mPRRi4hEqqmpifLyco4ePep3lLhIT0+nuLiYUCgU8XNUqEXEV+Xl5eTk5FBSUoKZ+R0nppxzVFZWUl5ezujRoyN+nro+RMRXR48eZdCgQX2+SAOYGYMGDerxXw8q1CLiu/5QpNuczP81MIXaOcdPn9vMi5sq/I4iIhIogSnUZsaipe+wZMN+v6OISD9SVVXFL37xi5N67o9//GPq6uqOfX3HHXcwYsQIsrOzoxUPCFChBsjLClFd3+R3DBHpR6JZqC+99FKWL18erWjHBOqqj7yMVA7VNfodQ0T6kdtuu42tW7cybdo0zjvvPAYPHsxDDz1EQ0MDH//4x7nnnns4cuQIV111FeXl5bS0tHDnnXeyb98+du/ezbx58ygoKGDJkiXMnDkzJhmDVagzQxyqU4tapL+65/G3eHv34ai+5qnDBnD3pZM7ffzee+9l3bp1rF69msWLF/Pwww+zfPlynHNcdtllLF26lIqKCoYNG8YTTzwBQHV1Nbm5ufzwhz9kyZIlFBQURDXz8QLV9ZGfmUq1WtQi4pPFixezePFipk+fzowZM9iwYQObN29mypQpPPPMM3zzm9/kpZdeIjc3N6651KIWkcDoquUbD845br/9dq6//voTHlu5ciVPPvkkCxYs4JxzzuGuu+6KW65AtajzMlM5fLSJllatjC4i8ZGTk0NNTQ0AF1xwAffddx+1tbUA7Nq1i/3797N7924yMzO59tprueWWW1i5cuUJz42lQBXq/MwQzsFhXfkhInEyaNAgZs+ezWmnncYzzzzDpz71KWbNmsWUKVO48sorqampYe3atZx55plMmzaNe+65hwULFgAwf/58LrzwQubNmwfArbfeSnFxMXV1dRQXF/Ptb387KhnNue5br2Z2E/C/AQN+5Zz7cVf7l5aWupNZOOCRVeV87S9v8vy/fYgxhdG9DlFEgmn9+vVMmjTJ7xhx1dH/2cxWOOdKO9q/2xa1mZ2GV6TPBE4HLjGzcVHIeoK8zFQA9VOLiLQTSdfHJGCZc67OOdcMvAhcEYsw+eFCXV2vKz9ERNpEUqjXAWeb2SAzywQuBkYcv5OZzTezMjMrq6g4ufk68jK8+VkPHVGLWkSkTbeF2jm3HvgusBh4GlgNtHSw3yLnXKlzrrSwsMOFdLuVf6zrQy1qEZE2EV314Zz7jXPuDOfcXOAQsCkWYXLSU0gyNN+HiEg7EQ14MbPBzrn9ZjYSr386JgPak5KM3IyQWtQiIu1Eeh3138zsbeBx4CvOuapYBcrPTNVVHyISN9GaPa+uro6PfvSjTJw4kcmTJ3PbbbdFLWOkXR9nO+dOdc6d7px7LmpH70BeZohqFWoRiZNoTnP6jW98gw0bNrBq1SpeeeUVnnrqqahkDNRcH+BdS73vcP9YjVhE/BfNaU7bRiimpqYyY8YMysvLo5IxgIU6xMa9sR87LyIB9NRtsHdtdF9z6BS46N5OH47FNKdVVVU8/vjj3HTTTVH5LwRqrg/w+qir9GGiiPggGtOcNjc3c80113DjjTcyZsyYqOQKXos6I8SRxhbufnTd+1brvfT0Is4YNdDHZCISc120fOMhGtOczp8/n/Hjx3PzzTdHLVfgCvWMUfkUZKfyP6t3H9tWc7SJPdX1/PIzKtQiEl3HT3N655138ulPf5rs7Gx27dpFKBSiubmZgQMHcu2115KXl8evf/3r9z23retjwYIFVFdXH3s8WgJXqGePK6BswXnv2/aJha9S29DsUyIR6cvaT3N60UUXHZvmFCA7O5sHHniALVu2cMstt5CUlEQoFGLhwoXAe9OcDhs2jD/84Q985zvfYeLEicyYMQOAG264gS9+8Yu9zhjRNKc9dbLTnHbmuvuXc+hII4/eMCdqrykiwaBpTj29muY0CLLTUqhRi1pE+qmEKNQ56SnUHlWhFpH+KSEKdXZaivqoRfqwWHTBBtXJ/F8TpFCHqGtsobml1e8oIhJl6enpVFZW9oti7ZyjsrKS9PT0Hj0vcFd9dCQ73Yt5pKGF3MyE+N0iIhEqLi6mvLyck11wJNGkp6dTXFzco+ckRKHOCRfqmoYmcjNDPqcRkWgKhUKMHj3a7xiBlhDN05w0r1Crn1pE+qOEKNRtXR+68kNE+qPEKNRpbV0fKtQi0v8kRKE+1ketFrWI9EMRFWoz+5qZvWVm68zsT2bWs2tLeik7zfsAUV0fItIfdVuozWw4cCNQ6pw7DUgGro51sPaO9VE3aIkuEel/Iu36SAEyzCwFyAR2d7N/VGWlJmOmFrWI9E/dFmrn3C7gB8BOYA9Q7ZxbfPx+ZjbfzMrMrCzaF66bmSZmEpF+K5Kuj3zgcmA0MAzIMrNrj9/PObfIOVfqnCstLCyMetCcNE3MJCL9UyRdH+cC25xzFc65JuDvwFmxjXWi7PQUXfUhIv1SJIV6JzDTzDLNW8TwHGB9bGOdSDPoiUh/FUkf9TLgYWAlsDb8nEUxznWC7PSQ+qhFpF+KaFIm59zdwN0xztKlnLQUdh2q8zOCiIgvgjMysakeHrwKyu7v8OGcdHV9iEj/FJxCHcqAg1thwxMdPpytqz5EpJ8KTqEGGHsObH8Zmo6e8FB2egpHGltoae37q0CIiLQXrEI97hxoroedr57wULbmpBaRfipYhbpkDiSnwpbnTngoJ12FWkT6p2AV6tQsGDkTtj5/wkNtM+hV1TXGO5WIiK+CVagBRn8I9r8NR6vft3nysAEAvLHtoB+pRER8E7xCnT3Yu22oed/mkoIsxhZm8dyG/T6EEhHxT/AKdSjTu208csJD50wawuvvVFJzVPNSi0j/EbxCnZrl3XZUqCcOpqnF8dLmA3EOJSLin+AV6rYWddOJw8XPGJVPbkaIOx5ZyyU/fYl3D2pIuYj0fcEr1KnZ3m3jiUU4JTmJBR+dxFnjCti0t5ZfLt0a53AiIvEXwELd1qI+sesD4JOlI/j5p2bwsenDeHhFOYeO6HI9Eenbgleou/gwsb0vnj2Go02tPPD6jjiEEhHxT/AK9bEPE7vuf54wJIcPlOTz7Pp9cQglIuKf4BXqUNddH+0Nz8vgoEYqikgfF8BCnQFYty1qgLzMVKqO6JpqEenbIlmF/BQzW93u32Ezuzlmicy87o8OLs87Xl6mtzxXU0trzOKIiPit26W4nHMbgWkAZpYM7AIeiWmqUGa3HyYC5GemAlBd30RBdlpMI4mI+KWnXR/nAFudc7G91CI1skKdl9k2o566P0Sk7+ppob4a+FNHD5jZfDMrM7OyioqK3qUKRdr14bWoNfWpiPRlERdqM0sFLgP+2tHjzrlFzrlS51xpYWFh71JF2KLOD7eoD6lFLSJ9WE9a1BcBK51zsb9wOZQZUYs6Xy1qEekHelKor6GTbo+oS82O6PK8XPVRi0g/EFGhNrMs4Dzg77GNE5aaCY213e6Wk5ZCSpJxSC1qEenDur08D8A5dwQYFOMs74mw68PMyMsMUVWvFrWI9F3BG5kI3oCXCLo+AHIzQuqjFpE+LZiFOpTpzfXhXLe75memckjDyEWkDwtmoU7NAtcKzQ3d7pqXmaquDxHp04JbqCHi0Ynq+hCRviyYhboHU53mZ4Z01YeI9GnBLNRty3FFONXp0aZWjja1xDiUiIg/glmoQ+Gujwha1JqYSUT6umAW6h60qNuGkav7Q0T6qoAW6rYWdWSLBwD8/rUdvLH9YCxTiYj4IpiFuq3rI4Jh5KMLsshMTeZPy3fy6V8vY/uB7rtLREQSSTALdQ+6PopyM1hz9/m8cttHSE1O4q7H3sJFMFBGRCRRBLNQhyLv+gBISU5ieF4G/3b+BJZuqmDst57kX375mtZSFJE+IaJJmeLuWIu6Z90Yn51VQkpyEhv2HObBZTt58PUdXDd7dAwCiojETzALdUo6YBG3qNskJxmfmTkK5xzbK4/wo2c387Hpw48t2SUikoiC2fVhFl484OQ+GDQzFnz0VKrrm3h4RXmUw4mIxFcwCzV4l+g11Jz00ycVDWB4XgZvlldHMZSISPwFt1BnFUJdZa9eYsrwXNaUV0Unj4iIT4JbqLMHQ23v1tGdOiKXHZV1VGt4uYgksEjXTMwzs4fNbIOZrTezWbEORvYQqN3fq5eYOjwPgDW7qnqfR0TEJ5G2qP8LeNo5NxE4HVgfu0hhbS3qXgxemTI8F4A16qcWkQTWbaE2s1xgLvAbAOdco3OuKsa5vBZ1SyMcPflD5WaGKBmUyVoVahFJYJG0qEcDFcD9ZrbKzH5tZlnH72Rm882szMzKKioqep8se7B329vuj+I8lm2r5IWN+zW0XEQSUiSFOgWYASx0zk0HjgC3Hb+Tc26Rc67UOVdaWFjY+2TZQ7zbXn6g+LmzSkgPJXPd/W/wx+U7e59LRCTOIinU5UC5c25Z+OuH8Qp3bB0r1L1rUZ8xKp8Xb5nHmMIs/vlW74q+iIgfui3Uzrm9wLtmdkp40znA2zFNBe26PnpfXFNTkpgzroCy7QdpbNZETSKSWCK96uOrwINmtgaYBvxHzBK1Sc+F5LSoFGqAWWMGUdfYogEwIpJwIpqUyTm3GiiNbZTjmEXlWuo2HxwzCIDXtlZSWjIwKq8pIhIPwR2ZCFEZndhmYFYqk4oG8No7vRuWLiISbwEv1NFrUYPX/bFixyEamlui9poiIrEW8EIdvRY1wJmjB9LQ3Mq6XRoAIyKJI+CFeggcOQAtzVF5udKSfADe2H4oKq8nIhIPAS/UgwEHR6LT/VGQncaYgizKth+MyuuJiMRDsAv1kMne7a4VUXvJ0pJ8ynYcorVVw8lFJDEEu1APm+GtSL5tadResrRkIFV1TWytqI3aa4qIxFKwC3VKKoyaFdVCfWb4Gur/eHI9P1+yhSMN0en/FhGJlWAXaoDRc6FiA9RE5+qPUYMy+UBJPmXbD/H9f27koz95iUdX76KipiEqry8iEm3BL9QlZ3u321+KysuZGX/90lmsvecC/jx/Jk0tjpv+vJp5P3iB8kN1UTmGiEg0Bb9QF53uzfsRpULd3swxg3jxlg/z4Bc/SG1DM/9YsyfqxxAR6a3gF+qkZCicCAfficnLpyQnMXtcAaePyOMfa3bH5BgiIr0R/EINkFMEh2Pb2r10ahHrdh1m+4EjMT2OiEhPJUahHjAcDu/u1UK33bl4ShGAWtUiEjgJUqiLoOkIHI3dHB3D8jI4c/RAHiorp0WDYUQkQBKkUA/zbmti2/3xuVkl7DxYx/Mbojdjn4hIbyVGoc4JF+rDu2J6mPMnD6EoN53fvrotpscREemJiAq1mW03s7VmttrMymId6gRtLeoYf6AYSk7i2pmjeGVLJW/t1lSoIhIMPWlRz3POTXPOxXdJLvCu+gDvA8UYu/aDo8hJT+FHz2yK+bFERCKRGF0fKamQVQg1sS/UuZkh5p89hmfX72fVTs1bLSL+i7RQO2Cxma0ws/kd7WBm882szMzKKioqopewTU5RXFrUAJ+fM5pBWaksfGFrXI4nItKVSAv1HOfcDOAi4CtmNvf4HZxzi5xzpc650sLCwqiGBMLXUsdniHd2WgoXnjaUV7YcoKmlNS7HFBHpTESF2jm3K3y7H3gEODOWoTo0oCjmV320N3tcAUcaW1hTXhW3Y4qIdKTbQm1mWWaW03YfOB9YF+tgJxgwDOoPQlN9XA43a8wgzOCVLZVxOZ6ISGciaVEPAV42szeB5cATzrmnYxurA8eupY5PP3V+ViqnFg3glS0H4nI8EZHOpHS3g3PuHeD0OGTp2sAx3u2BzTBobFwOOWdcAfe/sp2XNx8gKQnSUpKYPiKfpCSLy/FFRCBRLs8DGDoFMNizOm6H/NCEQhpbWrn2N8v41K+W8YmFr/HkOs1ZLSLx1W2LOjDSsqFgPOx5M26HnDV2EI/dMJu6xhYAbvzTKp5Ys4dLpg6LWwYRkcQp1ABF02D7y3E7nJkxtTjv2NcXTB7KwyvKqW9sISM1OW45RKR/S5yuD/CW5arZDbX+zG530WlDqW9q4cVNml1PROInsQr1sGnebRy7P9o7c/RA8jNDPLl2ry/HF5H+KbEK9dCp3u3u1b4cPiU5iUumDuPJtXvYsr/Wlwwi0v8kVqFOHwADx8LO13yLcNO548lITebbj72Fi+HSYCIibRKrUANMuRK2Pgd71vhy+ILsNP7tvAm8vOUA/3xLXSAiEnuJV6hnfhnScuGFe32LcO3MUUwYks29T22gsVmTNolIbCVeoc7Ig1lfgY1PwL63fYmQkpzE7RdPYntlHX94fYcvGUSk/0i8Qg1Q+nnvdtNTvkX48IRC5owrYOELW2nVquUiEkOJWaizB3tDyrcu8S2CmXHFjOEcqG3grd2HfcshIn1fYhZqgLEfgZ2vQ4N/l8mdPd5bIGHp5hisaCMiEpbYhbq1Ka5Dyo9XmJPG5GEDeHGjCrWIxE7iFuqRsyAlA7Y+72uMuRMKWbnzEDVHm3zNISJ9V+IW6pQ0KJkD7/jXTw3eVKjNrY6fLdlCbUOzr1lEpG9K3EINMHouHNgENf4NPDljVD4fmTiYX774DvN+8AKb9tX4lkVE+qaIC7WZJZvZKjP7RywD9cjos73bbS/5FiGUnMR9132Av/3rWRhw9aLXWfaO1lkUkejpSYv6JmB9rIKclKFTIT0Xti/1OwlnjMrnL9fPIjM1mX9Z9Do3/HGl+q1FJCoiKtRmVgx8FPh1bOP0UFIyjJrta4u6vdEFWTzztQ/xtXMn8PS6vVy58DV2Vtb5HUtEElykLeofA7cCnU5sYWbzzazMzMoqKuJ4udrouXBoG1SXx++YXchITeamc8fz28+fye7qei748VJ++8o2v2OJSALrtlCb2SXAfufciq72c84tcs6VOudKCwsLoxawW2M+7N2+/Vj8jhmBOeMLePrmuZSW5PPtx99ma4XmrxaRkxNJi3o2cJmZbQf+DHzEzB6IaaqeGDwJRnwQli+C1mDNZDc8L4P/vGIKAEs2aPkuETk53RZq59ztzrli51wJcDXwvHPu2pgn64kPXu91f2x5xu8kJyjOz2TCkGyWbFShFpGTk9jXUbeZdBnkFMHLP4LWFr/TnGDeKYNZvu2gBsSIyEnpUaF2zr3gnLskVmFOWnII5t3hLdH1zF1+pznBvImDaWpxPLKynM37ati8r4ajTcH7hSIiwZTid4ComfEZ2LsGXvsZFJ4CMz7rd6JjzhiVT25GiDsffevYtnMmDuY3133Ax1Qikij6TqEGuOA/4cBm+MfXYdA4GHWW34kAb/Tin+fPPHblx2tbK3lw2U5W7DjEGaPyfU4nIkHXN/qo2ySnwCfvh/xR8PfrIUCrhE8qGsAlU4dxydRhfOviSQzKSuUH/9zIpn011DWq71pEOte3CjVARr63pmL1Tqjc6neaDmWlpfCvHx7La+9Ucv6PlvKlB1b6HUlEAqxvdX20KZnr3W5/CQrG+ZulE9edVcKoQVk8tW4Pj6zaxd7qowzNTfc7logEUN9rUQMMGgvZQ31d/aU7KclJnHfqEG6YNw7n4PE3d/sdSUQCqm8WajNvUYHtLweqn7ojYwqzmVqcy/+s3uV3FBEJqL5ZqMEr1LV7A9tP3d7l04bz1u7DzPnu89z16DpcwH+5iEh89c0+avBm1QPY+lxg+6nbXHlGMVsratlTVc/vX9vByIGZfPHsMX7HEpGAsFi03kpLS11ZWVnUX7dHnINfhleAuf4lrzsk4JxzfOmBFTy7fj/D8zIACCUbN587gUtPH+ZzOhGJJTNb4Zwr7eixvtv1YQZnXAd718LuVX6niYiZ8f1Pns7nZpVwxqh8zhiVT3ooma/+aRULX9iqLhGRfqrvdn0ATPkkLL4TVvwWhs/wO01EBqSHuOvSU499fbSphW/89U2++/QGlm2r5EdXTSM/K9XHhCISb323RQ3eeoqTPw7r/gZNR/1Oc1LSQ8n89Jrp/Pvlk3l1ayWf/+0b1DdqQieR/qRvF2rwCnVjbaCvqe6OmfGZWSX89JrpvFlexScWvsqXH1zBmvIqv6OJSBz0/UJdcjaEsmDjk34n6bULJg/le5+YSqtzLNlQwU+e2+J3JBGJg75fqEPpMO4jsPGpwA9+icQnS0fw9M1z+eysUbywcT+VtQ1+RxKRGOv7hRrglIuhZjesfwyqdvqdJiqumFFMc6vT0HORfqBvX/XRZvz5kJQCD4UXExg6FS68F0pm+5urF04ZmsPkYQP47avbOXikkcunD2dsYbbfsUQkBrptUZtZupktN7M3zewtM7snHsGiKqsAvvAM/MsDcP534Gi1V7RrE3vB2evOKmFXVT0/eX4L1yx6nT3V9X5HEpEY6HZkopkZkOWcqzWzEPAycJNz7vXOnhOIkYld2b8eFn3Ymw/kUw9BUrLfiXpl494aPrHwVXIzQowb/P5W9YCMEGMKsrj6zBEU5Wb4lFBEutPVyMQeDSE3s0y8Qv2vzrllne0X+EIN8MZv4Imvw+nXwOU/T/hi/eqWA/zo2U00trT7fjrHobomyg/VkZKcxIyReSSFh9J/+JRC5s8d61NaETleV4U6oj5qM0sGVgDjgJ93VKTNbD4wH2DkyJEnnzZePvAFqKuEJd+BnCI4926/E/XKWeMKOGtcQYePvXuwjl+8sJUt+2towVFR08D3nt7IRacVMWJgZpyTikhP9bRFnQc8AnzVObeus/0SokXd5u/z4e1H4cZVMKB/THy0p7qeD33vBa4sLeY/Pj7F7zgiQhRa1G2cc1VmtgS4EOi0UCeUed/yhpgv/T5c/IOE7wKJRFFuBp8sLeahsndpbmnFeG9mwUlFOXzurBIsAWYbFOkvui3UZlYINIWLdAZwHvDdmCeLl/wSmPFZKLvP+1c0Dc65E8ad63eymPryvHEs23aQpZsOHNvW3Or4S9m77Ktp4NYLTuny+SrkIvETyVUfU4HfAcl4l/M95Jz7P109J6G6PgDqDnoz7DXVw5q/QNUO+OxjMOZDfieLK+ccC/5nHQ8u63pQUEF2Gou/NpeBmsVPJGqidtVHpBKuULfXVA8/mQ4Dx8Lnn/A7Tdy1tjoeKnuXvYc7nm2wsbmVX7ywlRvPGc/Xz5sQ53QifVfU+qj7hVAGnHUj/PN22PwsDJvmbc/I7xf910lJxtVndn3Vzpb9tfzu1e1cP3cMWWl6C4nEmlrUHWmsg/+aCkcq3ts2vBSue8Kb5KmfW7nzEFf84lUmFQ0gPzPU5b456SmcMiSH62aPVleJSBfUou6p1Ez49F+hPPzL5sgBePFeWLwALvouWFJCrMEYKzNG5vOFOaNZU15FU0trl/tu2V/Ls+v38/iaPfzwqtMZlJXGiIEZ+jBSpAfUoo7UP++A137m3R8xEz7/FCT1j8kHe6ts+0G++PsyquqaAJg7oZBvXngKWaknthOy01MoyE6Ld0QR3+nDxGhoboRVv/cWyl31AFz1ezj1cr9TJYw91fUs33aQXVX1/Oz5LdR1sZzYxKE5x1ZhP15KspGWkkySwZAB6UwbkUdBThqpyUkd/pEzIj9Ta0xKQlChjqbWFvj5B71pU+e/8F43SHLXfbXynl1V9SzfVtnhY/sON/Dy5gNU1Td2+Hhzi+NoUwutDvZWH6Wxm66XAekpPHbDHEoKsnqdWySWVKijbe3D8LcvtNtgMP1ab47rNM0JHS9Hm1rYvK+W6vomGppPbKE3NLfyrUfWMiQnndsunkiyGXMnFPqQVKR7+jAx2iZf4c1pXX/I+/rwLii7HzY9DWM/AoUTYcBwyB0OBRMge7C/efuo9FAyU4pzu9wnJz2Fz923nM/f/wbpoSQ2/PtFcUonEj1qUUfLztdh2S+91c6PHLcgQX4JnPfvMOnSfn21iF/KD9Wxv6aBJDOmjcjzO45Ih9SijoeRM71/AA21ULMHqt+F/Rtg9R/hoc/A3FvgIwv8zdkPFednUpyv6Vwlcen6slhIy4aC8V43yKwvex86TvkkvPxjqNzqdzoRSTAq1PGQnOKt1ZiSBk/dCu+84P3bvRpi0PUkIn2Luj7iJWeI1/Xx7N2w5dn3tp//f+Gsr/qXS0QCT4U6nmbfBGM+DE113tevL/SGpR/aDmkDun9+UrL3gWTR6bFMKSIBo0IdT2bvzcYHMGwGPHQUVvwusue7Fm8lmlFzvPlIwOtOyRsFaTlgyZCZDwWnwPAZkJzmdbuISELTT7GfQune5E+ROloNr/4UtjwHTUe8bY11sGkxtDR0/JzxF8CV92kgjkgC03XUfUHb97ClCeoOwJ41sG+dNyDn9YXeAJz2LflIZeR7S5LlFkN6rgbuiMRQr66jNrMRwO+BIYADFjnn/iu6EaVX2gbRpKR6K6kPGAanXOhtGzUbnrkLti3t+eseqXhvxkDMK9pDT3v/PqEsr9988MSTji8iXYtkzcQioMg5t9LMcoAVwMecc2939hy1qPuIxiOw/RVoOAwHNsGqB08cddkSnjwplNWzUZcp6TCgyLsFwKC41PtlkBLh4gyZA70l01I0O54kvqhOymRmjwI/c84909k+KtT9SO1+WPc3qC7v2fMaa6Fm73uFvrkRype/93VPWBJg4V8UPbnluK+T3rs/dp43yVbmwJ7nETkJUSvUZlYCLAVOc84dPu6x+cB8gJEjR56xY8eOkw4s/VR9FexdE+EgIAe1FXBwq9c3jws/r7Nb3v+1a+1836Z6WPewdyVN9tATD93hXw524j4Dx8CQySe/1qYlw6BxkD/qxNePN0vyPuvQVUQxE5VCbWbZwIvAd5xzf+9qX7WoJeHtXgWv/QKaj1+NvYOfl45+hlpboGK9d418XzH8DLjiV95nIH2dJce9S63XkzKZWQj4G/Bgd0VapE8YNh0+8avev05L08k/t7kBKjZ4XUR+q90Lz94DP53hd5L4yR4KGXk9e07GQPhfT0U9SiRXfRjwG2C9c+6HUU8g0pf1ZuWf5JD3AWtQjDsX3n7MG3jV1zU3QNW70FjTs+eldz0/+smKpEU9G/gMsNbMVoe3fcs592RMEolIMOWXwOwb/U7RL3VbqJ1zL+P7JxkiIv2XpjkVEQk4FWoRkYBToRYRCTgVahGRgFOhFhEJOBVqEZGAU6EWEQm4mCwcYGYVwMnOylQAHIhinGhRrp4Lajbl6hnl6rmTyTbKOVfY0QMxKdS9YWZlnU1M4ifl6rmgZlOunlGunot2NnV9iIgEnAq1iEjABbFQL/I7QCeUq+eCmk25eka5ei6q2QLXRy0iIu8XxBa1iIi0o0ItIhJwgSnUZnahmW00sy1mdpuPOUaY2RIze9vM3jKzm8Lbv21mu8xsdfjfxT7l225ma8MZysLbBprZM2a2OXybH+dMp7Q7L6vN7LCZ3ezHOTOz+8xsv5mta7etw/Njnp+E33NrzCym60x1ku37ZrYhfPxHzCwvvL3EzOrbnbv/jnOuTr93ZnZ7+JxtNLML4pzrL+0ybW9bzCTO56uzGhG795lzzvd/QDKwFRgDpAJvAqf6lKUImBG+nwNsAk4Fvg18IwDnajtQcNy27wG3he/fBnzX5+/lXmCUH+cMmAvMANZ1d36Ai4Gn8BbGmAks8yHb+UBK+P5322Urab+fD7k6/N6FfxbeBNKA0eGf2+R45Tru8f8H3OXD+eqsRsTsfRaUFvWZwBbn3DvOuUbgz8DlfgRxzu1xzq0M368B1gPD/cjSA5cDvwvf/x3wMf+icA6w1Tl3siNTe8U5txQ4eNzmzs7P5cDvned1IM/MiuKZzTm32DnXHP7ydaA4VsfvSa4uXA782TnX4JzbBmzB+/mNa67wWq5XAX+KxbG70kWNiNn7LCiFejjwbruvywlAcTSzEmA6sCy86Ybwny73xbt7oR0HLDazFWY2P7xtiHNuT/j+XmCIP9EAuJr3//AE4Zx1dn6C9r77X3gtrzajzWyVmb1oZmf7kKej711QztnZwD7n3OZ22+J+vo6rETF7nwWlUAeOmWUDfwNuds4dBhYCY4FpwB68P7v8MMc5NwO4CPiKmc1t/6Dz/tby5ZpLM0sFLgP+Gt4UlHN2jJ/npytmdgfQDDwY3rQHGOmcmw58HfijmQ2IY6TAfe+Ocw3vbxDE/Xx1UCOOifb7LCiFehcwot3XxeFtvjCzEN434EHn3N8BnHP7nHMtzrlW4FfE6M+97jjndoVv9wOPhHPsa/tTKny7349seL88Vjrn9oUzBuKc0fn5CcT7zsyuAy4BPh3+ASfctVAZvr8Cry94QrwydfG98/2cmVkKcAXwl7Zt8T5fHdUIYvg+C0qhfgMYb2ajw62yq4HH/AgS7vv6DbDeOffDdtvb9yl9HFh3/HPjkC3LzHLa7uN9ELUO71x9Lrzb54BH450t7H2tnCCcs7DOzs9jwGfDn8rPBKrb/ekaF2Z2IXArcJlzrq7d9kIzSw7fHwOMB96JY67OvnePAVebWZqZjQ7nWh6vXGHnAhucc+VtG+J5vjqrEcTyfRaPT0kj/CT1YrxPT7cCd/iYYw7enyxrgNXhfxcDfwDWhrc/BhT5kG0M3ifubwJvtZ0nYBDwHLAZeBYY6EO2LKASyG23Le7nDO8XxR6gCa8v8AudnR+8T+F/Hn7PrQVKfci2Ba//su299t/hfT8R/h6vBlYCl8Y5V6ffO+CO8DnbCFwUz1zh7b8FvnTcvvE8X53ViJi9zzSEXEQk4ILS9SEiIp1QoRYRCTgVahGRgFOhFhEJOBVqEZGAU6EWEQk4FWoRkYD7/7YHpG11awiJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(regressor.training_loss_history, label = \"test1\")\n",
    "#ax.plot(regressor.validation_loss_history, )\n",
    "ax.plot(regressor2.training_loss_history, label = \"test2\")\n",
    "#ax.plot(regressor2.validation_loss_history)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x167121160>]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlUElEQVR4nO3deZAe9X3n8ff3Oec+JI2u0TG6AAsZBB4wRIR1hI2Fk4Jy1rGh1jbrEFOJg403sRNcSZGYrF1xsomPgnghseMNWcNi4sSKI4MTwNiFzSECBkkgPDqQZkBoRseM5p7neX77R/cz88z9aOY51D2fV9VTff2e7l9Pw6d/+nU/3eacQ0REgi9S7gqIiEhhKNBFREJCgS4iEhIKdBGRkFCgi4iERKxcG16yZIlraWkp1+ZFRALp+eef73LONU21rGyB3tLSwu7du8u1eRGRQDKz16dbpi4XEZGQUKCLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFREIicIH+n2/9J195/ivosb8iIuPNGuhm9k0zO25me6ZZbmb2NTNrM7OXzOzSwldzzN4Te/nGnm/QPdRdzM2IiAROPi30bwE7Zlh+HbDJ/9wKfH3+1ZresqplALzV/1YxNyMiEjizBrpz7sfAyRmK3AD8g/M8DTSY2YpCVXCiYyeTAHScebNYmxARCaRC9KE3A0dzptv9eZOY2a1mttvMdnd2ds5pYydOVwHQ0XtsTt8XEQmrkl4Udc7d55xrdc61NjVN+bCwWTVWLMK5CG8q0EVExilEoHcAq3OmV/nziqIiFselatWHLiIyQSECfSfwUf9ulyuAbudc0Tq4k/EIbqSet/rUQhcRyTXr89DN7AHgXcASM2sH/gSIAzjn/jewC3gf0Ab0Ax8rVmUBEtEomVQ9nYPHi7kZEZHAmTXQnXM3zbLcAb9bsBrNIhmL4EbqODHYhnMOMyvVpkVEzmmB+6VoIhYhk6pnKD3AmZEz5a6OiMg5I3CB7rXQ6wF4q08XRkVEsgIX6IlYBJfyA113uoiIjApcoCdjUTJqoYuITBK4QPda6LUYpha6iEiOwAV6MhYBYlTHGhToIiI5AhroUBNboi4XEZEcAQz0KAA10cUc069FRURGBS7QE34LvTKyWF0uIiI5AhvoFbaI3pFeeod7y1wjEZFzQ+ACPRoxYhEjaY2A7kUXEckKXKCDd2E04RYD8Gaf3lwkIgIBDfRELELMD/Q3et8oc21ERM4NgQz0ZCxKNF1PzGJqoYuI+AIZ6IlYhOG0Y1n1MrXQRUR8gQz0ZCzCcDrDypqVCnQREV8gAz0RizA0kmFF9Qre6FOgi4hAQAM9t4Xe2d/JSHqk3FUSESm7QAZ6toW+snolDsexfj0CQEQkkIGejEUZ8lvoAG/26k4XEZFABrrXQk+zstoLdPWji4gENNCzfejLq5djmFroIiIENNCzfejxaJymyiY6ejvKXSURkbILZKAnY1GG0xkAVtas1K9FRUQIbKB7fegAK2pW6MdFIiIEONBHW+jVKznWf4yMy5S5ViIi5RXIQE/EIgylMjjnWFmzklQmRWd/Z7mrJSJSVoEM9GQsgnOQyjhWVK8A9Fx0EZFABnr2NXRDqQzNtc0AtPe2l7NKIiJlF8hAT8aiAAynMjTXNGMY7WcU6CKysOUV6Ga2w8z2m1mbmd0xxfI1ZvaEmb1gZi+Z2fsKX9UxYy30NMlokqVVSzl65mgxNykics6bNdDNLArcA1wHbAZuMrPNE4r9MfCQc+4S4Ebgbwpd0VxJP9CHU96dLatqV6mFLiILXj4t9MuBNufcQefcMPAgcMOEMg6o88frgaLeGJ7bhw6wuna1Al1EFrx8Ar0ZyO3PaPfn5fpT4MNm1g7sAj451YrM7FYz221muzs7536bYW4fOniBfnzgOIOpwTmvU0Qk6Ap1UfQm4FvOuVXA+4D7zWzSup1z9znnWp1zrU1NTXPeWG4fOsCqmlUAaqWLyIKWT6B3AKtzplf583LdAjwE4Jz7GVABLClEBaeS7UMfGhlroYNuXRSRhS2fQH8O2GRm68wsgXfRc+eEMkeAawDM7G14gV60n25WxL0ul8FsC73Wa6HrThcRWchmDXTnXAq4DXgUeAXvbpa9ZnaXmV3vF/t94ONm9nPgAeC/O+dcsSpdEfeqPei30BuSDdTEaxToIrKgxfIp5JzbhXexM3fenTnj+4Btha3a9Cr9FvrAsNdCNzPd6SIiC14gfyk6scsFvG4XtdBFZCELdKBnW+jgBXpHbwfpTHq6r4mIhFogAz3b5TI4khPoNasYyYzQOaDH6IrIwhTIQI9HjYiNXRSFsVsX1e0iIgtVIAPdzKiMRxnIaaEr0EVkoQtkoIPXj57b5bK8ejmxSIzXe14vY61ERMon0IGe20KPRWKsqV2jQBeRBSvAgR4Z/el/1tq6tRzuPlyeComIlFlgA70yMb6FDtBS18KRM0d066KILEiBDfSK2Pg+dICW+hZGMiO80VfUx7GLiJyTAhvoU7XQ19atBVA/uogsSIEN9GQsOu4+dPC6XAD1o4vIghTYQK9MTO5yWVSxiNp4LYd7DpenUiIiZRTcQI9Hxj3LBbwfHLXUtyjQRWRBCmygV8Sj4562mLW2bq360EVkQQpsoFfGo5Na6OAF+rG+Y/SP9JehViIi5RPYQE/GowylMmQy41+M1FLfAuiZLiKy8AQ20LOP0B1KTX2ny6GeQ6WukohIWQU20MfeKzq+22VN7RoAXu9WP7qILCyBDfTR94pOCPSqeBXLq5dzsPtgOaolIlI2gQ30iineWpS1oWGDAl1EFpzAB/rEFjrAhvoNHOo+pId0iciCEthAr0xM30Lf2LCRofQQ7b3tpa6WiEjZBDbQK2LZi6KZScs2NGwA4MDpAyWtk4hIOQU20LMt9Kl+XKRAF5GFKLCBPnpRdIqf/1fHq1lRvYK2022lrpaISNkENtBHb1ucooUOsL5hve50EZEFJbCBnsz+sCg1uQ8dYGP9Rt3pIiILSmADPdtCH5ymhb6hYYPudBGRBSXwgd4/TaBvbNgI6MKoiCwceQW6me0ws/1m1mZmd0xT5oNmts/M9prZtwtbzcli0QiJWIT+kdSUy9c3rAcU6CKycMRmK2BmUeAe4D1AO/Ccme10zu3LKbMJ+BywzTl3ysyWFqvCuaoTUfqHpm6h604XEVlo8mmhXw60OecOOueGgQeBGyaU+Thwj3PuFIBz7nhhqzm1qkSMvuGpW+gAmxo38dqp10pRFRGRsssn0JuB3LdFtPvzcp0HnGdmT5nZ02a2Y6oVmdmtZrbbzHZ3dnbOrcY5qpPTt9ABzm88n8PdhxlKD817WyIi57pCXRSNAZuAdwE3AX9rZg0TCznn7nPOtTrnWpuamua90dla6OcvOp+US6kfXUQWhHwCvQNYnTO9yp+Xqx3Y6Zwbcc4dAl7DC/iiqknG6BuaIdAbzwdg/8n9xa6KiEjZ5RPozwGbzGydmSWAG4GdE8r8C17rHDNbgtcFU/SfaVYlotPetgiwunY1lbFK9aOLyIIwa6A751LAbcCjwCvAQ865vWZ2l5ld7xd7FDhhZvuAJ4DPOudOFKvSWdXJmbtcopEomxo38erJV4tdFRGRspv1tkUA59wuYNeEeXfmjDvg9/xPyVTNcNti1vmN5/PI4UdwzmFmJaqZiEjpBfaXojB7Cx3ggkUXcGb4DG/2vVmiWomIlEegA70qEWVwJEM646Ytc17jeYAujIpI+AU60KsTXo9R/wyt9PMaz8Mw9p9SoItIuAU70JNeoPfN0I9eFa9iTd0atdBFJPQCHujeExdn60c/v/F8Xjn5SimqJCJSNoEO9Kpsl8ssd7psXryZjt4OTg+eLkGtRETKI9CBXp3Ir4W+ZckWAPae2Fv0OomIlEugA70qOftFUfBa6KBAF5FwC3Sgj7bQZ+lyqU3U0lLXwp6uPaWolohIWQQ60PNtoQNcuORC9naphS4i4RXoQM+20HtnaaEDbFm8heMDxzneX5J3b4iIlFygA33sLpf8WuiAWukiElqBDvRELEIiGqFvhkfoZl2w6AKiFmXPCfWji0g4BTrQAaqS0bz60CtjlWxo2KA7XUQktAIf6NWJ2Kx3uWRduNi7MOo97VdEJFwCH+jeW4tmb6EDXNR0EaeHTvN6z+tFrpWISOkFPtCrkzHODOYX6JcsvQSAFztfLGKNRETKI/CBXlcZ58zgSF5l19WvozZRy4vHXyxupUREyiDwgV5bkX8LPWIRtjZtVaCLSCgFPtDrKuL05NlCB9i6dCsHug/QPdRdxFqJiJReCAI9Rk+eLXQY60f/eefPi1UlEZGyCHyg11bEGE5lGBzJ/9bFqEXV7SIioRP4QK+rjAPk3Y9eFa/igkUX6E4XEQmdwAd6bYX3PJd873QBrx/95c6XGcnk/x0RkXNd4AO9rsJroZ9tP/pgepB9J/YVq1oiIiUX+ECvrch2ueTf2r5s+WUAPHfsuaLUSUSkHAIf6HWVXpdLz0D+LfRFFYvY2LBRgS4ioRL4QJ9LCx3g8uWX88LxFxhJqx9dRMIhBIGevSiafwsdvG6XgdSAno8uIqER+ECvScQw46x+LQrQuqwVw3j2zWeLVDMRkdLKK9DNbIeZ7TezNjO7Y4Zy/9XMnJm1Fq6KM4tEjJqzeOJiVkNFA+c1nqd+dBEJjVkD3cyiwD3AdcBm4CYz2zxFuVrgduCZQldyNnUVcXoGzr4v/LLll/Fi54sMp4eLUCsRkdLKp4V+OdDmnDvonBsGHgRumKLcnwFfAgYLWL+81J7l81yy3rninQylh/QYABEJhXwCvRk4mjPd7s8bZWaXAqudc/8204rM7FYz221muzs7O8+6stM52ycuZl22/DJiFuOpN54qWF1ERMpl3hdFzSwC/DXw+7OVdc7d55xrdc61NjU1zXfTo+oqz74PHaA6Xs0lyy7hqQ4FuogEXz6B3gGszple5c/LqgW2AD8ys8PAFcDOUl4Yra3I/61FE13VfBX7T+3neP/xAtdKRKS08gn054BNZrbOzBLAjcDO7ELnXLdzbolzrsU51wI8DVzvnNtdlBpPob4yTvccLooCbFu5DUCtdBEJvFkD3TmXAm4DHgVeAR5yzu01s7vM7PpiVzAfDVVxzgymGElnzvq75zWeR1Nlk/rRRSTwYvkUcs7tAnZNmHfnNGXfNf9qnZ1F1QkATveP0FSbPKvvmhnbmrfx+JHHSWVSxCJ5/UlERM45gf+lKEBjlRfop/rndj/5tuZt9Az3sKdLjwEQkeAKV6D3zS3Qr1xxJVGL8mT7k4WslohISYUj0Ku9Jy7OtYVen6yndXkrjx95vJDVEhEpqXAE+miXy9wfhbt99XYOdh/kUPehQlVLRKSkQhXoJ+fY5QKwfc12AJ44+kRB6iQiUmqhCPTKRJTKeJTTc+xyAVhevZzNizer20VEAisUgQ7QWBXnZN/83j60ffV2Xup8ic7+wj1nRkSkVMIT6NWJOV8Uzdq+ZjsOp24XEQmk0AT6ogIE+saGjbTUtfDo4UcLVCsRkdIJTaA3VCXmfB96lpmxY90Onjv2nB7WJSKBE5pAX1QVn9dti1nXrbsOh1MrXUQCJzSB3lidoHtghNQcHtCVa339ei5YdAE/OPSDAtVMRKQ0whPo/r3oc32Mbq7r1l3Hy10vc7Tn6OyFRUTOEaEJ9OwTF0/Msx8d4LqW6wD4wWG10kUkOEIT6Ev9x+Ye7xma97pW1Kzg0qWX8q8H/hXn3LzXJyJSCuEJ9LoKAI6fGSzI+t6/6f0c7jnMC8dfKMj6RESKLTyBnm2hn5l/Cx3g2rXXUh2v5ru/+G5B1iciUmyhCfTqZIzqRLQgXS4AVfEqdrTs4Iev/5De4d6CrFNEpJhCE+gATbXJgnW5gNftMpAa0D3pIhIIoQr0pbUVBetyAbhoyUVsbNjIw689XLB1iogUS6gCvakuSWcBA93M+OD5H2TPiT281PlSwdYrIlIMoQr0pbVJjvcUrssF4PoN11Mdr+bbr367oOsVESm0kAV6BX3DafqGUgVbZ3W8mvdvfD+PHn6UroGugq1XRKTQQhbohb11MeumC24inUnznf3fKeh6RUQKKVyBXpf9tWhhu13W1K3hquareHD/gwymCrtuEZFCCVeg12Z/LVrYFjrAx7Z8jJODJ/le2/cKvm4RkUIIVaCvaPAC/Y3TAwVfd+uyVi5uupi/3/v3jGTm/0RHEZFCC1Wg11XEqauI0X6q8IFuZvzW23+Ljt4OHjn0SMHXLyIyX6EKdIBVjVV0FKGFDnD1qqvZ1LiJb7z8DTJufi/SEBEptBAGeiXtp/qLsu6IRbj17bdyoPsAuw7tKso2RETmKq9AN7MdZrbfzNrM7I4plv+eme0zs5fM7DEzW1v4quanubGS9lMDRXuO+bUt13LBogu4+4W7GUmrL11Ezh2zBrqZRYF7gOuAzcBNZrZ5QrEXgFbn3EXAw8BfFLqi+VrVWEX/cJrTBXhh9FQiFuH2S2+no7eDh3+hZ7yIyLkjnxb65UCbc+6gc24YeBC4IbeAc+4J51y2n+NpYFVhq5m/VY2VAEW5MJq1beU2Wpe1cu/P76V/pDjdOyIiZyufQG8Gct+W3O7Pm84twJQv4zSzW81st5nt7uzszL+WZ6G5IRvoxQtaM+P2S2/nxOAJvrX3W0XbjojI2SjoRVEz+zDQCvzlVMudc/c551qdc61NTU2F3PSo1Y1VAEW70yVr69KtvLflvXxzzzc5eubo7F8QESmyfAK9A1idM73KnzeOmb0b+CPgeudc4X+qmae6yhi1yRhHTha/K+QzrZ8hYhH+4tmyXTIQERmVT6A/B2wys3VmlgBuBHbmFjCzS4B78cL8eOGrmT8zY31TNYe6+oq+reXVy/nti3+bH7X/iB+3/7jo2xMRmcmsge6cSwG3AY8CrwAPOef2mtldZna9X+wvgRrgO2b2opntnGZ1JbGhqYa246V5D+hH3vYR1tWv44vPfFEXSEWkrPLqQ3fO7XLOneec2+Cc+4I/707n3E5//N3OuWXOua3+5/qZ11hcG5bW8Gb3IL0FfC76dOLROHdecScdvR18+fkvF317IiLTCd0vRQE2NFUDcKiz+N0uAK3LW/nw2z7Mg/sf5Ok3ny7JNkVEJgploG9cWgNAW+eZkm3zU5d+irV1a7nzqTvpHS5Nd4+ISK5QBvqaRdVEI8aB46VpoQNUxir5n9v+J2/1v8VdP7uraI8eEBGZTigDPRGLsHZRFQc6S9tS3rp0K7dtvY0fHP4BD+1/qKTbFhEJZaCD1+2y/1jpulyybnn7Lfxy8y/zpee+xN6uvSXfvogsXKEN9C3N9Rw60VeSO11yRSzCF6/6IosrF/PpH32aroGukm5fRBau0Ab625vrcQ72dnSXfNsNFQ189Ve+SvdQN5987JMMpIr7GAIREQhxoG9prgfg5TIEOsDmxZv581/+c/ae2MvnfvI50pl0WeohIgtHaAO9qTbJivqKsgU6wPY12/lM62d47Mhj/NnTf6Y7X0SkqGLlrkAxbWmuL2ugA3z0wo9yeug0f/vy31IRq+APL/tDzKysdRKRcAp1oF/UXM9/vPIW3f0j1FfFy1aPT17ySQbTg9y/734iFuGzrZ9VqItIwYU60N+5fjHOwTOHTnDthcvLVg8z47OtnyWdSXP/vvvpHurm87/0eWKRUP/5RaTEQtuHDnDx6nqSsQg/O3ii3FXBzLjj8jv4xNZPsPPATj79xKd194uIFFSoAz0Zi9La0sjPDpQ/0MEL9d+5+Hf443f+MT9u/zE3/+Bm3uh9o9zVEpGQCHWgA1y5fjGvHjvDyb7hcldl1Icu+BB3X3M3R88c5cbv38izbz5b7iqJSAiEPtC3bVwCwJOvlfVFSpNcvepqHvjVB2isaOTj//5x7n7hbkYyI+WulogEWOgD/eJVDSyrS/LInmPlrsokLfUtfPtXv82vrf817n3pXj6666Mc6j5U7mqJSECFPtAjEWPHhct58rVO+odL+1yXfFTHq/nCVV/gr/7LX3HkzBE+sPMDfP3nX2coXbb3bItIQAUv0Dueh5/dAy/8I+zbCQefhDdegJMHoe8EpCd3W+zYsoLBkQxPvNpZhgrn59qWa/nnG/6Z7Wu28zcv/g2//r1f5yftP9GvS0Ukb1auwGhtbXW7d+8++y/+5K/gsbtmLhOvgop6SNZBRT2ZZC3/cWiIWFU92y/eBBV1/vJ6bzg67Q8T1VDGH/789I2f8sVnvsjrPa9z2fLL+NQln2Lr0q1lq4+InDvM7HnnXOuUywIX6Jk0DPXAYDcM+sPc6dHx7nHLTp08QXrgNIujA9hsFx8t6oV8NuCzn9Hp7LI6SNR448nayZ9IdG5/HGA4Pcx3XvsO9710HycHT3L1qqv52IUf4x3L3qFfmYosYOEK9Dk61j3Iti89zm/+0lr+6L3rpzgZdM98ohid7oGhPJ8PE68aH/Azhf/ET8Ib9kei/GPbP3H/K//I6aHTbFm8hZsvvJlr1l5DPFK+xxmISHko0H23P/gCP9z7Fj/+g1+hqTY59xVlMl64D/fC0JkZPj3ecFK5nrHxTB4Xai3KQLKWnXW13F8Z4fWIYxFRfjW2mPdXrWFT5QpI1nhdRYlq72QwOl6Ts6zG+8QSc993ESkrBbrvUFcf7/7rJ/nIFWv50+svLOm2p+QcpIYmh/zoCaBn0kkiPdjDU8PH+ef0KX4UGSZl8LbhFO/p7eWa/n7Wj+RxgojEvYBP5gb/hBNB0g//3BPBTMuiei6NSCnMFOgL6v/CdUuq+WDrau5/+nU+8I5Voy/BKBsziFd4n5qmvL4SBa72PycHT/JvB/+NRw49wte6XuJrixpYV7uaX1l6Ge9s2MQlVauoTA17J4jhPn+YHe+Dod7xy/pP+icTf97ZPGsmmpwc9vGqnGEVxKv9YWXOeHaYLVs54XvV87oWIbKQLKgWOkB3/wjv+fKTLKpO8C+/u42KeDjC4ljfMZ44+gSPHXmM5489T8qliEfibF26lcuWX8bFTRezZckW6hJ1+a80k845EfSND/vhKYZDE08c/TDS780bGRgbd2f59qZociz0J50cZjgRjJad6nvV3ok0VgmR4N29KwuXulwmePzVt/jNb+3mhq0r+cqHtoburpH+kX6ef+t5nnnzGZ499iyvnnwVh3ecW+pa2LJkCxcuvpCNjRvZUL+BJZVLSvc3cA7Sw37I93tBnx0f7oeRvqnnDftlR8f7c9bRPzZvpP/s6xRN+icE/xOr9P/lVAWxiimW5U775caVrxo7WUz8rk4eMk8K9Cnc80Qbf/nofj5yxVo+f/2FRCLhCvVcPcM97O3ay56uPezp2sPLXS/TOTD2I6u6RB0bGjawvn49q2tX01zbTHN1M821zTQmG4N1wstkvK6i3IAfd1LInjD6vXIjOZ9J04P+OvxhanBs2VyfuxNNTh3+E08eE08MsaQ/r8IbZqdjE6eTY9/PzlOXVaioD30Kn3jXBnoGR7j3yYN0nB7gLz5wEUtq5nHnyzmsLlHHlSuv5MqVV47O6xro4sDpA7SdbuPA6QMcOH2Ax488zqmhU+O+WxmrpLmmmaVVS1lSuYQllUtoqmxiSeUSFlcupqmyiYZkA7WJWqLnQnBEImMXb4spnZrjCWGaE8TIAPR3TbGsP787oWYSiU8T+smZTw6TTh7J8SeXSevJLZPwTl7ReFl/pLfQLNgWetb/+elhvrDrFWqTMT51zSZuvHw1ydg5EExl0jfSR/uZdjp6O3ij9w06ejvo6O2ga6CLzoFOuga6SE0TMDXxGuqT9dQl6rxPsm50vDJeSVWsispYJVVxf5gznR2viFWQiCSIRWLB+pdBMaVTkB7y7ohKDfph7w9H5w15J5Rx0/MtN+htd76iSS/oo4lphsmxE8DoMDnzsnzXMVW5gHd7zbvLxcx2AF/Fu8ni75xzfz5heRL4B+AdwAngQ865wzOt81wJdIBXj/Vw5/f28uyhkyyqTnDD1pW8Z/MyLl3TGJqLpoXinKNnuIfO/k66BrvoGuiie6ibnqEeeoZ7vPHh8eNnhs+c9cPGDCMRTZCIJLxhNEEymiQejZOITB6PRWLEIjGiFh0/jESJWWx0PDs/Zv6ynLLZ8ex3zIyoRYlYxPsQIRLxhzb+E7XoaPmJw5m+N+P3sfKf1DIZ/2Qyh5NEasi7XjJuOASp4ZwT1HTLJgzTBXyfQSSW/0kkGvdOBtGEPy/7yc7PLRMfO3lMuTynTO1yqGycU/XnFehmFgVeA94DtAPPATc55/bllPkEcJFz7rfN7Ebg/c65D8203nMp0MELqqfaTvDAs0f44b5jjKQdyViE85fXsnFpDRuaalhWV8HimgRNNUnqKuJUJCJUJWJUxqNEQ9wHXwjpTJqB1AADqQH6U/30j/TTn+r3pv3x/pF+htPDDGeGGUoPMZIeGR0fTg+PfTKTx1OZFKlMirRLjxtmx9OZNCl37j1tczbZE4mZEbHIaMjnjhs2emLI/Q7GaLnpvptdd+56plo2Op6zjtFtTFEud1nEJnx3mvVOWy67zGUwlyHinD/MQCZDhAyRTAZcmkgmWybtLXNpLON/XBrLZLBMCnNpIuk0uBSWSRPJeEMyKSKZtFcmk/K2mfbH/XL4yyOZEQwHznvKoeV+nBsdz/57wICIA8Ox6ao/ZOW235vTfxPz7UO/HGhzzh30V/YgcAOwL6fMDcCf+uMPA3ebmbkAPSrQzLhq0xKu2rSEM4MjPHvoJD87cIJXj53hp20n+O5/dsz4/UQ0QixqRM2IRIxoxIiYEY0wbt5UsT9dK2zKudOcN/Jd77l52kn6n7m1WCaK+p+Jv4f17vTJABkcGbA0kB4dd2S8afOG4LxvWcYfz/hr8adH5+fOc/76x8pDBmfjp6derz9uE9Y5bt7YMHvnUna5y477ewvjv5Ndx9gn92/CpOVj28/9Pv58Jqwr+7eavI2x/Zu8jXH1m1THCfWbUMZNsY2x/ZgHY+w/onGmnDknv9E9zJ0FWdN4+QR6M3A0Z7odeOd0ZZxzKTPrBhYDXbmFzOxW4FaANWvWzLHKxVdbEeeaty3jmrctG53XP5yi88wQXb1DdJ4ZpncoxcBImoHhFAPDGfpHUqTTjrRzZDLeMJ1hdDw7nGi6U95Us6c7P045d4qZbuqSIqHj3NhJwI07ecBUJ5Lp5jO6NLdcJu/505V7x9qLC7/TlPguF+fcfcB94HW5lHLb81WViLF2cYy1i4t894SIyBzlc7m3A1idM73KnzdlGTOLAfV4F0dFRKRE8gn054BNZrbOzBLAjcDOCWV2Ajf74x8AHg9S/7mISBjM2uXi94nfBjyKd0Xgm865vWZ2F7DbObcT+AZwv5m1ASfxQl9EREoorz5059wuYNeEeXfmjA8Cv1HYqomIyNkI9k+mRERklAJdRCQkFOgiIiGhQBcRCYmyPW3RzDqB1+f49SVM+BXqAqB9Xhi0zwvDfPZ5rXNuyndWli3Q58PMdk/3cJqw0j4vDNrnhaFY+6wuFxGRkFCgi4iERFAD/b5yV6AMtM8Lg/Z5YSjKPgeyD11ERCYLagtdREQmUKCLiIRE4ALdzHaY2X4zazOzO8pdn0Ixs9Vm9oSZ7TOzvWZ2uz9/kZn9u5n9wh82+vPNzL7m/x1eMrNLy7sHc2NmUTN7wcy+70+vM7Nn/P36f/4jmzGzpD/d5i9vKWvF58jMGszsYTN71cxeMbMrF8Ax/h/+f9N7zOwBM6sI43E2s2+a2XEz25Mz76yPrZnd7Jf/hZndPNW2phOoQDfvhdX3ANcBm4GbzGxzeWtVMCng951zm4ErgN/19+0O4DHn3CbgMX8avL/BJv9zK/D10le5IG4HXsmZ/hLwZefcRuAUcIs//xbglD//y365IPoq8Ihz7gLgYrx9D+0xNrNm4FNAq3NuC94juG8knMf5W8COCfPO6tia2SLgT/Be83k58CfZk0BenHOB+QBXAo/mTH8O+Fy561Wkff0e8B5gP7DCn7cC2O+P3wvclFN+tFxQPnhvv3oM2A58H+/1vF1AbOLxxnse/5X+eMwvZ+Xeh7Pc33rg0MR6h/wYZ983vMg/bt8H3hvW4wy0AHvmemyBm4B7c+aPKzfbJ1AtdKZ+YXVzmepSNP4/My8BngGWOefe9BcdA7Jvrg7D3+IrwB8w9lr3xcBp51zKn87dp3EvIgeyLyIPknVAJ/D3fjfT35lZNSE+xs65DuB/AUeAN/GO2/OE+zjnOttjO69jHrRADz0zqwH+Cfi0c64nd5nzTtmhuM/UzH4NOO6ce77cdSmhGHAp8HXn3CVAH2P/BAfCdYwB/O6CG/BOZiuBaiZ3SywIpTi2QQv0fF5YHVhmFscL8//rnPuuP/stM1vhL18BHPfnB/1vsQ243swOAw/idbt8FWjwXzQO4/cpDC8ibwfanXPP+NMP4wV8WI8xwLuBQ865TufcCPBdvGMf5uOc62yP7byOedACPZ8XVgeSmRneu1lfcc79dc6i3Bdw34zXt56d/1H/avkVQHfOP+3Oec65zznnVjnnWvCO4+POuf8GPIH3onGYvL+BfhG5c+4YcNTMzvdnXQPsI6TH2HcEuMLMqvz/xrP7HNrjPMHZHttHgWvNrNH/1821/rz8lPsiwhwuOrwPeA04APxRuetTwP26Cu+fYy8BL/qf9+H1Hz4G/AL4D2CRX97w7vg5ALyMdxdB2fdjjvv+LuD7/vh64FmgDfgOkPTnV/jTbf7y9eWu9xz3dSuw2z/O/wI0hv0YA58HXgX2APcDyTAeZ+ABvOsEI3j/GrtlLscW+E1//9uAj51NHfTTfxGRkAhal4uIiExDgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCYn/DzV226DbTXB+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "y1 = lambda epoch: 1 / math.exp(epoch / ((epochs + 1) / (20 * math.log10(epochs + 1))))\n",
    "y2 = lambda epoch: 0.1 * math.exp(-(epoch + 1) * (1 / (epochs + 1))) - 0.03\n",
    "y3 = lambda epoch: math.exp(-epoch / (epochs / (5 * math.log10(epochs + 1)))) + 0.02 * math.exp(-(epoch + 1) * (1 / (epochs + 1))) - 0.005\n",
    "\n",
    "a1 = list(range(epochs))\n",
    "a1 = [y1(x) for x in a1]\n",
    "a2 = list(range(epochs))\n",
    "a2 = [y2(x) for x in a2]\n",
    "a3 = list(range(epochs))\n",
    "a3 = [y3(x) for x in a3]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "print(f\"{a3[-1]:f}\")\n",
    "ax.plot(a1)\n",
    "ax.plot(a2)\n",
    "ax.plot(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x164127b80>]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "y = lambda epoch:  1 / math.exp(epoch / ((epochs + 1) / (20 * math.log10(epochs + 1))))\n",
    "y1 = lambda epoch:  math.exp(-epoch / (epochs / (20 * math.log10(epochs + 1))))\n",
    "\n",
    "a = list(range(epochs))\n",
    "a = [y(x) for x in a]\n",
    "a1 = list(range(epochs))\n",
    "a1 = [y1(x) for x in a1]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "print(f\"{a[-1]:f}\")\n",
    "#print(f\"{math.log10(max // 10) / 10:f}\")\n",
    "ax.plot(a)\n",
    "ax.plot(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x16016db80>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(regressor.training_loss_history.__len__())\n",
    "print(regressor.validation_loss_history.__len__())\n",
    "print(regressor2.training_loss_history.__len__())\n",
    "print(regressor2.validation_loss_history.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hej'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hej, = [\"hej\"]\n",
    "\n",
    "hej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.018"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.018 * 10 * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First_1: 1.103005\n",
      "Last_1: 0.040788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr_target = 0.04\n",
    "lr_inital_descent = 60\n",
    "lr_final_descent = 0.1\n",
    "\n",
    "mutation_sigma1 = lambda epoch: 0.08 + 0.5 * 1 / math.exp(epoch / ((epochs + 1) / (60 * math.log10(epochs + 1))))\n",
    "#mutation_sigma2 = lambda epoch: math.exp(-epoch / (epochs / (20 * math.log10(epochs + 1)))) + 0.08 * math.exp(-(epoch + 1) * (1 / (epochs + 1))) + 0.05\n",
    "\n",
    "mutation_sigma_new_1 = lambda epoch: math.exp(-epoch / (epochs / (lr_inital_descent * math.log10(epochs + 1)))) + lr_final_descent * math.exp(-(epoch + 1) * (1 / (epochs))) + lr_target + (-0.036 * 10 * lr_final_descent)\n",
    "#mutation_sigma_new_2 = lambda epoch: lr_final_descent * math.exp(-(epoch + 1) * (1 / (epochs))) + lr_target + (-0.036 * 10 * lr_final_descent)\n",
    "\n",
    "a1 = list(range(epochs))\n",
    "a1 = [mutation_sigma1(x) for x in a1]\n",
    "#a2 = list(range(epochs))\n",
    "#a2 = [mutation_sigma2(x) for x in a2]\n",
    "a_new_1 = list(range(epochs))\n",
    "a_new_1 = [mutation_sigma_new_1(x) for x in a_new_1]\n",
    "\n",
    "#a_new_2 = list(range(epochs))\n",
    "#a_new_2 = [mutation_sigma_new_2(x) for x in a_new_2]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "print(f\"First_1: {a_new_1[0]:f}\")\n",
    "print(f\"Last_1: {a_new_1[-1]:f}\")\n",
    "#print(f\"First_2: {a_new_2[0]:f}\")\n",
    "#print(f\"Last_2: {a_new_2[-1]:f}\")\n",
    "ax.plot(a_new_1, label = \"a_new_1\")\n",
    "ax.plot(a1, label = \"a1\")\n",
    "#ax.plot(a_new_2, label = \"a_new_2\")\n",
    "ax.legend()\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47d3b7ff548c1bae2d6b155a9b3d6f1122689b634566f833764ba5dd9fcfa2e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Deep-learning-Daniel-Petersson-bXusHwTH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
